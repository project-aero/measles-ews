---
title: Early warning signals of exceptional outbreaks of measles from
  multi-scale data streams
author: "Andrew Tredennick"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Preliminaries
Load necessary packages. These will have to be installed via `install.packages()` if not already available on your machine.

```{r load-packages}
library(tidyverse)  # data wrangling
library(lubridate)  # time and date functions
library(ggthemes)   # pleasing ggplot2 themes
library(cowplot)    # combining ggplot2 objects
library(viridis)    # pleasing color palette
library(spaero)     # project AERO code; EWS metrics, etc.
library(forecast)   # time series functions
library(moments)    # skewness function
library(sf)         # working with spatial data
library(spdep)      # spatial neighborhood functions

theme_set(theme_minimal())  # set the ggplot2 theme globally
```

And define a couple handy wrapper functions around the `spaero::get_stats()` function.

```{r helper-functions, echo=FALSE}
# Functions written by Toby Brett

get_tau <- function(stat_ts, time){
  # Calculates Kendall's tau for association of EWS metrics through time
  #
  # Args:
  #  stat_ts: a vector of EWS stats for each time window
  #  time: a sequence of time windows
  #
  # Returns:
  #  A scalar of Kendall's tau for the assocition of the metric with time
  
  stats::cor(stat_ts, time, use="pairwise.complete.obs", method="kendall")
}

get_ews_cor <- function(reports, bw = bandwidth, l = lag){
  # Calculates EWS from case reports time series and their association
  #  with time (Kendall's tau)
  #
  # Args:
  #  reports: a vector of case reports through time
  #  bw: bandwidth of kernel for detrending
  #  l: lag for autocovariance calculation
  #
  # Returns:
  #  A list of size vectors of EWS stats and a vector of Kendall's tau over 
  #  time for each EWS stat.
  
  stats <- spaero::get_stats(
    reports,
    center_bandwidth = bw, 
    stat_bandwidth = bw,
    center_trend = "local_constant",
    stat_trend = "local_constant",
    center_kernel = "uniform",
    stat_kernel = "uniform", 
    lag = l
  )
  
  taus <- sapply(stats$stats, get_tau, time = seq_along(reports))
  list(stats = stats$stats, taus = taus)
}
```

## Data
The data are weekly reports from 1995 to 2005 of measles cases from 40 deparments in Niger, which I sum over here to plot the national trend through time.

```{r load-data}
file_name <- "../niger_measles/niger_regional_1995_2005.csv"
niger_measles_raw <- read_csv(file_name, col_types = cols())

num_regions <- nrow(niger_measles_raw)
num_weeks <- ncol(niger_measles_raw) - 1  # subtract 1 from ncol() because first column are regions

# Create a vector of dates for each week over 11 years
start_date <- ymd("19950101")
all_dates <- seq(start_date, by = "week", length.out = num_weeks)

# Clean up the data frame
niger_measles <- niger_measles_raw %>%
  gather(key = week, value = cases, -X1) %>%
  mutate(
    week_num = rep(1:num_weeks, each = num_regions),
    date = rep(all_dates, each = num_regions)
  ) %>%
  dplyr::rename(region = X1) %>%
  dplyr::select(-week)

# Aggregate over departments (regions) for plotting national trend 
national_data <- niger_measles %>%
  group_by(date) %>%
  summarise(total_cases = sum(cases, na.rm = TRUE))  # ignore NAs from some regions

ggplot(national_data, aes(x = date, y = total_cases)) +
  geom_col(fill = "coral") +
  labs(x = "Date", y = "Reported cases") +
  ggtitle("Reported measles cases", subtitle = "Niger")
```

We can also look at the data by deparment, as below. Note that the cycles of large outbreaks are less regular than at the national scale (also see [Ferrari et al. 2008, Nature](https://www.nature.com/articles/nature06509)).

```{r plot-region-cases}
ggplot(niger_measles, aes(x = date, y = cases)) +
  geom_col(fill = "coral") +
  labs(x = "Date", y = "Reported cases") +
  facet_wrap(~region, scales = "free_y") +
  theme_minimal(base_size = 8)
```

## Analysis
### Time series decomposition and identifying exceptionally large outbreaks
The first step is to identify "exceptionally large outbreaks." To do this, I will first decompose the time series into trend, seasonal, and random components. I will use the trend component as the time series for identifying large outbreaks as anomalies. An exceptionally large outbreak year will be defined as a year in which the maximum value of the trend component exceeds 4 standard deviations (4$\sigma$) of the mean of the trend component.

Much of this is based on this: https://anomaly.io/anomaly-detection-moving-median-decomposition/.

```{r ts_decomp}
# Convert national cases to time series object
start_date <- min(national_data$date)
end_date <- max(national_data$date)

national_ts <- ts(
  national_data$total_cases, 
  start = c(year(start_date), month(start_date)), 
  end = c(year(end_date), month(end_date)), 
  frequency = 53  # weekly frequency is problematic, but choosing 52 weeks/year
)

# Decompose the time series and calculate anomaly threshold
trend <- runmed(national_ts, k = 53)  # median trend
detrend <- national_ts / trend  # remove the trend assuming multiplicative dynamics
m <- t(matrix(data = detrend, nrow = 53))  # quick matrix of time series
seasonal <- colMeans(m, na.rm = T)  # calculate seasonal component, averaged over weeks
random <- national_ts / (trend * seasonal)  # calculate random component
anom_thresh <- mean(random, na.rm = T) + 4*sd(random, na.rm = T)

# Plot the trend with threshold for outbreak
rand_df <- tibble(
  value = random,
  date = national_data$date[1:length(trend)]
)

ggplot(rand_df, aes(x = date, y = value)) +
  geom_line(aes(color = as.factor(year(date)))) +
  geom_hline(aes(yintercept = anom_thresh), linetype = 2) +
  labs(y = "Random component", x = "Date") +
  scale_color_discrete(name = "Year") +
  annotate("text", 
           x = min(national_data$date)+365, 
           y = 3.25, 
           label = expression(paste("anomaly threshold (4", sigma, ")")), 
           size = 3)
```

The 2003-2004 epidemic year is the only one for which the random component exceeds the anomaly threshold of 4$\sigma$. Thus, our goal is to anticipate this national level outbreak in 2003-2004. The flip side is to avoid signaling an expceptionally large outbreak in the other years (i.e., false positives).

### Spatial indicators of impending outbreak
In spatially extended systems, there are several spatially-based metrics that can serve as indicators of imminent regime shifts:

1. Increase in spatial variance ([Dakos et al. 2011, The American Naturalist](https://www.journals.uchicago.edu/doi/full/10.1086/659945))
2. Increase in spatial correlation/coherence ([Dakos et al. 2010, Theoretical Ecology](https://link.springer.com/article/10.1007/s12080-009-0060-6))
3. Peaking of spatial skewness ([Guttal and Jayaprakash 2009, Theoretical Ecology](https://link.springer.com/article/10.1007/s12080-008-0033-1))
4. Discrete Fourier transform ([Carpenter and Brock 2010, Ecosphere](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/ES10-00016.1))

Measles dynamics in Niger following metapopulation dynamics (Ferrari et al. 2008, Nature), meaning it is a spatially-extended system. Therefore, signals of the national scale outbreak in 2004 might be detectable in the temporal dynamics of measles across space, which in this case are the case reports within regions.

We'll start by looking at the dynamics across space and do an initial test with spatial coherence. The individual metrics will be converted to indices through time by calculating their standardized difference over a moving window from all times from the beginning of the sampling period to the time of the focal sample. Then the individual indices are combined into a composite early warning index, which is simply the sum of all the individual indices ([Drake and Griffen 2010, Nature](https://www.nature.com/articles/nature09389#s1)).

```{r plot-spacetime, fig.height=6}
# Set 0 reports to NA for visualization
niger_measles_0na <- niger_measles %>%
  mutate(
    cases = ifelse(cases == 0, NA, cases)
  )

totals_plot <- ggplot(national_data, aes(x = date)) +
  geom_ribbon(fill = "grey", aes(ymin = 0, ymax = total_cases)) +
  labs(x = NULL, y = "Total\ncases") +
  theme_minimal(base_size = 10)

heat_plot <- ggplot(niger_measles_0na, aes(x = date, y = region, fill = log(cases))) +
  geom_tile() +
  scale_fill_viridis() +
  labs(x = "Date", y = "District") +
  guides(fill = FALSE) +
  theme_minimal(base_size = 10)

plot_grid(totals_plot, heat_plot, align = "v", nrow = 2, rel_heights = c(0.25,1))
```

### Create nieghbor weights for Moran's I
To calculate spatial coherence (or correlation), we first need to create a list of spatial weights that define the spatial connection between different districts.

```{r create-neighbors}
# Read in shapfile of districts
region_boundaries <- sf::st_read("./spatial_data/NER_adm2.shp") %>%
  rename(region = NAME_2) %>%
  mutate(region = as.character(region)) %>%
  mutate(  # rename several regions to match incidence data
    region = ifelse(region == "Aguié", "Aguie", region),
    region = ifelse(region == "Filingué", "Filingue", region),
    region = ifelse(region == "Gouré", "Goure", region),
    region = ifelse(region == "Illéla", "Illela", region),
    region = ifelse(region == "Maïné-Soroa", "Maine-Sora", region),
    region = ifelse(region == "N'Guigmi", "N'Guimi", region),
    region = ifelse(region == "Téra", "Tera", region),
    region = ifelse(region == "Tillabéry", "Tillabery", region),
    region = ifelse(region == "Groumdji", "Guidan-Roumdji", region),
    region = ifelse(region == "Mirriah", "Miria", region),
    region = ifelse(region == "Tanout", "Tannout", region),
    region = ifelse(region == "Tchighozerine", "Tchirozerine", region),
    region = ifelse(region == "Tchin-Tabarade", "Tchin-Tabaraden", region)
  ) %>%
  arrange(region)

# Subset measles data to districts present in shapefile, i.e. remove cities
niger_measles_inspace <- niger_measles %>%
  filter(region != "Agadez (City)") %>%
  filter(region != "Maradi (City)") %>%
  filter(region != "Zinder (City)") %>%
  mutate(region = ifelse(region == "Niamey (City)", "Niamey", region)) %>%
  arrange(region) %>%
  filter(region %in% unique(region_boundaries$region))

# Subset spatial data to regions that are present in the incidence data
region_boundaries <- region_boundaries %>%
  filter(region %in% unique(niger_measles_inspace$region))


# Plot Niger with district boundaries
ggplot(region_boundaries)+
  geom_sf(fill = NA) +  # requires development version of ggplot2 from Github
  labs(x = "Longitude", y = "Latitude")

# Calculate neighbor weights
regions_nb <- poly2nb(sf::as_Spatial(region_boundaries$geom))
nblist <- nb2listw(regions_nb)

# Calculate Moran's I across districs for each week
all_weeks <- unique(niger_measles_inspace$date)
morans_over_time <- {}  # empty object for storage

for(i in 1:length(all_weeks)){
  cases <- niger_measles_inspace %>%
    filter(date == all_weeks[i]) %>%
    pull(cases)
  
  morans_now <- moran(
    x = cases, 
    listw = nblist, 
    n = length(regions_nb), 
    S0 = Szero(nblist), 
    zero.policy = TRUE, 
    NAOK = TRUE
  )
  
  tmpdf <- tibble(
    date = all_weeks[i],
    morans_i = morans_now$I,
    morans_k = morans_now$K
  )
  
  morans_over_time <- bind_rows(
    morans_over_time,
    tmpdf
  )
}

morans_over_time <- morans_over_time %>%
  mutate(
    runmean_two_year = zoo::rollmean(morans_i, k = 104, align = "right", fill = NA)
  )


date_of_max_cases <- niger_measles_inspace %>%
  group_by(date) %>%
  summarise(total_cases = sum(cases, na.rm = TRUE)) %>%
  filter(total_cases == max(total_cases)) %>%
  pull(date)

ggplot(morans_over_time, aes(x = date, y = runmean_two_year)) +
  geom_line(aes(y = morans_i), color = "steelblue", alpha = 0.25) +
  geom_line(color = "steelblue", size = 1) +
  geom_vline(aes(xintercept = date_of_max_cases), color = "coral", size = 1) +
  labs(x = "Date", y = expression(paste("Moran's ", italic(I))))

```

Now we need to calculate Kendall's $\tau$ to look at within-epidemic year correlations between Moran's *I* and time.
This first requires defining "epidemic year," which I will as October to September (see figure below).

```{r epi-years}
total_cases_inspace <- niger_measles_inspace %>%
  group_by(date) %>%
  summarise(total_cases = sum(cases, na.rm = TRUE))

epi_starts <- ymd(paste0(as.character(seq(1995,2005)), "1001"))

ggplot()+
  geom_line(data = total_cases_inspace, aes(x = date, y = total_cases)) +
  geom_vline(aes(xintercept = epi_starts), linetype = 2, color = "grey")

total_cases_inspace <- total_cases_inspace %>%
  mutate(
    epidemic_year = year(date),
    epidemic_year = ifelse(month(date) >= 10, epidemic_year+1, epidemic_year)
  ) %>%
  group_by(epidemic_year) %>%
  mutate(epidemic_week = seq(1:n()))

epidemic_timings <- total_cases_inspace %>%
  dplyr::select(date, epidemic_year, epidemic_week)
```




```{r ews-space, fig.height=4, fig.width=5, eval=FALSE, echo=FALSE}
# Calculate spatial variance and skewness at each time point
spatial_var <- niger_measles %>%
  group_by(date) %>%
  # mutate(cases = scale(cases)) %>%
  summarise(
    var_cases = var(cases, na.rm = TRUE),  # rm NAs == ignore missing reports
    skew_cases = skewness(cases, na.rm = TRUE),  # rm NAs == ignore missing reports
    w_ind = var_cases + skew_cases  # composite index, following Drake and Griffen 2010, Nature
  ) %>% 
  left_join(national_data)


# Calculate time-varying standardized deviations
spatial_var_2004 <- spatial_var %>%
  filter(year(date) >= 2003 & year(date) < 2005) %>%
  filter(date > ymd("20031001"))

# spatial_var_2004 <- spatial_var %>%
#   filter(year(date) >= 1997 & year(date) < 1999) %>%
#   filter(date > ymd("19971001"))

all_times <- spatial_var_2004$date
indicator_df <- {}

for(do_time in all_times){
  tmp_df <- spatial_var_2004 %>%
    filter(date <= do_time)
  
  xnow <- tmp_df %>%
    filter(date == do_time) %>%
    pull(w_ind)
  
  xmean <- mean(tmp_df$w_ind)
  xsd <- sd(tmp_df$w_ind)
  
  if(do_time == min(all_dates))
  outdf <- tibble(
    date = do_time,
    w = (xnow - xmean) / xsd,
    rollmu = NA,
    rollsigma = NA
  )
  
  if(do_time > min(all_dates))
  outdf <- tibble(
    date = do_time,
    w = (xnow - xmean) / xsd,
    rollmu = mean(indicator_df$w, na.rm = TRUE),
    rollsigma = sd(indicator_df$w, na.rm = TRUE)
  )
  
  indicator_df <- rbind(indicator_df, outdf)
}

indicator_df <- indicator_df %>%
  mutate(
    date = all_times
  )

ggplot(indicator_df) +
  geom_point(aes(x = date, y = w), size = 2, color = "steelblue") +
  geom_line(aes(x = date, y = rollmu), color = "coral") +
  geom_line(aes(x = date, y = rollsigma+rollmu), linetype = 2, color = "coral") +
  geom_line(aes(x = date, y = 2*rollsigma+rollmu), linetype = 3, color = "coral") +
  labs(x = "Date", y = expression(paste("Spatial early warning index (", italic(w),")"))) +
  annotate(geom = "text", x = max(all_times)+10, y = 0.5, label = expression(bar(italic(w)))) +
  annotate(geom = "text", x = max(all_times)+14, y = 1.9, label = expression(paste("+", sigma))) +
  annotate(geom = "text", x = max(all_times)+20, y = 3.3, label = expression(paste("+2", sigma))) +
  theme_minimal(base_size = 13)

```
