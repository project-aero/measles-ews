---
title: "Anticipating disease emergence and elimination: a test of early warning signals using empirically based models"
author:
  - name: "Andrew T. Tredennick"
    affiliation: UGA,CEID
    footnote: "Current address: Western EcoSystems Technology, Inc., 200 S. Second Street, Laramie, WY 82070, USA"
    email: atredenn@gmail.com
  - name: "Eamon B. O'Dea"
    affiliation: UGA,CEID
  - name: "TBD"
    affiliation: other
  - name: "Pejman Rohani"
    affiliation: UGA,CEID,ID
  - name: "John M. Drake"
    affiliation: UGA,CEID
    email: jdrake@uga.edu
address:
  - code: UGA
    address: "Odum School of Ecology, University of Georgia, Athens, GA 30602, USA"
  - code: CEID
    address: "Center for the Ecology of Infectious Diseases, University of Georgia, Athens, GA 30602, USA"
  - code: other
    address: "A University of Somewhere"
  - code: ID
    address: "Department of Infectious Diseases, University of Georgia, Athens, GA 30602, USA"
abstract: |
  Forecasts of the emergence, re-emergence, and elimination of human infectious diseases would allow for proactive, rather than reactive, decisions that could save lives. Recent theory suggests that a generic feature of dynamical systems approaching a tipping point -- critical slowing down -- can anticipate disease emergence and elimination. Empirical demonstrations of critical slowing down in real disease dynamics are scarce, but are essential before we can implement model-independent outbreak detection systems. Here, we use empirically-based, mechanistic models of measles transmission in four Nigerien cities to detect critical slowing down through statistical early warning signals. We find that several early warning signals accurately anticipate measles re-emergence and elimination, suggesting that critical slowing down can be detected before tipping points in real disease dynamics. Broadly, our findings suggest that early warning signals, coupled with decision-support algorithms and expert judgment, could provide the basis for outbreak early detection systems.
keywords:
  - critical slowing down,
  - early warning signals,
  - epidemiology,
  - measles,
  - infectious disease
bibliography: ./measles-ews.bib
date: "`r Sys.Date()`"
csl: proceedings-of-the-royal-society-b.csl
output: rticles::elsevier_article
layout: 3p # review # review = doublespace, 3p = singlespace, 5p = two-column
preamble: |
  \journal{Proceedings of the Royal Society B}
  \usepackage{lineno}
  \linenumbers
  \usepackage{mathptmx}
  \renewcommand{\theaffn}{\arabic{affn}}
  \usepackage{setspace}
  \onehalfspacing
  \usepackage[nomarkers]{endfloat}
  \usepackage{xcolor}
  \newcommand{\comment}[1]{\ignorespaces}
extra: \usepackage[nomarkers]{endfloat}
---

```{r libraries, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, cache = FALSE)
library(tidyverse)
library(ggthemes)
library(viridis)
library(ggrepel)
library(cowplot)
library(pomp)
library(sf)
```

```{r load-data, include = FALSE}
## Fig 1A
region_boundaries <- st_read("../data/spatial-data/NER_adm2.shp")
mycoords <- as_tibble(st_coordinates(region_boundaries)) %>%
  group_by(L3) %>%
  summarise(minx = min(X)) %>%
  mutate(
    NAME_2 = region_boundaries$NAME_2
  )

region_boundaries <- region_boundaries %>%
  left_join(mycoords)

my_cities <- tibble(
  city = c("Agadez", "Maradi", "Niamey", "Zinder"),
  lat = c(16.9, 13.5, 13.5, 13.8),
  lon = c(8.0, 7.1, 2.1, 8.98),
  population = c("(118,244)", "(267,249)", "(1,027,000)", "(322,935)")
) %>%
  mutate(
    label = paste(city, population, sep = "\n")
  )

## Fig 1B
measles_file <- "../data/clean-data/weekly-measles-incidence-niger-cities-clean.RDS"
measles_data <- readRDS(measles_file) %>%
  filter(year > 1994) %>%
  dplyr::select(-year, -week_of_year, -obs_week, -time) %>%
  mutate(
    region = str_sub(region, 1, str_length(region)-7)  # remove (City) from name
  )
pred_ids <- grep("predictive-dist-states", list.files("../results/"))
pred_files <- list.files("../results/")[pred_ids]
pred_cases <- tibble()
for(do_file in pred_files){
  do_city <- str_split(do_file, "-")[[1]][4]
  do_city <- str_split(do_city, "[.]")[[1]][1]
  
  tmp_data <- measles_data %>%
    filter(region == do_city)
  
  tmp <- readRDS(paste0("../results/", do_file)) %>%
    slice(2:n()) %>%  # drop first row of unobserved data
    mutate(
      upper_est = mean_cases + sdev_cases*2,
      lower_est = mean_cases - sdev_cases*2,
      lower_est = ifelse(lower_est < 0, 0, lower_est),
      city_name = do_city,
      date = tmp_data$date,
      observed_cases = tmp_data$cases
    )
  pred_cases <- bind_rows(pred_cases, tmp)
}
```


# Introduction

Forecasts of the emergence and re-emergence of infectious diseases have the potential to save lives, money, and human productivity by allowing for proactive, rather than reactive, preparedness measures [@Han2016].
Similarly, indicators of the elimination of infectious diseases can signal the effectiveness of ``end game'' strategies aimed at disease eradication [@Drake2017].
Predicting (re)emergence and elimination is possible with complex mathematical models of disease transmission, but their success relies on detailed understanding of the underlying transmission dynamics and adequate data [@Metcalf2017].
We often do not have enough information (or time) to parameterize such models.
An alternative approach is to use model-independent statistical signals that portend infectious disease (re)emergence and elimination by detecting critical slowing down as the system approaches a critical transition [@ORegan2013].

Emergence and elimination of an infectious disease both involve a critical transition (technically, a *transcritical bifurcation*).
The transition typically occurs at the critical point where the basic reproduction number ($R_0$, the number of secondary cases that arise from a single infected case in a fully susceptible population) is equal to one [@Heffernan2005].
Thus, subcritical ($R_0 < 1$) and supercritical ($R_0 > 1$) systems represent alternative modes of fluctuation [@Scheffer2009; @Scheffer2012; @ORegan2013].

Critical transitions in stochastic systems, such as systems of disease transmission, are often associated with critical slowing down, a reduction in the resilience of a system to perturbations [@Wissel1984; @VanNes2007].
Critical slowing down (CSD), in turn, is associated with changes in the dynamical features of the system: early warning signals (EWS) such as an increase in the variance and autocorrelation [@Carpenter2006; @Scheffer2009].
Recent theoretical work suggests that CSD occurs as disease dynamics approach $R_0 = 1$ from below (emergence) [@ORegan2013; @Dibble2016] and from above (elimination) [@ORegan2013; @ORegan2016; @Drake2017], and that several EWS anticipate the critical transition [@Brett2017; @Brett2018; @Miller2017].
These findings suggest that early warning signals could be operationalized to develop early warning systems of disease emergence and elimination, or outbreaks of endemic diseases.

However, operationalizing EWS, and deploying early warning systems based on them, faces many challenges [@Boettiger2013; @Han2016].
For example, using EWS in an "online mode" requires choosing temporal windows over which EWS are calculated.
These moving windows should be long enough to provide reliable statistics, but short enough to forget the past so as to not overwhelm information contained in new observations.
This will be especially important for diseases that fluctuate seasonally, where EWS might always increase and then decrease over the course of the year, requiring the end-user to reset computations each season.
Another challenge is defining thresholds for detection of an upcoming tipping point.
Detection thresholds can be based on the absolute value of an EWS (e.g., warning if variance exceeds some value), the trend in an EWS over time (e.g., warning if the correlation of variance with time exceeds some value), or an algorithmic combination of many factors (e.g., variance and autocorrelation increases above some value three observation periods in a row).
Developing (semi)objective algorithms for combining EWS, their values, and their trends to best detect disease emergence and elimination is a surmountable task, but one that will take considerable research effort.

Given the amount of research still required to operationalize EWS, it is imperative that we stress test the hypothesis that EWS anticipate critical transitions before we allocate time and resources to the task of deploying early warning systems.
One way to stress test EWS is through empirical case studies: Can EWS anticipate emergence and elimination in real disease time series?
However, uncritical application of EWS to observed data could lead to researchers getting the right answer for the wrong reasons.
EWS might perform well for a given time series, but for reasons having nothing to do with critical slowing down.
Likewise, critical transitions may occur in the absence of early warning signals [@Boettiger2012a].
Indeed, without known the critical point (i.e., when $R_0(t) = 1$) it is impossible to know if EWS are in fact sending us the signal we think they are.

Another option is to use empirically based models of disease transmission to test EWS.
This offers several advantages.
First, using a model to simulate time series of cases means we also have access to a time series of $R_0(t)$, which allows us to know precisely when the critical transition occurs.
This means we know whether we are getting the right answer for the right reason.
Second, we can simulate replicate time series to account for the inherent stochasticity of disease transmission.
This means our conclusions are not based on one-off events that bias conclusions [@Boettiger2012].
Third, we can specifically simulate emergence and elimination events.
This means we can separate the stress testing of EWS from the research necessary to operationalize EWS.
Thus, we have all the flexibility of a theoretical model, but we remain tethered to reality because the model parameters are fitted to real data.

Here, we use empirically based model simulations of measles dynamics to test whether CSD anticipates critical transitions in real disease dynamics.
We focus on two scenarios: the re-emergence of measles following a large outbreak, a situation typical of measles dynamics in sub-Saharan Africa [@Ferrari2008], and the elimination of measles by a vaccination campaign.
We seek to answer two related questions.
First, can CSD distinguish between time series of disease incidence when the underlying dynamics are far from and near to a critical transition?
If so, then CSD can anticipate disease re-emergence and elimination.
Second, how does the distance to and the rate of approaching the threshold impact the anticipatory skill of CSD?

To answer these questions, we fit mechanistic models of disease transmission to time series of measles incidence in four Nigerien cities [@Ferrari2008; @Bharti2011].
We then use the fitted models to perform model experiments designed to test the performance of several EWS, which quantify CSD, at anticipating re-emergence and elimination.
Our results confirm theoretical expectations about several EWS and associated CSD.
In particular, we show that CSD before a critical transition is detectable by several EWS in realistic scenarios, and they do so using much shorter time series than used in theoretical studies.
However, our study highlights the limitations of EWS in situations where disease re-emergence and elimination occurs rapidly.
Moreoever, and contrary to theoretical expectations [@ORegan2013], we find that EWS perform better at detecting CSD before re-emergence than before elimination.

\comment{I don't believe @ORegan2013 created theoretical expectations
in that regard, as John and I have agreed that the emergence
simulations did not provide a fair comparison with the elimination
simulations because the fraction of susceptibles changed very little
in the emergence simulations.}

# Materials and methods

## Data
We used weekly measles case report data from four Nigerien cities: Agadez, Maradi, Niamey, and Zinder (figure \ref{data-plot}*a*).
The data were collected over an 11 year period from 1995-2005 (figure \ref{data-plot}*b*).
These data are ideal for testing theory on CSD in disease dynamics because each city has different population sizes, has different dynamics in terms of outbreak sizes and length of inter-epidemic periods, and each time series has different amounts of demographic stochasticity due to differences in population size.
Such differences provide a natural gradient of "noise" that may influence CSD [@Hastings2010; @Dakos2012a; @ODea2018a; @ORegan2018].
The data are provided by the Niger Ministry of Health [@NigerMinistryofHealth2008].

```{r data-plot, fig.width=8.5, fig.height=4, fig.cap="Locations of data sources and observed and predicted measles dynamics. (*a*) Locations and population sizes (in parantheses) of our four focal cities in Niger. (*b*) Time series of weekly reported cases (yellow solid lines) and the 95% prediction intervals (black ribbons) for one-week-ahead predictions from our fitted SEIR models for each city. \\label{data-plot}"}

the_map <- ggplot(region_boundaries)+
  geom_sf(fill = "grey90", col = "grey80", size = 0.3) +
  geom_point(data = my_cities, aes(x = lon, y = lat), size = 2) +
  geom_label_repel(
    data = my_cities,
    aes(x = lon, y = lat, label = label),
    box.padding   = 0.35, 
    point.padding = 0.3,
    size = 2,
    family = "Times"
  ) + 
  annotate("text", x = 12, y = 20, label = "Niger", fontface = 3, size = 5, family = "Times") +
  labs(x = "longitude", y = "latitude") +
  theme_minimal(base_family = "Times")

the_series <- ggplot(pred_cases, aes(x = date)) +
  geom_ribbon(aes(ymin = lower_est, ymax = upper_est), color = "black") +
  geom_line(aes(y = observed_cases), color = ptol_pal()(3)[2], size = 0.4) +
  facet_wrap(~city_name, scales = "free_y", ncol = 1) +
  labs(x = "date", y = "reported cases") +
  theme_minimal(base_family = "Times")

plot_grid(the_map, the_series, ncol = 2, labels = c("(a)", "(b)"), 
          label_size = 12, label_fontfamily = "Times", label_fontface = 3)
```

## Stochastic *SEIR* model
The model is a discrete-time approximation of a continuous-time SEIR model with limited demography, specified as a set of difference equations,

\begin{align}
S_{t+dt} - S_t &= n_{S,t} - n_{E,t} \\
E_{t+dt} - E_t &= n_{E,t} - n_{I,t} \\
I_{t+dt} - I_t &= n_{I,t} + n_{O,t} - n_{R,t},
\end{align}

\noindent{}where $dt$ is a time step of $\text{year} / 365$, and $\textbf{n}_t$ are random variables representing the number of individuals transitioning into or out of each class at each timestep $t \rightarrow t+dt$.
$n_{S}$ is the number of births, $n_{E}$ is the number of newly infected individuals that have the disease but are not infectious, $n_{I}$ is the number of newly infectious indiviuals, $n_{O}$ is the number of imported infections, and $n_{R}$ is the number of newly recovered individuals who are no longer infectious and have life-long immunity.
The stochastic random variables are specified as follows:

\begin{align}
n_{S,t} &\sim \text{Poisson}(\mu_t (1 - p) N_t \times dt) \\
n_{E,t} &\sim \text{Binomial}( S_{t}, \lambda_{E,t}) \\
n_{I,t} &\sim \text{Binomial}( E_{t}, \lambda_{I,t}) \\
n_{O,t} &\sim \text{Poisson}(\psi \times dt) \\
n_{R,t} &\sim \text{Binomial}( I_{t}, \lambda_{R,t}),
\end{align}

\noindent{}where $\mu_t$ is the birth rate at time *t*, $p$ is the vaccination rate, $\psi$ is the rate of imported infections, and $\lambda_E$, $\lambda_I$, and $\lambda_R$ are the probabilities of exposure, becoming infectious, and recovery, respectively.
These probabilities reflect the processes of transmission, transition from the latent period to the infectious period, and recovery, which we model as:

\begin{align}
\lambda_{E,t} &= 1 - e^{-\frac{\beta_t I_t dt}{N_t}} \\
\lambda_{I,t} &= 1 - e^{-\eta E_{t} dt} \\
\lambda_{R,t} &= 1 - e^{-\gamma I_{t} dt},
\end{align}

\noindent{}where $\beta_t$ is a time-varying rate of transmission, $\eta$ is a time-invariant rate of progression from the exposed class to the infectious class, and $\gamma$ is a time-invariant recovery rate.
We model the rate of transmission as,

\begin{equation}
\beta_t = \beta \left(1 + \exp \left( \sum^6_{i=1} q_i \xi_{i_{t}} \right) \right) \Gamma_t,
\end{equation}

\comment{I have corrected the above equation to match code/make-pomp-filtering-functions.R and code/make-pomp-simulation-functions.R}
\noindent{} where $\beta$ is the minimum transmission rate over the season, and the term $\sum^6_{i=1} q_i \xi_{i_{t}}$ is a B-spline to model seasonality in transmission.
The B-spline bases ($\xi_{i_{t}}$) are periodic with a 1 year period.
The transmission rate ($\beta_t$) is also subject to stochastic process noise at each time step, $\Gamma_t$, which we model as gamma-distributed white (temporally uncorrelated) noise with mean 1 and intensity $\sigma^2$ [@Breto2011].

We do not include death events in the model because the rate of infection is much faster than the rate of death.
Excluding deaths means we can avoid making further assumptions about demographic rates -- we are already making assumptions about birth rates (e.g., the rate is the same across cities, but with city-specific population size).
We model demographic stochasticity in births and imported infections by drawing time-specific values from Poisson distributions.
In this model, the effective reproduction number at time $t$ may be approximated as: $R_E(t) \approx \frac{\beta_t}{\gamma} \frac{S_t}{N_t}$.

We assume observed case reports ($y_t$) are drawn from a negative binomial distribution subject to a constant reporting fraction ($\rho$) and dispersion parameter $\tau$,

\begin{align}
y_t \sim \text{Negative Binomial} \left( \rho x_t, \tau \right),
\end{align}

\noindent{}where $x_t$ are the accumulated cases that transition from the infected class to the recovered class in a one week period.

##  Model fitting and inference

We fit the SEIR model to time series of case reports from each of our focal cities using Maximization by Iterated particle Filtering (MIF).
We estimated 14 parameters for each city: six seasonal transmission parameters ($q_i$), mean transmission rate ($\beta$), three initial conditions $\left(S_{(t=0)},E_{(t=0)},I_{(t=0)}\right)$, the number of imported infections ($\psi$), reporting fraction ($\rho$), one parameter accounting for process noise ($\sigma$), and one parameter accounting for measurement noise ($\tau$).
To ensure identifiability, and to make the model easier to fit, we assumed the incubation period was fixed at $1/\eta = 8$ days and the infectious period was fixed at $1/\gamma = 5$ days.
The vaccination rate ($p$) was set to 70\%, consistent with reported vaccination coverage [@Ferrari2008].

MIF relies on particle filtering, which estimates the likelihood of fixed parameters by integrating state variables of a stochastic system.
To narrow in on the maximum likelihood estimates, MIF lets parameters take a random walk during the filtering process and selectively propagates forward parameter sets (i.e., particles) with the highest likelihood.
The variance of the random walk decreases at each iteration of MIF, where a MIF iteration means one filtering pass through the time series.
This procedure converges toward the maximimum likelihood estimates (MLEs), in theory.

We used the IF2 algorithm [@Ionides2015] implemented in the R [@R2017] package `pomp` version 1.18 [@King2016; @King2018] to conduct the MIF procedure.
To initialize MIF, we generated 5000 parameter sets using Latin Hypercube Sampling over large ranges of the parameter values.
We then performed two rounds of MIF, each for 100 iterations, with 10,000 particles, and geometric cooling.
For the first round of MIF we set `cooling.factor = 1`.
For the second round, which was initialized using the collection of parameter sets from the end of the first round, we set `cooling.factor = 0.9`.
We computed the log likelihood of 5000 final MIF parameter sets (i.e., parameter sets collected after 200 MIF iterations) as the log of the mean likelihoods of 50 replicate particle filters with 10,000 particles each.
At this stage, we assume the parameter set with highest log likelihood is the MLE.

We used a bootstrapping approach to estimate approximate 95\% confidence intervals for all parameters.
The procedure, which was conducted for each city independently, is as follows.
First, we simulated 100 realizations from the fitted model using the MLE parameters.
Second, we fitted the SEIR model to each of the 100 bootstrap simulations using the same MIF procedure described above, except we initiated the parameter search from 50 parameter sets rather then 5000.
We reduced the number of parameter sets due to the computational constraints of fitting 100 simulated data sets for each of the four cities.
Third, we identified the MLE parameter set for each of the 100 bootstrap simulations from among the 50 MIF paramete sets.
Last, we calculated summary statistics (mean, median, quantiles) from the distribution of 100 MLE parameters (SI text).

## Model assessment
We used the MLE parameter sets to make one-week-ahead predictions and compared observed and expected case counts.
To make one-week-ahead predictions, we used particle filtering with 50,000 particles and retained the mean and standard deviation of all latent states across all particles before they were filtered at each time step.
We used the mean predictions ($\mathbb{E}(\text{cases}_t)$) to assess model fit using a generalized coefficient of determination, calculated as: $R^2 = 1 - \frac{\sum_t [\mathbb{E}(\text{cases}_t) - \text{cases}_t]^2}{\sum_t [\text{mean(cases)}-\text{cases}_t]^2}$ [@Martinez-Bakker2015].
In addition to comparing model expectations to in-sample observed data, we also compared our fitted SEIR models to two benchmarking models: a negative binomial sampling model that assumes independent and identically distributed observations and a SARIMA model (SI text).
We fit the benchmarking models to the observed data and then compared models using Akaike's Information Criterion (AIC) to account for differences in the number of model parameters [@Akaike1973].

## Simulating re-emergence
To simulate re-emergence of measles, we manipulated the initial size of the susceptible pool to simulate an increase from low $R_E(t)$ to high $R_E(t)$.
Doing so allows us to test whether EWS can distinguish between windows of time when $R_E(t)$ is far from a critical transition and when $R_E(t)$ is near a critical transition.
We reduced the initial fraction of susceptible individuals by multplying the MLE for $S_{(t=0)}$ by six discounting factors: 1e-4, 0.1, 0.2, 0.3, 0.4, and 0.5.
These discounting factors represent situations of susceptible depletion after outbreaks of various size.
After defining $S_{(t=0)}$ based on the discounting factor, we then set the initial number of recovered individuals to $R_{(t=0)} = N - S_{(t=0)}$ and set the initial number of exposed and infected individuals to zero.
Population size, *N*, was set to the mean population size for each city over the 1995-2005 time period.
We then simulated the model forward for forty years using mean birth rate for the entire country ($\mu = 0.05$) and setting the death rate equal to the birth rate ($\mu = \nu = 0.05$) to achieve a constant equilibrium total population size over the course of the simulation (total population size does vary, though, because of stochasticity in the model).
Forty years was long enough for $R_E(t)$ to reach or exceed 1 for each city.
Because the model is stochastic, we repeated these simulations 500 times for each city--susceptible-discount combination.

Next, we split each simulated time series into null and test intervals.
First, averaging across all simulations for a city-susceptible discount combination, we found the simulation year in which $R_E(t)$ reaches or exceeds 1 and excluded years past that year (SI text).
We split the remaining time series into two windows of equal length (figure \ref{emerge-aucs}*a*).
The null interval is the first window, where $R_E(t)$ is increasing but far from 1.
The test interval is the second window, where $R_E(t)$ is increasing and approaching 1.
We did this for each city and for each level of susceptible depletion.
We calculated EWS over null and test intervals separately.

## Simulating elimination
To simulate elimination, we simulated a vaccine campaign in which vaccination coverage linearly increased over time to eventually reach 100\%, i.e. eradication (figure S3).
We ran simulations for 100 years, starting with 50 years of dynamics at the baseline vaccine coverage reported for Niger of 70\%, $p = 0.7$ [@Ferrari2008].
Note that vaccination coverage is included in our model by discounting the birth rate of susceptibles by $1-p$.
At year 50, we initiated the vaccination campaign and let the model run for another 50 years.
We ran simulations across six vaccination ``speeds'' (the rate at which $p \rightarrow 1$; SI text), simulating situations of slow and fast approaches to elimination.
As in the re-emergence simulations, we set the birth rate equal to the death rate to achieve a constant equilibrium population size. 

We then split each time series into null and test intervals for calculating EWS.
We define the test interval as the window of time between the start of the vaccination campaign (year 50) and the time at which vaccination coverage reached the vaccination threshold of $1 - 1/R_0$ (figure \ref{elim-aucs}*a*).
$R_0$ was calculated for each city using the MLE parameters as: $R_0 = \left[\eta \beta \right]/ \left[\left(\eta+\nu\right)\left(\gamma+\nu\right)\right]$, where $\beta$ is the maximum seasonal transmission rate.
We define the null interval as the window of time that ends at the start of the vaccination campaign (year 49) and starts at a time that results in an interval equal in length the test interval (figure \ref{elim-aucs}*a*).
EWS were then calculated for each interval.

## Calculating early warning signals
We considered nine candidate early warning signals (Table S1).
We used the `spaero::get_stats()` function [@ODea2018] in R [@R2017] to calculate EWS according to the formulas in Table S1.
All EWS except the coefficient of variation are expected to increase as $R_E(t)$ approaches 1 from below [@ORegan2013; @ORegan2016; @Brett2018].
Less is known about the behavior of EWS as $R_E(t)$ approaches 1 from above.
But, theory does tell us that, for SIR models, the mean should decrease, autocorrelation at a fixed lag can either increase or decrease, and the variance should decrease [@ORegan2013].

For each simulation of re-emergence and elimination, we calculated EWS for the time series of expected cases in the null and test intervals.
This yielded a distribution of EWS over the 500 null and test intervals.
We assessed the performance of each EWS using the Area Under the Curve (AUC) statistic.
Specifically, we use AUC to calculate the amount of overlap between the distributions of each EWS from the null and test intervals.
Values of AUC far from 0.5 (i.e., close to 0 or 1) indicate a greater degree of separation and thus better performance of a particular EWS in terms of classifying whether $R_E(t)$ is close to a critical transition.
We calculated AUC as: $\text{AUC} = \left[r_{\text{test}} - n_\text{test} \left(n_{\text{test}}+1\right)/2\right] / \left(n_{\text{test}}n_{\text{null}}\right)$ where $r_{\text{test}}$ is the sum of the ranks of test set EWS statistics in a combined set of null and test statistics (lower numbers have lower ranks), $n_{\text{test}}$ is the number of test of statistics and $n_{\text{null}}$ is the number of null statistics.
The AUC of an EWS is the probability that a randomly chosen EWS value from the test set is higher than an EWS value randomly chosen from the null set [@Fawcett2006].
Therefore, AUC should be high (closer to 1) when an EWS is expected to increase as a critical transition is approached, whereas AUC should be low (closer to 0) when an EWS is expected to decrease.


```{r scatters-r0, fig.width=8.5, fig.height=4, fig.cap="Accuracy of the fitted *SEIR* models and estimated seasonality. (*a*) Comparison of in-sample model predictions and observations for each city. Expected cases are one-week-ahead predictions from the fitted models. The dashed line shows 1:1. Coefficients of determination ($R^2$) were calculated as the reduction in the sum-of-squared errors from model predictions relative to a null model of the mean number of cases (Methods). (*b*) The estimated seasonality of the basic reproductive ratio ($R_0$) for each city. $R_0$ was calculated as: $\\frac{\\eta \\beta_t}{(\\eta+\\nu)(\\gamma+\\nu)}$, where $1/\\eta$ is the incubation period, $1/\\gamma$ is the infectious period, $\\beta_t$ is the time-specific rate of transmission, and $\\nu$ is the death rate. Only $\\beta_t$ is estimated by our model. We set $1/\\eta$ = 8 days, $1/\\gamma$ = 5 days, and $\\mu = \\nu$ = 0.05 for calculating $R_0$ as shown in this figure. The white line is $R_0$ calculated using the MLE parameters; shaded regions are the bootstrapped 95% confidence intervals. \\label{scatters}"}
r_squares <- pred_cases %>%
  group_by(city_name) %>%
  mutate(
    mean_observations = mean(observed_cases),
    error_numer = (mean_cases - observed_cases)^2,
    error_denom = (mean_observations - observed_cases)^2
  ) %>%
  summarise(
    summed_numer = sum(error_numer),
    summed_denom = sum(error_denom)
  ) %>%
  mutate(
    R2 = 1 - (summed_numer / summed_denom)
  ) %>%
  dplyr::select(city_name, R2)

scatters <- ggplot(pred_cases, aes(x = log(observed_cases+1), y = log(mean_cases+1))) +
  geom_point(aes(color = city_name), size = 1, alpha = 0.3) +
  geom_abline(aes(intercept = 0, slope = 1), linetype = 2) +
  geom_label(data = r_squares, 
             aes(x = 1.7, y = 7.3, label = paste0("italic(R)^2 == ", 
                                                  round(R2,2))), 
             label.size = NA, parse = TRUE, size = 3, family = "Times") +
  labs(y = "expected log(cases + 1)", x = "observed log(cases + 1)") +
  facet_wrap(~city_name, nrow = 2, scales = "free") +
  scale_y_continuous(limits = c(0,8)) +
  scale_x_continuous(limits = c(0,8)) +
  scale_color_colorblind()+
  guides(color = FALSE)+
  theme_classic(base_size = 10, base_family = "Times") +
  theme(panel.spacing = unit(1, "lines"), strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
        plot.title = element_text(face = "bold")) 
  # ggtitle("Model-data agreement")

calc_R0 <- function(beta = NULL, B = NULL, qis = NULL, season = NULL, 
                    eta = (365/8), nu = 0.05, gamma = (365/5)){
  if(is.null(beta)){
    R0 <- (eta*B) / ((eta + nu)*(gamma + nu))
  } else{
    B <- as.numeric((1 + exp(season %*% qis)) * beta)
    R0 <- (eta*B) / ((eta + nu)*(gamma + nu))
  }
  return(R0)
}

# Define computation grid for bootstraps

nboots <- 100
nmifs <- 50
comp_grid <- expand.grid(1:nboots, 1:50)
colnames(comp_grid) <- c("boot_series", "param_set")
comp_grid$do_grid <- 1:nrow(comp_grid)

# Load example pomp file for basis function
pomp_file <- "../code/measles-pomp-object-Agadez.RDS"
measles_pomp <- readRDS(pomp_file)  # exemplar bases

bases <- as_tibble(measles_pomp@covar) %>%
  dplyr::select(starts_with("x")) %>%
  dplyr::slice(1:365) %>%
  mutate(
    day = 1:365
  ) %>%
  gather(key = base, value = value, -day)

season <- bases %>%
  spread(key = base, value = value) %>%
  dplyr::select(-day) %>%
  as.matrix()

seasonal_functions <- tibble()
for(do_city in c("Agadez", "Maradi", "Niamey", "Zinder")){
  boots <- read.csv(paste0("../results/bootstrap-mif-lls-", do_city, ".csv"))
  
  b_splines <- boots %>%
    slice(2:n()) %>%  # ignore first row of NAs
    left_join(comp_grid, by = "do_grid") %>%  # merge in comp grid info
    group_by(boot_series) %>%
    filter(loglik == max(loglik)) %>%
    ungroup() %>%
    dplyr::select(b1, b2, b3, b4, b5, b6)
  
  betas <- boots %>%
    slice(2:n()) %>%  # ignore first row of NAs
    left_join(comp_grid, by = "do_grid") %>%  # merge in comp grid info
    group_by(boot_series) %>%
    filter(loglik == max(loglik)) %>%
    ungroup() %>%
    dplyr::select(beta_mu)
  
  seasonal_betas <- tibble()
  for(i in 1:nrow(b_splines)){
    qis <- as.numeric(b_splines[i, ])
    beta_tmp <- as.numeric(betas[i, "beta_mu"])
    
    seasonal_tmp <- tibble(
      beta = as.numeric((1+exp(season %*% qis)) * beta_tmp),
      day = 1:365,
      boot = i
    )
    seasonal_betas <- bind_rows(seasonal_betas, seasonal_tmp)
  }  # end bootstrap loop
  
  seasonal_betas <- seasonal_betas %>%
    mutate(
      city = do_city,
      rnaught = calc_R0(B = beta)
    ) %>%
    group_by(city, day) %>%
    summarise(
      upper_R0 = quantile(rnaught, 0.975),
      lower_R0 = quantile(rnaught, 0.025)
    ) %>%
    ungroup()
  
  seasonal_functions <- bind_rows(seasonal_functions, seasonal_betas)
  
}  # end city loop

seasonal_functions <- seasonal_functions %>%
  mutate(
    date = as.Date(day, origin = "2016-12-31",tz = "UTC")
  )

# Calculate MLE R0 curves for each city

R_0s <- tibble()

for(do_city in c("Agadez", "Maradi", "Niamey", "Zinder")){
  
  # Load fitted parameters and pomp model 
  mle_file <- paste0("../results/initial-mif-lls-", do_city, ".csv")
  
  mles <- read.csv(mle_file) %>% 
    slice(2:n()) %>%  # ignore first row of storage NAs
    filter(loglik == max(loglik, na.rm = TRUE)) %>%
    dplyr::select(-do_grid, -loglik, -loglik_se)
  
  pomp_file <- paste0("../code/measles-pomp-object-", do_city, ".RDS")
  fitted_pomp <- readRDS(pomp_file)
  
  # Calculte R0 
  qis <- mles %>%
    dplyr::select(b1, b2, b3, b4, b5, b6) %>%
    as.numeric()
  
  beta <- mles %>%
    pull(beta_mu)
  
  bases <- as_tibble(fitted_pomp@covar) %>%
    dplyr::select(starts_with("x")) %>%
    dplyr::slice(1:365) %>%
    mutate(
      day = 1:365
    ) %>%
    gather(key = base, value = value, -day)
  
  season <- bases %>%
    spread(key = base, value = value) %>%
    dplyr::select(-day) %>%
    as.matrix()
  
  N <- round(mean(fitted_pomp@covar[, "N"]))
  
  R0 <- calc_R0(beta = beta, qis = qis, season = season)
  
  tmp_out <- tibble(
    city = do_city,
    day = 1:length(R0),
    R0 = R0
  )
  
  R_0s <- bind_rows(R_0s, tmp_out)
}

R_0s <- R_0s %>%
  mutate(
    date = as.Date(day, origin = "2016-12-31",tz = "UTC")
  )

all_R_0s <- left_join(R_0s, seasonal_functions, by = c("city", "day", "date"))

rnaughts <- ggplot(all_R_0s, aes(x = date)) +
  geom_ribbon(aes(ymin = lower_R0, ymax = upper_R0, fill = city), alpha = 0.6) +
  geom_line(aes(y = R0), color = "white") +
  scale_fill_colorblind(name = NULL) +
  scale_color_colorblind(name = NULL) +
  guides(fill = FALSE) +
  facet_wrap(~city,nrow = 2, scales = "free") +
  labs(x = "time of year", y = expression(italic(R[0]))) +
  scale_x_date(date_labels = "%b", date_breaks = "2 months") +
  scale_y_continuous(limits = c(0,35))+
  theme_classic(base_size = 10, base_family = "Times") +
  theme(panel.spacing = unit(1, "lines"), strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
       plot.title = element_text(face = "bold")) 
  # ggtitle("Seasonal basic reproduction number")

plot_grid(scatters, rnaughts, scale = 0.9, labels = c("(a)", "(b)"), 
          label_size = 12, label_fontfamily = "Times", label_fontface = 3)
```


# Results

The fitted models adequately reproduce observed dynamics (figure \ref{data-plot}*b*), with in-sample $R^2$s from one-week-ahead predictions ranging from 0.54 for Agadez to 0.89 for Maradi (figure \ref{scatters}*a*).
The fitted models also had lower AIC values than two benchmarking models (SI table Sx).
Stochastic simulations of the models displayed dynamics typical of each city (figure S1), including the decline in seasonality amplitude as population size decreases (figure \ref{scatters}*b*) [@Ferrari2008].
\comment{Figuer S1 seems to be an incorrect reference. Is this figure still in the works?}
Our model for Agadez performs poorly relative to the other cities, but still better than non-mechanistic models (SI table Sx).
Maximum likelihood estimates and bootstrapped 95% confidence intervals for all parameters are in the SI text (tables Sx-Sz).

The EWS generally perform as expected by theory on the approach to re-emergence.
Most EWS increased as the critical transition is approached, resulting in positive AUC values near 1 (figure \ref{emerge-aucs}).
Skewness, kurtosis, and coefficient of variation performed poorly across all levels of susceptible depletion in all cities.
Thus, these metrics are unreliable.

Variance, mean, index of dispersion, autocovariance, and autocorrelation all perform equally well at predicting re-emergence (figure \ref{emerge-aucs}*c*).
Their performance declines as the amount of susceptible depletion decreases.
This is expected because more rapid returns to $R_E(t)=1$ result in shorter null and test intervals, making estimates of EWS less precise [@Brett2017].
Moreover, as the time to reach $R_E(t)=1$ decreases, the chance of a bifurcation delay increases because of the changing equilibrium of $R_0$ combined with demographic stochasticity [@Dibble2016; @Brett2017].
Thus, re-emergence may prove difficult to anticipate in "fast" transmission systems, as demonstrated theoretically by @Brett2017 and seen here when susceptible depletion was relatively small (figure \ref{emerge-aucs}*c*).

```{r emergence-results, fig.width=8.5, fig.height=5, fig.cap="Performance of early warning signals (EWS) over fixed windows on the approach to emergence. (*a*) A typical example of an emergence simulation for Maradi. The two vertical blue lines indicate the start (left-most line) and end (line for critical year) of the full window. The black line demarcates the division between the equal-length null and test intervals, in which we show the calculated variance. (*b*) Empirical densities of variance in the null and test intervals across 500 simulations and the associated area under the curve (AUC) statistic. (*c*) Heatmap of AUC statistics for each EWS at each level of susceptible discount factor. AUC values closer to 0 or 1 indicate higher ability to distinguish among time series near and far from a critical transition. See Fig. Sx for visualization of how susceptible discounting factor maps to number of weeks in the null and test intervals.  \\label{emerge-aucs}"}
# mycols <- c("#91CDF0", "#EF6677")
mycols <- c("#008FD5", "#FF2700")  # fivethirtyeight blue/red

ex_file <- "../simulations/emergence-simulations-grid-Maradi-1e-04.RDS"
emerge_sim <- readRDS(ex_file)

re_one_year <- emerge_sim %>%
  group_by(time) %>%
  summarise(mean_re = mean(RE_seas)) %>%  
  mutate(year = round(time)) %>%  # create 'year' variable
  ungroup() %>%
  filter(mean_re >= 1) %>%  # drop times where Re less than 1
  filter(year == min(year) + 1) %>%  # filter to critical transition year
  distinct(year, .keep_all = TRUE) %>%  # drop duplicates
  dplyr::select(year) %>%
  ungroup()

re_path <- emerge_sim %>%
  group_by(time) %>%
  summarise(mean_re = mean(RE_seas)) %>%  
  mutate(year = round(time)) %>%  # create 'year' variable
  ungroup()

one_sim <- emerge_sim %>% 
  filter(sim == 1) %>%
  left_join(re_path) %>%
  mutate(used = ifelse(time <= re_one_year$year, "yes", "no")) %>%
  filter(year < 9)

variance_one_sim <- one_sim %>%
  filter(used == "yes") %>%
  mutate(interval = ifelse(time < max(year)/2, "null", "test")) %>%
  group_by(interval) %>%
  summarise(variance = round(var(reports),1))

variance_all_sim <- emerge_sim %>%
  left_join(re_path) %>%
  mutate(used = ifelse(time <= re_one_year$year, "yes", "no")) %>%
  filter(used == "yes") %>%
  mutate(interval = ifelse(time < max(year)/2, "null", "test")) %>%
  group_by(interval, sim) %>%
  summarise(variance = var(reports))

variance_cats <- variance_all_sim %>%
  ungroup() %>%
  mutate(cat = ifelse(interval == "null", TRUE, FALSE)) 

calc_auc <- function(predictions, is_null){
    r <- rank(predictions)
    r1 <- sum(r[!is_null])
    n1 <- sum(!is_null)
    n2 <- sum(is_null)
    (r1 - n1 * (n1 + 1) / 2) / (n1 * n2)
}

var_auc <- round(calc_auc(variance_cats$variance, variance_cats$cat), 3)

# Case time series
ggplot(filter(one_sim, time < 11.5 & time > 0.6), aes(x = time, y = reports)) +
  geom_line(color = "tan", aes(alpha = used)) +
  geom_vline(aes(xintercept = 0.6), color = "dodgerblue4", linetype = 2) +
  geom_vline(aes(xintercept = re_one_year$year), color = "dodgerblue4", 
             linetype = 2) +
  geom_vline(aes(xintercept = 8/2)) +
  annotate(geom = "text", x = 2.35, y = 50, size = 3,
           label = "null interval", fontface = "bold", family = "Times") +
  annotate(geom = "text", x = 6, y = 50, size = 3,
           label = "test interval", fontface = "bold", family = "Times") +
  annotate(geom = "text", x = 2.35, y = 45, size = 3, family = "Times",
           label = paste("variance =", 
                         filter(variance_one_sim, interval == "null") %>%
                           pull(variance))) +
  annotate(geom = "text", x = 6, y = 45, size = 3, family = "Times",
           label = paste("variance =", 
                         filter(variance_one_sim, interval == "test") %>%
                           pull(variance))) +
  scale_alpha_manual(values = c(0.4, 1)) +
  guides(alpha = FALSE) +
  annotate(geom = "text", x = 7.3, y = 25, label = "critical\nyear", 
           size = 3, color = "dodgerblue4", family = "Times") +
  labs(x = "simulation time (year)", y = "reported cases") +
  theme_classic(base_size = 11, base_family = "Times") -> cases_series

# Distribution of variance across simulations
ggplot(variance_all_sim, aes(x = log(variance + 1), fill = interval)) +
  geom_density(size = 0.5, alpha = 0.65, color = "white") +
  annotate(geom = "text", x = 3, y = 1.2, size = 3, family = "Times",
           label = paste("area under the curve:", var_auc)) +
  scale_fill_manual(values = mycols, name = "interval",
                    labels = c("null", "test")) +
  labs(x = "log(variance + 1)", y = "density") +
  coord_cartesian(xlim = c(0, 4)) +
  theme_classic(base_size = 11, base_family = "Times") +
  theme(legend.position = c(0.8, 0.8)) -> dist_plot

# AUC heatmap
emergence_aucs <- read.csv("../results/emergence-grid-aucs.csv") %>%
  filter(metric != "Decay time")

# star_tbl <- tibble(
#   city = "Niamey",
#   x = as.factor(rep(1e-04, 2)),
#   y = c(5.7, 7.7)
# )

emergence_aucs <- emergence_aucs %>%
  mutate(susc_discount = ifelse(susc_discount == 0.0, 1e-04, susc_discount)) %>%
  mutate(metric = tolower(metric))

ggplot() +
  geom_tile(data = emergence_aucs, aes(x = as.factor(susc_discount), y = metric, fill = AUC)) +
  # geom_text(data = star_tbl, aes(x = x, y = y, label = "*"), color = "white", size = 6) +
  scale_fill_viridis(limits = c(0,1), direction = -1, option = "E", name = "AUC") +
  facet_wrap(~city, nrow = 1) +
  labs(x = "proportion of mean susceptibles", y = NULL) +
  theme_minimal(base_family = "Times") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(panel.spacing = unit(1, "lines"),
        strip.text = element_text(face = "bold"),
        plot.title = element_text(size = 11, face = "bold")) -> aucs


row2 <- cowplot::plot_grid(aucs, labels = "(c)", label_size = 12, label_fontfamily = "Times", label_fontface = 3)
row1 <- cowplot::plot_grid(cases_series, dist_plot, scale = 0.9, labels = c("(a)", "(b)"), 
          label_size = 12, label_fontfamily = "Times", label_fontface = 3)
final <- cowplot::plot_grid(row1, row2, ncol = 1, align = "v")
print(final)
```


The EWS did not perform as well when anticipating elimination, relative to emergence (figure \ref{elim-aucs}).
Only three metrics are reliable: mean, autocovariance, and variance.
All three metrics decreased as $R_E(t)$ approached the critical transition (figure S5).
As in the case of anticipating elimination, AUC values moved closer to 0.5 as the speed of the vaccine campaign increased (figure \ref{elim-aucs}*c*).
Again, this is because of shorter null and test intervals.

```{r elimination, fig.width=8.5, fig.height=5, fig.cap="Performance of early warning signals (EWS) over fixed windows on the approach to elimination. (*a*) A typical example of an elimination simulation for Maradi. The two vertical blue lines indicate the start (left-most line) and end (line for critical year) of the full window. The black line demarcates the division between the equal-length null and test intervals, in which we show the calculated variance. (*b*) Empirical densities of variance in the null and test intervals across 500 simulations and the associated area under the curve (AUC) statistic. (*c*) Heatmap of AUC statistics for each EWS at each speed of approach to herd immunity. AUC values closer to 0 or 1 indicate higher ability to distinguish among time series near and far from a critical transition. See Fig. Sx for visualization of how vaccination speed maps to number of weeks in the null and test intervals.  \\label{elim-aucs}"}
example_data <- readRDS("../simulations/single-elimination-example.RDS")[[1]]
ews_data_example <- readRDS("../simulations/single-elimination-example.RDS")[[2]]

variance_example <- ews_data_example %>%
  group_by(half) %>%
  summarise(variance = round(var(reports)))

ggplot() +
  geom_line(data = example_data, aes(x = time, y = reports, group = group), 
            color = "tan", alpha = 0.4, size = 0.3) +
  geom_vline(data = ews_data_example, aes(xintercept = max(time)), 
             color = "dodgerblue4",  linetype = 2) +
  geom_vline(data = ews_data_example, aes(xintercept = min(time)), 
             color = "dodgerblue4",  linetype = 2) +
  geom_vline(data = ews_data_example, aes(xintercept = 50), 
             color = "grey45", linetype = 1) +
  geom_line(data = ews_data_example, aes(x = time, y = reports),
            color = "tan", size = 0.3) +
  annotate(geom = "text", x = 28, y = 1450, size = 3, family = "Times",
           label = "null interval", fontface = "bold") +
  annotate(geom = "text", x = 70, y = 1450, size = 3, family = "Times",
           label = "test interval", fontface = "bold") +
  annotate(geom = "text", x = 36, y = 900, family = "Times",
           label = "start of\nvaccination campaign", 
           size = 2.5, color = "grey25") +
  annotate(geom = "text", x = 79, y = 900, family = "Times",
           label = "coverage reaches\nherd immunity",
           size = 2.5, color = "dodgerblue4") +
  annotate(geom = "text", x = 28, y = 1300, size = 3, family = "Times",
           label = paste("variance =", 
                         filter(variance_example, half == "first") %>% 
                           pull(variance))) +
  annotate(geom = "text", x = 70, y = 1300, size = 3, family = "Times",
           label = paste("variance =", 
                         filter(variance_example, half == "second") %>% 
                           pull(variance))) +
  labs(x = "simulation time (year)", y = "reported cases") +
  theme_classic(base_size = 11, base_family = "Times") -> cases_series

# Plot variance distributions
all_variances <- read_csv("../results/ews-elimination.csv") %>%
  filter(metric == "variance", city == "Maradi", vacc_speed == 0.000015) %>%
  mutate(interval = ifelse(half == "first", "null", "test"),
         variance = value)

variance_cats <- all_variances %>%
  ungroup() %>%
  mutate(cat = ifelse(interval == "null", TRUE, FALSE)) 

calc_auc <- function(predictions, is_null){
    r <- rank(predictions)
    r1 <- sum(r[!is_null])
    n1 <- sum(!is_null)
    n2 <- sum(is_null)
    (r1 - n1 * (n1 + 1) / 2) / (n1 * n2)
}

var_auc <- round(calc_auc(variance_cats$variance, variance_cats$cat),2)

ggplot(data = all_variances, aes(x = log(variance + 1), fill = interval)) +
  geom_density(size = 0.5, alpha = 0.65, color = "white") +
  annotate(geom = "text", x = 10, y = 0.4, size = 3, family = "Times",
           label = paste("area under the curve:", var_auc)) +
  scale_fill_manual(values = mycols, name = "interval",
                    labels = c("null", "test")) +
  labs(x = "log(variance + 1)", y = "density") +
  coord_cartesian(xlim = c(6, 11)) +
  theme_classic(base_size = 11, base_family = "Times") +
  theme(legend.position = c(0.8, 0.8)) -> dist_plot

# AUC heatmap
elimination_aucs <- read.csv("../results/elimination-grid-aucs.csv") %>%
  filter(metric != "Decay time") %>%
  mutate(metric = tolower(metric))

ggplot() +
  geom_tile(data = elimination_aucs, aes(x = as.factor(vacc_speed*10000), 
                                         y = metric, fill = AUC)) +
  scale_fill_viridis(limits = c(0,1), direction = -1, option = "E",
                     name = "AUC") +
  facet_wrap(~city, nrow = 1) +
  labs(x = expression(paste("rate to full vaccine coverage (", 
                            phantom()%*%phantom(), 10^4, ")")), 
       y = NULL) +
  theme_minimal(base_size = 11, base_family = "Times") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(panel.spacing = unit(1, "lines"),
         strip.text = element_text(face = "bold"),
        plot.title = element_text(size = 11, face = "bold")) -> aucs

row2 <- cowplot::plot_grid(aucs, labels = "(c)", label_size = 12, 
                           label_fontfamily = "Times", label_fontface = 3)
row1 <- cowplot::plot_grid(cases_series, dist_plot, scale = 0.9, labels = c("(a)", "(b)"), 
          label_size = 12, label_fontfamily = "Times", label_fontface = 3)
final <- cowplot::plot_grid(row1, row2, ncol = 1, align = "v")
print(final)
```

In all, the suite of EWS suggest that critical slowing down does occur in measles dynamics as a critical transition is approached.
We found similar results for the approach to elimination when calculating EWS over a moving window of 35 weeks in the null and test intervals (SI text, figure S7).
But, all EWS performed worse when predicting the approach to emergence over the moving window (figure S7).
\comment{I don't think these elimination results say much about critical slowing down. How does a decrease in variance and the mean relate to declining stability of the equilibrium? If we want to demonstrate that CSD is detectable, I think the analysis must demonstrate the expected changes in the autocorrelation function of increased periodicity }

# Discussion

Using empirically-based disease transmission models, we found evidence of critical slowing down before critical transitions to re-emergence and elimination of measles.
This evidence comes from the fact that several EWS accurately anticipate the critical transition.

Evidence of CSD is strongest for scenarios of re-emergence.
This is because the autocorrelation and other EWS increased on the approach to $R_E = 1$ (fig. \ref{emerge-aucs}*c*).
Increases in EWS besides the autocorrelation, such as the variance, are necessary but insufficient evidence of CSD because such EWS can also increase when a critical transition does not exist (**CITATION?**).
However, an increase in the autocorrelation, coupled with coincident increases in other EWS, provides stronger evidence of CSD (**CITATION?**).
\textcolor{blue}{JOHN: I remember you making the points in the previous two sentences in a meeting once. Can you provide citations?}

The autocorrelation was not a strong indicator of the transition to elimination (fig. \ref{elim-aucs}*c*), suggesting weaker evidence for CSD.
\comment{I disagree completely. I don't think the autocorrelation has been analyzed properly.}
Other EWS (variane, autocovariance, and mean) did show altered behavior as the transition to elimination was approached, but these EWS were less sensitive under elimination scenarios compared to re-emergence scenarios.
These results suggest that CSD might not preempt disease elimination or that CSD is harder to detect when a disease is fading out rather than emerging.
We have reasons to expect CSD at the elimination threshold based on theoretical modeling studies [@ORegan2013; @ORegan2016; @Drake2017], but most theory has been developed for SIR models rather than the SEIR model we employed here.
Still, we think it is more likely that CSD is simply harder to detect in noisy systems approaching elimination.
\textcolor{blue}{EAMON: Can you add text on why this might be the case?}
\comment{I think the combination of seasonality and the intrinsic oscillations of the state variables around the endemic equilibrium both can lead to the autocorrelation at a single lag increasing or decreasing as the elimination threshold is approached. Thus a wavelet analysis or an analysis of the full autocorrelation function may be necessary. I don't think this is too much work for us to try to do for this paper. I think the paper would be much better for it, and am willing to work on it myself.}

```{r susc-deplete}
# Define threshold for outbreak year --------------------------------------

# Outbreaks defined as: an annual case count exceeding x% of the maximum
# annual case count for a region, where x is the threshold set below.
outbreak_threshold <- 0.8  # 80% of max = outbreak year


# Load simulated data -----------------------------------------------------

cities <- c("Agadez", "Maradi", "Niamey", "Zinder")
sim_data <- tibble()
for(do_city in cities){
  tmp_file <- paste0("../simulations/bootstrap-sims-", do_city, ".RDS")
  tmp_data <- readRDS(tmp_file) %>%
    unnest(cols = data) %>%
    mutate(city = do_city)
  sim_data <- bind_rows(sim_data, tmp_data)
}


# Identify outbreak years and calculate S depletion -----------------------

outbreak_years <- sim_data %>%
  mutate(year = trunc(time)) %>%
  group_by(city, sim, year) %>%
  summarise(total_cases = sum(reports),
            max_S = max(S),
            min_S = min(S)) %>%
  mutate(outbreak = ifelse(total_cases > outbreak_threshold*max(total_cases), 
                           TRUE, FALSE),
         max_S_t_minus_1 = lag(max_S),
         susc_depletion = min_S / max_S_t_minus_1) %>%
  filter(outbreak == TRUE) %>%
  drop_na()


# Calculate fraction of depletions less than 0.5 --------------------------

fracs_less_than_half <- outbreak_years %>%
  ungroup() %>%
  group_by(city) %>%
  mutate(
    deplete_half = ifelse(susc_depletion < 0.5, TRUE, FALSE)
  ) %>%
  group_by(city, deplete_half) %>%
  count() %>%
  group_by(city) %>%
  mutate(
    frac_less = n/sum(n)
  ) %>%
  filter(deplete_half == TRUE) %>%
  dplyr::select(city, frac_less)

percs <- fracs_less_than_half$frac_less*100
```

A potential limitation of our findings is that the levels of susceptible depletion we modeled (figure \ref{emerge-aucs}*c*) might be lower than the levels that occur in reality.
To check the relevance of this limitation, we calculated the level of susceptible depletion after outbreaks (defined as years where the total number of cases reached 80% of the maximum observed) across one hundred replicate simulations (SI text).
We found that susceptible depletion was less than 0.5, the smallest susceptible depletion level we tested, for `r round(percs[1], 1)`% of outbreaks in Agadez, `r round(percs[2])`% of outbreaks in Maradi, `r round(percs[3])`% of outbreaks in Niamey, and `r round(percs[4])`% of outbreaks in Zinder.
These statistics do not detract from our main findings of CSD in measles dynamics, but they do suggest that EWS might be less useful in some cases than in others.
For example, AUC values for emergence at the 0.5 level of susceptible depletion are already low for most cities (figure \ref{emerge-aucs}*c*).
Thus, EWS are not practical for cities that rarely experience levels of susceptible depletion below 0.5 (e.g., Agadez).

Our results should encourage efforts to develop model-independent early warning systems for infectious diseases [@Han2016].
We have shown that critical slowing down precedes tipping points in real disease dynamics, but how to operationalize the phenomenon of critical slowing down remains an open research area [@Shmueli2010].
Emerging technologies like artifical intelligence might offer new ways to find optimal detection thresholds for early warning signals.
But there will always be a role for expert judgement.
Early warning signals, though powerful and now accompanied with empirical support, will likely be just one part of a decision-support toolkit.

# Acknowledgements
We thank Tobias Brett and Andrew Park for comments on the modeling approach, and Paige Miller and ric Marty for helpful comments on early versions of this work.

# Funding
This research was funded by the National Institute of General Medical Sciences of the National Institutes of Health (Award Number U01GM110744).
The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.
This work was done on the Olympus High Performance Compute Cluster located at the Pittsburgh Supercomputing Center at Carnegie Mellon University, which is supported by National Institute of General Medical Sciences Modeling Infectious Disease Agent Study (MIDAS) Informatics Services Group grant 1U24GM110707.

# Authors' contributions
ATT concieved of the study, designed the study, carried out the statistical and modeling analysis, and drafted the manuscript; EBO participated in the design of the study, participated in statistical and modeling analysis, and critically revised the manuscript; PR participated in the conception and design of the study, guided the statistical and modeling analysis, and helped draft and revise the manuscript; JMD coordinated the study, participated in the conception and design of the study, guided the statistical and modeling analysis, and helped draft and revise the manuscript.
All authors gave final approval for publication and agree to be held accountable for the work performed therein.

# References
