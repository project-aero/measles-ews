---
title: "Anticipating infectious disease re-emergence and elimination: a test of early warning signals using empirically based models"
author:
  - name: "Andrew T. Tredennick^[Authors contributed equally.]"
    affiliation: UGA,CEID,WEST
    email: atredennick@west-inc.com
  - name: "Eamon B. O'Dea*"
    affiliation: UGA,CEID
    email: odea35@gmail.com
  - name: "Matthew J. Ferrari"
    affiliation: CIDDBIO
  - name: "Andrew W. Park"
    affiliation: UGA,CEID,ID
  - name: "Pejman Rohani"
    affiliation: UGA,CEID,ID
  - name: "John M. Drake"
    affiliation: UGA,CEID
    email: jdrake@uga.edu
address:
  - code: UGA
    address: "Odum School of Ecology, University of Georgia, Athens, GA 30602, USA"
  - code: CEID
    address: "Center for the Ecology of Infectious Diseases, University of Georgia, Athens, GA 30602, USA"
  - code: WEST
    address: "Western EcoSystems Technology, Inc., 1610 East Reynolds Street, Laramie, WY 82070, USA"
  - code: CIDDBIO
    address: "The Center for Infectious Disease Dynamics and Department of Biology, The Pennsylvania State University, University Park, PA 16802, USA"
  - code: ID
    address: "Department of Infectious Diseases, University of Georgia, Athens, GA 30602, USA"
abstract: |
  Timely forecasts of the emergence, re-emergence, and elimination of human infectious diseases allow for proactive, rather than reactive, decisions that save lives. Recent theory suggests that a generic feature of dynamical systems approaching a tipping point -- early warning signals due to critical slowing down -- can anticipate disease emergence and elimination. Empirical studies documenting critical slowing down in observed disease dynamics are scarce, but such demonstration of concept is essential to the further development of model-independent outbreak detection systems. Here, we use fitted, mechanistic models of measles transmission in four cities in Niger to detect critical slowing down through statistical early warning signals. We find that several early warning signals accurately anticipate measles re-emergence and elimination, suggesting that critical slowing down should be detectable before disease transmission systems cross key tipping points. These findings support the idea that statistical signals based on critical slowing down, coupled with decision-support algorithms and expert judgment, could provide the basis for early warning systems of disease outbreaks.
keywords:
  - critical slowing down,
  - early warning signals,
  - epidemiology,
  - measles,
  - infectious disease
bibliography: ./measles-ews.bib
date: "`r Sys.Date()`"
csl: proceedings-of-the-royal-society-b.csl
output: rticles::elsevier_article
layout: 3p # review # review = doublespace, 3p = singlespace, 5p = two-column
preamble: |
  \journal{Journal of the Royal Society Interface}
  \usepackage{lineno}
  \linenumbers
  \usepackage{mathptmx}
  \renewcommand{\theaffn}{\arabic{affn}}
  \usepackage{setspace}
  \onehalfspacing
  \usepackage[nomarkers]{endfloat}
  \usepackage{xcolor}
  \newcommand{\comment}[1]{\ignorespaces}
  \newcommand{\new}{\textcolor{blue}}
  \renewcommand*{\thefootnote}{\fnsymbol{footnote}}
---


```{r libraries, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, cache = FALSE)
library(tidyverse)
library(ggthemes)
library(viridis)
library(ggrepel)
library(cowplot)
library(pomp)
library(sf)
```

```{r load-data, include = FALSE}
## Fig 1A
region_boundaries <- st_read("../data/spatial-data/NER_adm2.shp")
mycoords <- as_tibble(st_coordinates(region_boundaries)) %>%
  group_by(L3) %>%
  summarise(minx = min(X)) %>%
  mutate(
    NAME_2 = region_boundaries$NAME_2
  )

region_boundaries <- region_boundaries %>%
  left_join(mycoords)

my_cities <- tibble(
  city = c("Agadez", "Maradi", "Niamey", "Zinder"),
  lat = c(16.9, 13.5, 13.5, 13.8),
  lon = c(8.0, 7.1, 2.1, 8.98),
  population = c("(117,435 -\n 171,528)", "(314,277 -\n 459,019)", "(628,276 -\n 917,671)", "(260,997 -\n 381,216)")
) %>%
  mutate(
    label = paste(city, population, sep = "\n")
  )

## Fig 1B
measles_file <- "../data/clean-data/weekly-measles-incidence-niger-cities-clean.RDS"
measles_data <- readRDS(measles_file) %>%
  filter(year > 1994) %>%
  dplyr::select(-year, -week_of_year, -obs_week, -time) %>%
  mutate(
    region = str_sub(region, 1, str_length(region)-7)  # remove (City) from name
  )
pred_ids <- grep("predictive-dist-states", list.files("../results/"))
pred_files <- list.files("../results/")[pred_ids]
pred_cases <- tibble()
for(do_file in pred_files){
  do_city <- str_split(do_file, "-")[[1]][4]
  do_city <- str_split(do_city, "[.]")[[1]][1]
  
  tmp_data <- measles_data %>%
    filter(region == do_city)
  
  tmp <- readRDS(paste0("../results/", do_file)) %>%
    slice(2:n()) %>%  # drop first row of unobserved data
    mutate(
      upper_est = mean_cases + sdev_cases,
      lower_est = mean_cases - sdev_cases,
      lower_est = ifelse(lower_est < 0, 0, lower_est),
      city_name = do_city,
      date = tmp_data$date,
      observed_cases = tmp_data$cases
    )
  pred_cases <- bind_rows(pred_cases, tmp)
}
```


# Introduction

Forecasts of the emergence and re-emergence of infectious diseases have the potential to save lives, money, and human productivity by allowing for proactive, rather than reactive, preparedness measures [@Han2016].
Similarly, indicators of the elimination of infectious diseases can measure the effectiveness of "end game" strategies aimed at disease eradication [@Drake2017].
Predicting (re)emergence and elimination is possible with parametric mathematical models of disease transmission, but their success relies on detailed understanding of the underlying transmission dynamics and adequate data [@Metcalf2017].
We often do not have enough information (or time) to parameterize such models.
An alternative approach is to use model-independent statistical signals that portend infectious disease (re)emergence and elimination by detecting critical slowing down as the system approaches a critical transition [@ORegan2013;@Drake2019].

Emergence and elimination of an infectious disease both involve a critical transition, often reflected in deterministic models by a *transcritical bifurcation*, that occurs at the critical point where the effective reproduction number ($\mathcal{R}_e$, corresponding to the number of secondary cases that arise from a single infected case in a population) is equal to one [@Heffernan2005].
Thus, subcritical ($\mathcal{R}_e < 1$) and supercritical ($\mathcal{R}_e > 1$) systems represent alternative dynamical regimes [@Scheffer2009; @Scheffer2012; @ORegan2013].

Critical transitions in stochastic systems, such as systems of disease transmission, are often accompanied by critical slowing down (CSD), a reduction in the resilience of a system to perturbations [@Wissel1984; @VanNes2007].
CSD can be measured by changes in the statistical properties of the system, often referred to as early warning signals (EWS), such as an increase in the variance and autocorrelation [@Carpenter2006; @Scheffer2009].
Recent theoretical work suggests that CSD occurs as disease dynamics approach $\mathcal{R}_e = 1$ from below (emergence) [@ORegan2013; @Dibble2016] and from above (elimination) [@ORegan2013; @ORegan2016; @Drake2017], and that several EWS can anticipate the critical transition [@Brett2017; @Brett2018; @Miller2017].
These findings suggest that such model-independent statistical signals could be operationalized as part of early warning systems for disease emergence and elimination, or re-emergence and outbreaks of endemic diseases.

Operationalizing such EWS, however, and deploying early warning systems based on them, face many challenges [@Boettiger2013; @Han2016].
For example, using EWS in an "online mode" requires choosing temporal windows over which EWS are calculated.
These moving windows should be long enough to provide reliable statistics, but short enough to forget the past so as to not overwhelm information contained in new observations.
Such fine-tuning is especially important for diseases that fluctuate seasonally, where EWS might always increase and then decrease over the course of the year, requiring computations to be reset each season [@Miller2017].
Another challenge is defining thresholds for detection of an upcoming tipping point.
Detection thresholds can be based on the absolute value of an EWS (e.g., warning if variance exceeds some value), the trend in an EWS over time (e.g., warning if the correlation of variance with time exceeds some value), or an algorithmic combination of many factors (e.g., variance and autocorrelation increases above some value several observation periods in a row).
Ref. [@Brett2020] has pioneered the approach of developing algorithms for combining EWS, their values, and their trends to best detect disease emergence and elimination, but much work remains to be done.  

An important step in operationalize EWS based on critical slowing down is to stress test the performance of EWS in anticipating critical transitions.
One way to stress test EWS is through empirical case studies: do EWS anticipate re-emergence and elimination in observed time series of disease incidence [@Harris2020]?
However, uncritical application of EWS to observed data could lead to researchers getting the right answer for the wrong reasons.
EWS might perform well for a given time series, but for reasons having nothing to do with critical slowing down [@Kefi2013; @Dakos2015; @Dutta2018].
Critical transitions may also occur in the absence of early warning signals [@Boettiger2012a].
Without knowing the critical point (i.e., when $\mathcal{R}_e(t) = 1$), it is impossible to know if EWS are in fact sending us the signal we think they are.

Another option is to use fitted models of disease transmission to test EWS.
This offers several advantages.
First, using a model to simulate time series of cases means one also has access to a time series of $\mathcal{R}_e(t)$, essential for knowing the time at which the critical transition occurs.
This means we know whether we are getting the right answer for the right reason.
Second, one can simulate replicate time series to account for the inherent stochasticity of disease transmission, so that conclusions are not based on one-off events that might result in confirmation bias [@Boettiger2012].
Third, we can specifically simulate re-emergence and elimination events to separate the stress testing of EWS from the research necessary to operationalize EWS.
In short, a simulation approach to stress testing provides the flexibility of a theoretical model, but  remains tethered to reality because the model parameters are fitted to real data.
We believe this is the first study to take this step toward operationalizing EWS as part of infectious disease early warning systems.

Here, we report on a study using simulations from fitted models of measles transmission in an outbreak prone population to test whether CSD anticipates critical transitions in realist situations.
We focus on two scenarios: the re-emergence of measles following a large outbreak, a situation typical of measles dynamics in the Sahel [@Ferrari2008], and the elimination of measles by gradually increasing routine vaccination.
We seek to answer two related questions.
First, can CSD distinguish between time series of disease incidence when the underlying dynamics are far from vs. near to a critical transition?
Second, can CSD anticipate disease re-emergence and elimination?

To answer these questions, we fit mechanistic models to time series of measles incidence in four cities in Niger [@Ferrari2008; @Bharti2011].
We then use the fitted models to perform simulation experiments designed to test the performance of several EWS that are characteristic of critical slowing down with respect to anticipating re-emergence and elimination.
Our results confirm the theory concerning several EWS.
In particular, we show that slowing down before a critical transition is detectable by several EWS in realistic scenarios.
However, our study also highlights the limitations of EWS in situations where disease re-emergence and elimination occur rapidly.
Finally, we also find that EWS perform better at anticipating re-emergence than elimination.

# Materials and methods

## Data
We used weekly measles case report data (incidence) from four Nigerien cities: Agadez, Maradi, Niamey, and Zinder (figure \ref{data-plot}*a*).
The data were collected over an 11 year period from 1995-2005 (figure \ref{data-plot}*b*).
These data are ideal for testing the theory of critical slowing down in disease dynamics because each city has a different population size (with means ranging from about 150,000 to 750,000 during this time period), different dynamics in terms of outbreak sizes (maximum weekly incidence ranging from 60 to 1845 cases) and length of inter-epidemic periods (2-5 years), and has different amounts of demographic stochasticity due to differences in population size.
Such differences \new{provide an interesting test case for EWS because different levels of demographic stochasticity due to population sizes and environmental stochasticity due to potential differences in tranmission dynamics can} influence critical slowing down [@Hastings2010; @Dakos2012a; @ODea2018a; @ORegan2018].
\new{We also used data on district population sizes and national-level birth rates.}
\new{Measles incidence data and district-level population data were obtained from the Niger Ministry of Health [@NigerMinistryofHealth2008].}
\new{National-level birth rate data were downloaded from the FRED database (https://fred.stlouisfed.org/series/SPDYNCBRTINNER).}


```{r data-plot, fig.width=6.5, fig.height=4, fig.cap="Locations of data sources and observed and predicted measles dynamics. (*a*) Locations and 1995--2005 population-size--ranges (in parantheses) of our four focal cities in Niger. (*b*) Time series of weekly reported cases (incidence data; yellow solid lines) and the 68% prediction intervals (black ribbons) for one-week-ahead predictions from our fitted SEIR models for each city. \\label{data-plot}"}
set.seed(1) # affects placement of geom_label_repel
the_map <- ggplot(region_boundaries)+
  geom_sf(fill = "grey90", col = "grey80", size = 0.3) +
  geom_point(data = my_cities, aes(x = lon, y = lat), size = 2) +
  geom_label_repel(
    data = my_cities,
    aes(x = lon, y = lat, label = label),
    box.padding   = 0.5, 
    point.padding = 0.75,
    size = 2,
    family = "Times"
  ) + 
  annotate("text", x = 12, y = 20, label = "Niger", fontface = 3, size = 5, family = "Times") +
  labs(x = "longitude", y = "latitude") +
  theme_minimal(base_family = "Times")

the_series <- ggplot(pred_cases, aes(x = date)) +
  geom_ribbon(aes(ymin = lower_est, ymax = upper_est), color = "black") +
  geom_line(aes(y = observed_cases), color = ptol_pal()(3)[2], size = 0.4) +
  facet_wrap(~city_name, scales = "free_y", ncol = 1) +
  labs(x = "date", y = "reported cases") +
  theme_minimal(base_family = "Times")

plot_grid(the_map, the_series, ncol = 2, labels = c("(a)", "(b)"), 
          label_size = 12, label_fontfamily = "Times", label_fontface = 3)
```

## Stochastic *SEIR* model
The model is a discrete-time approximation to the continuous-time SEIR model with demography, specified as a set of difference equations,

\new{\begin{align}
S_{t+ \Delta t} - S_{t} &= n_{0S,t} - n_{SE,t} - n_{S0,t} \\
E_{t+ \Delta t} - E_{t} &= n_{SE,t} - n_{EI,t} - n_{E0,t} \\
I_{t+\Delta t} - I_{t} &= n_{EI,t} + n_{0I,t} - n_{IR,t} - n_{I0,t} \\
R_{t+\Delta t} - R_{t} &= n_{0R,t} + n_{IR,t} - n_{R0,t},
\end{align}}

\noindent{}where $\textbf{n}_t$ are random variables representing the number of individuals transitioning into or out of each class at each update $t \rightarrow t+\Delta t$.
\new{Transition definitions are in table \ref{tab:transitions}.}

| Random variable | Transition | $\left(\Delta S, \Delta E, \Delta I, \Delta R\right)$ |
| ---------- | ----------------------------| ---------- |
| $n_{0S}$ | Births into the *S* compartment, not vaccinated | (1, 0, 0, 0) |
| $n_{SE}$ | Number of people transitioning from *S* to *E* | (-1, 1, 0, 0) |
| $n_{S0}$ | Number of deaths leaving *S* | (-1, 0, 0, 0) |
| $n_{EI}$ | Number of people transitioning from *E* to *I* | (0, -1, 1, 0) |
| $n_{E0}$ | Number of deaths leaving *E* | (0, -1, 0, 0) |
| $n_{0I}$ | Number of imported infections | (0, 0, 1, 0) |
| $n_{IR}$ | Number of people transitioning from *I* to *R* | (0, 0, -1, 1) |
| $n_{I0}$ | Number of deaths leaving *I* | (0, 0, -1, 0) |
| $n_{0R}$ | Births into the *R* compartment, vaccinated | (0, 0, 0, 1) |
| $n_{R0}$ | Number of deaths leaving *R* | (0, 0, 0, -1) |

Table: Transitions in the simulating model. \label{tab:transitions}

The stochastic random variables are specified as follows:

\new{\begin{align}
n_{0S,t} &\sim \text{Poisson}((1-p_t)\mu N \times \Delta t) \\
(n_{SE,t}, n_{S0,t}) &\sim \text{EulerMultinomial}(S_{t}, (\beta_t I_t / N, \nu), \Delta t) \\
(n_{EI,t}, n_{E0,t}) &\sim \text{EulerMultinomial}(E_{t}, (\eta, \nu), \Delta t)  \label{eq:emulti} \\
(n_{IR,t}, n_{I0,t}) &\sim \text{EulerMultinomial}(I_{t}, (\gamma, \nu), \Delta t) \\
n_{I0,t} &\sim \text{Poisson}(\psi \times \Delta t) \\
n_{0R,t} &\sim \text{Poisson}(p_t \mu N \times \Delta t) \\
n_{R0,t} &\sim \text{EulerMultinomial}(R_t, (\nu), \Delta t),
\end{align}}

\noindent{}\new{where $p_t$ is the vaccination probability, $\mu$ is the per capita birth rate at time $t$, $N$ is population size at time $t$, $\sim \text{EulerMultinomial}(T, r_i, \Delta t)$ specifies that the variables on the left of $\sim$ follow an Euler Multinomial distribution for $T$ individuals with hazard rates $r_i$ and step size $\Delta t$, $\beta_t$ is a time-varying rate of transmission, $\eta$ is a time-invariant rate of transfer from the exposed class to the infectious class, $\gamma$ is a time-invariant recovery rate, $\nu$ is the per capita death rate, and $\psi$ is the rate of imported infections (estimated by the model).} 
\new{The Euler Multinomial distribution corresponds to a multinomial distribution where the event probabilities $P_i$ are determined by the Euler time step $\Delta t$ and the hazard rates $r_i$, according to,} 

\new{\begin{align}
P_0 &= \exp( -\sum_i r_i \Delta t), \\
P_i &= (1 - P_0) r_i / (\sum_i r_i)\qquad \text{for} \qquad i > 0.
\end{align}}

\new{\noindent{}Event zero is the event that an individual stays in its initial compartment and does not contribute to the vector $\textbf{n}_t$.}
\new{To provide a specific example, equation \eqref{eq:emulti} corresponds to,} 

\new{\begin{equation}
(E_{t} - n_{EI,t} - n_{E0,t}, \,n_{EI,t},\, n_{E0,t}) \sim \text{Multinomial}(E_{t}; P_0, (1 - P_0) \eta /(\eta + \nu), (1 - P_0) \nu / (\eta + \nu)),
\end{equation}}

\noindent{}\new{where $P_0 =  \exp(-(\eta + \nu) \Delta t)$.}
We used a daily time step of $\Delta t = \text{year} / 365$.

We modeled the rate of transmission as:

\begin{equation}
\beta_t = \beta \left(1 + \exp \left(\sum^6_{i=1} q_i \xi_{i_{t}}\right) \right) \Gamma_t.
\end{equation}

\noindent{}where $\beta$ is the minimum transmission rate over the season and the term $\sum^6_{i=1} q_i \xi_{i_{t}}$ is a B-spline to model seasonality in transmission.
The B-spline bases ($\xi_{i_{t}}$) are periodic with a 1 year period.
The transmission rate ($\beta_t$) is also subject to stochastic process noise at each time step, $\Gamma_t$, which we model as gamma-distributed white (temporally uncorrelated) noise with mean 1 and intensity $\sigma^2$ [@Breto2011].

In this model, the effective reproduction number at time $t$ may be approximated as: $\mathcal{R}_e(t) \approx \frac{\beta_t}{\gamma} \frac{S_t}{N_t}$. 
The effect of vaccination on $\mathcal{R}_e(t)$ is implicitly included through the size of the $S_t$ compartment.

Observed case reports ($y_t$) were drawn from a negative binomial distribution subject to a constant reporting fraction ($\rho$) and dispersion parameter $\tau$,

\begin{align}
y_t \sim \text{Negative Binomial} \left( \rho x_t, \tau \right),
\end{align}

\noindent{}where $x_t$ are the accumulated cases that transition from the infected class to the recovered class in a one week period. 
In this parameterization of the negative binomial, the mean is equal to $\rho x_t$ and the the variance is equal to $\rho x_t + (\rho x_t) ^ 2 \tau$. 


##  Model fitting and inference

The model described above was fit to the time series of case reports (incidence data) from each city using Maximization by Iterated particle Filtering (MIF) [@Ionides2015].
We estimated 14 parameters (table \ref{tab:params}.
To improve parameter identifiability, mean incubation period was fixed to $1/\eta = 8$ days and the mean infectious period was set to $1/\gamma = 5$ days [@Keeling2002].
The vaccination probability ($p_t$) was set to 70\% for all times $t$, consistent with reported vaccination coverage [@Ferrari2008].

| Parameter symbol | Definition | Fitted or fixed | 
| ------ | --------------------- | ---------- |
| $\beta$ | Minimum transmission rate within the season | Fitted |
| $q_i$ | Seasonal transmission spline parameters ($i \in 1,2,3, \dots 6$) | Fitted |
| $S_{(t=0)}/N_{t=0}$ | Initial susceptibal fraction | Fitted |
| $E_{(t=0)}/N_{t=0}$ | Initial exposed fraction | Fitted |
| $I_{(t=0)}/N_{t=0}$ | Initial infected fraction | Fitted |
| $\psi$ | Importation rate | Fitted |
| $\rho$ | Reporting fraction | Fitted |
| $\sigma$ | Gamma white-noise intensity | Fitted |
| $\tau$ | Negative binomial dispersion | Fitted |
| $1/\eta$ | Incubation period | Fixed (8 days) |
| $1/\gamma$ | Infectious period | Fixed (5 days) |
| $p_t$ | Vaccination probability | Fixed (0.7) |
| $mu_t$ | per capita birth rate | Fixed |
| $N_t$ | Population size | Fixed |

Table: Model parameters, definitions, and indicator as to whether they were fitted or fixed. Sources for fixed values are cited in the main text. \label{tab:params}


\new{For model fitting, we made simplifying assumptions to make the estimation procudure more tractable.} \new{First, we used known population size ($N_t$) for each city in each year.} \new{Second, death ($\nu$) was not included in the model when fitting because the rate of infection is much faster than the rate of death and because we used known population size at each time step.} Excluding deaths means we can avoid making further assumptions about demography. \new{This means we ignored the $R$ compartment entirely for model fitting.}

MIF relies on particle filtering, which estimates the likelihood of fixed parameters by integrating state variables of a stochastic system.
To identify the maximum likelihood estimates, MIF lets parameters take a random walk during the filtering process and selectively propagates forward parameter sets (i.e., particles) with the highest likelihood.
The variance of the random walk decreases at each iteration of MIF, where a MIF iteration means one filtering pass through the time series.
This procedure converges toward the maximimum likelihood estimates (MLEs).

We used the IF2 algorithm [@Ionides2015] implemented in the R [@R2017] package `pomp` version 1.18 [@King2016; @King2018] to conduct MIF.
To initialize MIF, we generated 5000 parameter sets using Latin hypercube sampling over large ranges of the parameters.
We then performed two rounds of MIF, each for 100 iterations, with 10,000 particles, using geometric cooling.
For the first round of MIF we set `cooling.factor = 1`.
For the second round, which was initialized using the collection of parameter sets from the end of the first round, we set `cooling.factor = 0.9`.
We computed the log likelihood of 5000 final MIF parameter sets (i.e., parameter sets collected after 200 MIF iterations) as the log of the mean likelihoods of 50 replicate particle filters with 10,000 particles each.
At this stage, we took the parameter set with highest log likelihood to be the MLE.

We used the parametric bootstrap to estimate approximate 95\% confidence intervals for all parameters, conducted for each city independently, as follows.
First, we simulated 100 realizations from the fitted model using the MLE parameters.
Second, we fitted the SEIR model to each of the 100 bootstrap simulations using the same MIF procedure described above, except we initiated the parameter search from 50 parameter sets rather then 5000.
We reduced the number of parameter sets due to the excessive computing time required to fit 100 simulated data sets for each of the four cities.
Third, we identified the MLE parameter set for each of the 100 bootstrap simulations from among the 50 MIF parameter sets.
Last, we calculated summary statistics (mean, median, quantiles) from the distribution of 100 MLE parameters.

## Model assessment
We used the MLE parameter sets to make one-week-ahead predictions and compared observed and expected case counts.
To make one-week-ahead predictions, we used particle filtering with 50,000 particles and retained the mean and standard deviation of all latent states across all particles before they were filtered at each time step.
We used the mean predictions ($\mathbb{E}(\text{cases}_t)$) to assess model fit using a generalized coefficient of determination, calculated as: $R^2 = 1 - \frac{\sum_t [\mathbb{E}(\text{cases}_t) - \text{cases}_t]^2}{\sum_t [\text{mean(cases)}-\text{cases}_t]^2}$ [@Martinez-Bakker2015].

In addition to comparing model expectations to in-sample observed data, we also compared our fitted SEIR models to two benchmarks: a negative binomial sampling model that assumes independent and identically distributed observations and a SARIMA model.
\new{Doing so allows us to gain some intuition as to whether accounting for mechanism (i.e., transmission dynamics) improves model fit and eventual inference.}
\new{The SARIMA is a seasonal autoregressive moving average model (an ARIMA (2,0,2)(1,0,1)\textsubscript{52} model) that can account for data dependencies and annual periodicity.}
\new{Beating the SARIMA is a harder test than beating the NBM.}

\new{We fitted both models to the weekly case count observations for each city using maximum likelihood.}
\new{After fitting, we calculated Akaike's Information Criterion for each model as: $\text{AIC} = 2k -2\text{ln}(L)$, where $k$ is the number of estimated parameters in the model and $L$ is the model's likelihood [@Akaike1973].}
\new{The NBM model has 2 parameters, the SARIMA model has 8 parameters, and the SEIR model has 14 parameters.}

## Model simulations
To fit the SEIR model, we used known population size interpolated between years.
This meant we were able to ignore certain demographic processes.
For example, deaths from the susceptible pool were ignored under the assumption that the infection rate was much faster than the death rate.
We also ignored the recovered class because their dynamics, outside of the contribution to population size (which was assumed known), do not impact the $S, E, \text{or } I$ compartments.
However, births and deaths from all compartments, including $R$, were needed when simulating the model over arbitrarily long time periods that do not necessarily represent real times for which we would have information on population size.
\new{For long-run simulations, we set $\mu = \nu = 0.05$, which is the per capita rate reported for 2005, rounded to the nearest 0.01.}
\new{Setting birth rate equal to death rate achieved an equilibrium population size for long-run simulations.}

### Simulating re-emergence
To simulate re-emergence of measles, we manipulated the initial size of the susceptible pool to represent an increase from low $\mathcal{R}_e(t)$ to high $\mathcal{R}_e(t)$.
Doing so allowed us to test whether EWS can distinguish between windows of time when $\mathcal{R}_e(t)$ is far from a critical transition and when $\mathcal{R}_e(t)$ is near a critical transition.
We reduced the initial fraction of susceptible individuals by multiplying the MLE for $S_{(t=0)}$ by six depletion factors: 1e-4, 0.1, 0.2, 0.3, 0.4, and 0.5.
These depletion factors represent situations of susceptible depletion after outbreaks of various size.
After defining $S_{(t=0)}$ based on the depletion factor, we then set the initial number of recovered individuals to $R_{(t=0)} = N_{(t=0)} - S_{(t=0)}$ and set the initial number of exposed and infected individuals to zero.
Initial population size for simulation scenarios, $N_{(t=0)}$, was set to the mean population size for each city over the 1995-2005 time period.
We then simulated the model forward for forty years using the mean birth rate for the entire country ($\mu = 0.05$) and setting the death rate equal to the birth rate ($\mu = \nu = 0.05$) to achieve a constant average total population size over the course of the simulation (total population size does vary, though, because of stochasticity in the model).
Forty years was long enough for $\mathcal{R}_e(t)$ to reach or exceed 1 for each simulation replicate.
Several outbreaks are seen within 11 years in the data (figure 1b), though time-to-outbreak was larger in  scenarios where the susceptible population was initialized to be much smaller than ever observed in reality.
Because the model is stochastic, we repeated these simulations 500 times for each city--susceptible-depletion combination.

Next, we split each simulated time series into null and test intervals.
Fixed-size windows before and after the known critical transition were used because our focus was on testing EWS using empirically-based models, rather than attempting to identify optimal methods for operationalizing EWS.
\new{To define the null and test intervals for our simulations of re-emergence and elimination, we need to know when the critical transition between alternative modes of fluctuation occurs.}
\new{For re-emergence, we defined the critical year as the year in which the effective reproduction number ($\mathcal{R}_e$) reaches or exceeds the critical value of 1.}
\new{When determining the critical year, we eliminated the variation in $\mathcal{R}_e$ that arises from the gamma white noise factor and thus calculated the expected value of $\mathcal{R}_e(t)$ over the set of all simulation replicates at time $t$.}
\new{From a window ranging from the beginning of the simulation to the end of the critical year, we defined the null interval as the first half of the window (far from $\mathcal{R}_e = 1$) and the test interval as the second half of the window (near $\mathcal{R}_e = 1$).}
We did this for each city and for each level of susceptible depletion, and calculated EWS over all null and test intervals separately.

### Simulating elimination
To simulate elimination, we simulated an improvement in routine vaccination in which the vaccination probability increased linearly with respect to time to eventually reach 100\%, i.e. eradication (figure S3).
Vaccination probablity started at baseline vaccine coverage reported for Niger of 70\%, $p_t = 0.7$ [@Ferrari2008].

\new{We defined the critical time as the year in which the vaccination probability reaches the threshold needed for herd immunity.}
\new{This vaccination threshold is defined as $p^* = 1 - 1/\mathcal{R}_0$.}
\new{Because our transmission function is seasonal, we first approximated time-specific $\mathcal{R}_0$ as: $\mathcal{R}_0(t) = \frac{\eta \beta_t}{(\eta+\nu)(\gamma+\nu)}$, where $1/\eta$ is the incubation period, $1/\gamma$ is the infectious period, $\beta_t$ is the time-specific rate of transmission, and $\nu$ is the death rate.} 
\new{We took a conservative approach for calculating the vaccination threshold by using the maximum value of $\mathcal{R}_0(t)$ out of the range of values in its seasonal variation.} 
\new{That is, we used $p^* = 1 - 1/\text{max}(\mathcal{R}_0(t))$ as the threshold value.}
\new{We set the time at which the vaccination probability is equal to this threshold value as the endpoint for the EWS analysis.}
\new{All elimination simulations had vaccination improvements that started at year 50.}
\new{Therefore, we defined the test interval as the times between the beginning of year 50 and the time at which the vaccination probability is equal to $p^*$.}
\new{We then defined the null interval as a window with length equal to the test interval and ending at the end of year 49.} EWS were then calculated for each interval.

## Calculating early warning signals
We considered eight candidate early warning signals \new{based on previous work} [@ORegan2013; @ORegan2016; @Brett2017; @Brett2018; @Brett2020] (table \ref{tab:ews}).
We used the `spaero::get_stats()` function [@ODea2018] in R [@R2017] to calculate EWS according to the formulas in table \ref{tab:ews}.
All EWS except the coefficient of variation are expected to increase as $\mathcal{R}_e(t)$ approaches 1 from below [@ORegan2013; @ORegan2016; @Brett2017].
We are not aware of theoretical results for the behavior of these EWS as $\mathcal{R}_e(t)$ approaches 1 from above that are applicable to our fitted model's dynamics, which are highly non-linear (figure S2).
But a natural expectation is that the mean should decrease as the endemic equilibrium of our model's deterministic skeleton moves toward zero.

| EWS | Estimator | Theoretical Correlation with $\mathcal{R}_e(t)$ in an emergence scenario |
| -------------------- | ----------------------------------- | ------------------------ |
| Mean | \( \bar{y} = \sum_{i=1}^n \frac{y_i}{n} \) | Positive |
| Variance | \( s^2 = \sum_{i=1}^n \frac{(y_i - \bar{y})^2}{n} \) | Positive |
| Coefficient of variation | \( \frac{ s }{ \bar{y} } \) | Null |
| Index of dispersion | \( \frac{ s^2 }{ \bar{y} } \) | Positive |
| Skewness | \( \frac{1}{s^3} \sum_{i=1}^n \frac{\left( y_i - \bar{y} \right)^3}{n} \) | Positive |
| Kurtosis | \( \frac{1}{s^4} \sum_{i=1}^n \frac{\left( y_i - \bar{y} \right)^4}{n} \) | Positive |
| Autocovariance | \( s^2_1 =  \sum^{n}_{i=2} \frac{\left( y_i - \bar{y} \right)\left( y_{i - 1}  - \bar{y} \right)}{n} \) | Positive |
| Autocorrelation | \( r_1 = \frac{s^2_1 }{ s^2} \) | Positive |

Table: List of candidate early warning signals and their estimating equations. See @Brett2018 for details, as well as moving window versions which we use in the section "Moving window analysis" in the following. \label{tab:ews}

For each simulation of re-emergence and elimination, we calculated EWS for the time series of expected cases in the null and test intervals.
This yielded a distribution of EWS over the 500 null and test intervals.
We assessed the performance of each EWS using the Area Under the Curve (AUC) statistic.
Specifically, we used AUC to calculate the amount of overlap between the distributions of each EWS from the null and test intervals [@Brett2018].
Values of AUC far from 0.5 (i.e., close to 0 or 1) indicate a greater degree of separation and thus better performance of a particular EWS in terms of classifying whether $\mathcal{R}_e(t)$ is close to a critical transition.
We calculated AUC as: $\text{AUC} = \left[r_{\text{test}} - n_\text{test} \left(n_{\text{test}}+1\right)/2\right] / \left(n_{\text{test}}n_{\text{null}}\right)$ where $r_{\text{test}}$ is the sum of the ranks of test set EWS statistics in a combined set of null and test statistics (lower numbers have lower ranks), $n_{\text{test}}$ is the number of test of statistics and $n_{\text{null}}$ is the number of null statistics [@Flach2011; @Brett2018].
The AUC of an EWS is the probability that a randomly chosen EWS value from the test set is higher than an EWS value randomly chosen from the null set [@Fawcett2006].
Therefore, AUC should be high (closer to 1) when an EWS is expected to increase as a critical transition is approached, whereas AUC should be low (closer to 0) when an EWS is expected to decrease.


```{r scatters-r0, fig.width=6.5, fig.height=4, fig.cap="Accuracy of the fitted *SEIR* models and estimated seasonality. (*a*) Comparison of in-sample model predictions and observations for each city. Expected cases are one-week-ahead predictions from the fitted models. The dashed line shows 1:1. Coefficients of determination ($R^2$) were calculated as the reduction in the sum-of-squared errors from model predictions relative to a null model of the mean number of cases (Methods). (*b*) The estimated seasonality of the basic reproductive ratio ($\\mathcal{R}_0$) for each city. $\\mathcal{R}_0$ was approximated as: $\\frac{\\eta \\beta_t}{(\\eta+\\nu)(\\gamma+\\nu)}$, where $1/\\eta$ is the incubation period, $1/\\gamma$ is the infectious period, $\\beta_t$ is the time-specific rate of transmission, and $\\nu$ is the death rate. Only $\\beta_t$ is estimated by our model. We set $1/\\eta$ = 8 days, $1/\\gamma$ = 5 days, and $\\nu$ = 0.05 for calculating $\\mathcal{R}_0$ as shown in this figure. The white line is $\\mathcal{R}_0$ calculated using the MLE parameters; shaded regions are the bootstrapped 95% confidence intervals. The dashed horizontal lines show the common range of measles $\\mathcal{R}_0$: 12 to 18.\\label{scatters}"}
r_squares <- pred_cases %>%
  group_by(city_name) %>%
  mutate(
    mean_observations = mean(observed_cases),
    error_numer = (mean_cases - observed_cases)^2,
    error_denom = (mean_observations - observed_cases)^2
  ) %>%
  summarise(
    summed_numer = sum(error_numer),
    summed_denom = sum(error_denom)
  ) %>%
  mutate(
    R2 = 1 - (summed_numer / summed_denom)
  ) %>%
  dplyr::select(city_name, R2)

scatters <- ggplot(pred_cases, aes(x = log(observed_cases+1), y = log(mean_cases+1))) +
  geom_point(aes(color = city_name), size = 1, alpha = 0.3) +
  geom_abline(aes(intercept = 0, slope = 1), linetype = 2) +
  geom_label(data = r_squares, 
             aes(x = 1.7, y = 7.3, label = paste0("italic(R)^2 == ", 
                                                  round(R2,2))), 
             label.size = NA, parse = TRUE, size = 3, family = "Times") +
  labs(y = "expected log(cases + 1)", x = "observed log(cases + 1)") +
  facet_wrap(~city_name, nrow = 2, scales = "free") +
  scale_y_continuous(limits = c(0,8)) +
  scale_x_continuous(limits = c(0,8)) +
  scale_color_colorblind()+
  guides(color = FALSE)+
  theme_classic(base_size = 10, base_family = "Times") +
  theme(panel.spacing = unit(1, "lines"), strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
        plot.title = element_text(face = "bold")) 
  # ggtitle("Model-data agreement")

calc_R0 <- function(beta = NULL, B = NULL, qis = NULL, season = NULL, 
                    eta = (365/8), nu = 0.05, gamma = (365/5)){
  if(is.null(beta)){
    R0 <- (eta*B) / ((eta + nu)*(gamma + nu))
  } else{
    B <- as.numeric((1 + exp(season %*% qis)) * beta)
    R0 <- (eta*B) / ((eta + nu)*(gamma + nu))
  }
  return(R0)
}

# Define computation grid for bootstraps

nboots <- 100
nmifs <- 50
comp_grid <- expand.grid(1:nboots, 1:50)
colnames(comp_grid) <- c("boot_series", "param_set")
comp_grid$do_grid <- 1:nrow(comp_grid)

# Load example pomp file for basis function
pomp_file <- "../code/measles-pomp-object-Agadez.RDS"
measles_pomp <- readRDS(pomp_file)  # exemplar bases

bases <- as_tibble(measles_pomp@covar) %>%
  dplyr::select(starts_with("x")) %>%
  dplyr::slice(1:365) %>%
  mutate(
    day = 1:365
  ) %>%
  gather(key = base, value = value, -day)

season <- bases %>%
  spread(key = base, value = value) %>%
  dplyr::select(-day) %>%
  as.matrix()

seasonal_functions <- tibble()
for(do_city in c("Agadez", "Maradi", "Niamey", "Zinder")){
  boots <- read.csv(paste0("../results/bootstrap-mif-lls-", do_city, ".csv"))
  
  b_splines <- boots %>%
    slice(2:n()) %>%  # ignore first row of NAs
    left_join(comp_grid, by = "do_grid") %>%  # merge in comp grid info
    group_by(boot_series) %>%
    filter(loglik == max(loglik)) %>%
    ungroup() %>%
    dplyr::select(b1, b2, b3, b4, b5, b6)
  
  betas <- boots %>%
    slice(2:n()) %>%  # ignore first row of NAs
    left_join(comp_grid, by = "do_grid") %>%  # merge in comp grid info
    group_by(boot_series) %>%
    filter(loglik == max(loglik)) %>%
    ungroup() %>%
    dplyr::select(beta_mu)
  
  seasonal_betas <- tibble()
  for(i in 1:nrow(b_splines)){
    qis <- as.numeric(b_splines[i, ])
    beta_tmp <- as.numeric(betas[i, "beta_mu"])
    
    seasonal_tmp <- tibble(
      beta = as.numeric((1+exp(season %*% qis)) * beta_tmp),
      day = 1:365,
      boot = i
    )
    seasonal_betas <- bind_rows(seasonal_betas, seasonal_tmp)
  }  # end bootstrap loop
  
  seasonal_betas <- seasonal_betas %>%
    mutate(
      city = do_city,
      rnaught = calc_R0(B = beta)
    ) %>%
    group_by(city, day) %>%
    summarise(
      upper_R0 = quantile(rnaught, 0.975),
      lower_R0 = quantile(rnaught, 0.025)
    ) %>%
    ungroup()
  
  seasonal_functions <- bind_rows(seasonal_functions, seasonal_betas)
  
}  # end city loop

seasonal_functions <- seasonal_functions %>%
  mutate(
    date = as.Date(day, origin = "2016-12-31",tz = "UTC")
  )

# Calculate MLE R0 curves for each city

R_0s <- tibble()

for(do_city in c("Agadez", "Maradi", "Niamey", "Zinder")){
  
  # Load fitted parameters and pomp model 
  mle_file <- paste0("../results/initial-mif-lls-", do_city, ".csv")
  
  mles <- read.csv(mle_file) %>% 
    slice(2:n()) %>%  # ignore first row of storage NAs
    filter(loglik == max(loglik, na.rm = TRUE)) %>%
    dplyr::select(-do_grid, -loglik, -loglik_se)
  
  pomp_file <- paste0("../code/measles-pomp-object-", do_city, ".RDS")
  fitted_pomp <- readRDS(pomp_file)
  
  # Calculte R0 
  qis <- mles %>%
    dplyr::select(b1, b2, b3, b4, b5, b6) %>%
    as.numeric()
  
  beta <- mles %>%
    pull(beta_mu)
  
  bases <- as_tibble(fitted_pomp@covar) %>%
    dplyr::select(starts_with("x")) %>%
    dplyr::slice(1:365) %>%
    mutate(
      day = 1:365
    ) %>%
    gather(key = base, value = value, -day)
  
  season <- bases %>%
    spread(key = base, value = value) %>%
    dplyr::select(-day) %>%
    as.matrix()
  
  N <- round(mean(fitted_pomp@covar[, "N"]))
  
  R0 <- calc_R0(beta = beta, qis = qis, season = season)
  
  tmp_out <- tibble(
    city = do_city,
    day = 1:length(R0),
    R0 = R0
  )
  
  R_0s <- bind_rows(R_0s, tmp_out)
}

R_0s <- R_0s %>%
  mutate(
    date = as.Date(day, origin = "2016-12-31",tz = "UTC")
  )

all_R_0s <- left_join(R_0s, seasonal_functions, by = c("city", "day", "date"))

rnaughts <- ggplot(all_R_0s, aes(x = date)) +
  geom_ribbon(aes(ymin = lower_R0, ymax = upper_R0, fill = city), alpha = 0.6) +
  geom_line(aes(y = R0), color = "white") +
  geom_hline(aes(yintercept = 12), linetype = 2, alpha = 0.5) +
  geom_hline(aes(yintercept = 18), linetype = 2, alpha = 0.5) +
  scale_fill_colorblind(name = NULL) +
  scale_color_colorblind(name = NULL) +
  guides(fill = FALSE) +
  facet_wrap(~city,nrow = 2, scales = "free") +
  labs(x = "time of year", y = expression(italic(R[0]))) +
  scale_x_date(date_labels = "%b", date_breaks = "2 months") +
  scale_y_continuous(limits = c(0,35))+
  theme_classic(base_size = 10, base_family = "Times") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(panel.spacing = unit(1, "lines"), strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
       plot.title = element_text(face = "bold")) 
  # ggtitle("Seasonal basic reproduction number")

plot_grid(scatters, rnaughts, scale = 0.9, labels = c("(a)", "(b)"), 
          label_size = 12, label_fontfamily = "Times", label_fontface = 3)
```


# Results

The fitted models adequately reproduce observed dynamics (figure \ref{data-plot}*b*), with in-sample $R^2$s from one-week-ahead predictions ranging from 0.55 for Agadez to 0.89 for Maradi (figure \ref{scatters}*a*).
The fitted models also had lower AIC values than two benchmarking models (table \ref{tab:AIC}).
The estimated seasonality is consistent with previously estimated patterns, including the decline in seasonality amplitude as population size decreases (figure \ref{scatters}*b*) [@Ferrari2008].
Our estimates of $\mathcal{R}_0$ do not all perfectly overlap with the often cited range of 12-18 (figure \ref{scatters}*b*) [@Anderson1982], but more recent reviews suggest that measles' $\mathcal{R}_0$ is much more variable and is context-specific [@Guerra2017].

```{r aic-comp}
data_file <- "../data/clean-data/weekly-measles-incidence-niger-cities-clean.RDS"
measles <- readRDS(data_file) %>%
  filter(year > 1994)

nb_lik <- function(theta) {
  -sum(dnbinom(as.vector(cases),size=exp(theta[1]),prob=exp(theta[2]),log=TRUE))
} 

all_logliks <- tibble()
for(do_city in unique(measles$region)){
  cases <- measles %>%
    filter(region == do_city) %>%
    pull(cases)
  
  # Negative binomial iid sampling model
  nb_mle <- optim(c(0,-5), nb_lik)
  nb_nll <- -nb_mle$value
  
  # SARIMA model
  log_y <- log(as.vector(cases)+1)
  arma_fit <- arima(log_y,order=c(2,0,2),seasonal=list(order=c(1,0,1),period=52), method = "CSS")
  arma_nll <- arma_fit$loglik - sum(log_y) ## log normal likelihood
  
  # SEIR fit log likelihood
  mif_city <- str_sub(do_city, 1, 6)
  seir_nll <- read.csv(file = paste0("../results/initial-mif-lls-", mif_city, ".csv")) %>%
    drop_na() %>%
    filter(loglik == max(loglik)) %>%
    pull(loglik)
  
  # Store results
  all_logliks %>%
    bind_rows(
      tibble(
        City = mif_city,
        `Neg. Binomial` = nb_nll,
        SARIMA = arma_nll,
        SEIR = seir_nll
      )
    ) -> all_logliks
}

num_params <- tibble(
  `Neg. Binomial` = 2,
  SARIMA = 8,
  SEIR = 14
) %>%
  gather(model, k)

all_logliks %>%
  gather(model, loglik, -City) %>%
  left_join(num_params, by = "model") %>%
  mutate(
    AIC = round(2*k - 2*loglik)
  ) %>%
  dplyr::select(-loglik, -k) %>%
  spread(key = model, value = AIC) %>%
  knitr::kable(format = "pandoc", caption = "AIC values for the benchmarking and SEIR models. \\label{tab:AIC}")
```

Our model for Agadez performed poorly relative to the other cities, but still did better than non-mechanistic models (table \ref{tab:AIC}).
Maximum likelihood estimates and bootstrapped 95% confidence intervals for all parameters are in the electronic supplement (tables S4-S7).
Parameter correlations were generally weak (electronic supplement section S9), but the correlation between initial susceptible population size ($S_{t=0}/N_{t=0}$) and transmission rate ($\beta$) was negative and larger than -0.5 for all cities.
Overall, weak parameter correlations indicated high parameter identifiability in the model.

The EWS generally performed as predicted by theory with respect to the approach to re-emergence.
Most EWS increased as the critical transition was approached, resulting in AUC values above 0.5 and often near 1 (figure \ref{emerge-aucs}).
Skewness, kurtosis, and coefficient of variation performed poorly across all levels of susceptible depletion in all cities.

Variance, mean, index of dispersion, autocovariance, and autocorrelation all performed equally well at predicting re-emergence (figure \ref{emerge-aucs}*c*).
Their performance declined as the size of the susceptible pool increased (i.e., a larger susceptible depletion factor).
This is expected because a larger susceptible pool results in more rapid returns to $\mathcal{R}_e(t)=1$, which, in turn, results in shorter null and test intervals, making estimates of EWS less precise [@Brett2017].
Thus, re-emergence may prove difficult to anticipate in "fast" transmission systems, as observed in simulations by ref. @Brett2017 and seen here when susceptible depletion was relatively small (figure \ref{emerge-aucs}*c*).

```{r emergence-results, fig.width=6.5, fig.height=5, fig.cap="Performance of early warning signals (EWS) over fixed windows on the approach to emergence. (*a*) A typical example of an emergence simulation for Maradi. The two vertical blue lines indicate the start (left-most line) and end (line for critical year) of the full window. The black line demarcates the division between the equal-length null and test intervals, in which we show the calculated variance. (*b*) Empirical densities of variance in the null and test intervals across 500 simulations and the associated area under the curve (AUC) statistic. (*c*) Heatmap of AUC statistics for each EWS at each level of susceptible depletion factor. AUC values closer to 0 or 1 indicate higher ability to distinguish among time series near and far from a critical transition. See figure S8 for a visualization of how susceptible depletion factor maps to number of weeks in the null and test intervals.  \\label{emerge-aucs}"}
# mycols <- c("#91CDF0", "#EF6677")
mycols <- c("#008FD5", "#FF2700")  # fivethirtyeight blue/red

ex_file <- "../simulations/emergence-simulations-grid-Maradi-1e-04.RDS"
emerge_sim <- readRDS(ex_file)

re_one_year <- emerge_sim %>%
  group_by(time) %>%
  summarise(mean_re = mean(RE_seas)) %>%  
  mutate(year = round(time)) %>%  # create 'year' variable
  ungroup() %>%
  filter(mean_re >= 1) %>%  # drop times where Re less than 1
  filter(year == min(year) + 1) %>%  # filter to critical transition year
  distinct(year, .keep_all = TRUE) %>%  # drop duplicates
  dplyr::select(year) %>%
  ungroup()

re_path <- emerge_sim %>%
  group_by(time) %>%
  summarise(mean_re = mean(RE_seas)) %>%  
  mutate(year = round(time)) %>%  # create 'year' variable
  ungroup()

one_sim <- emerge_sim %>% 
  filter(sim == 1) %>%
  left_join(re_path) %>%
  mutate(used = ifelse(time <= re_one_year$year, "yes", "no")) %>%
  filter(year < 9)

variance_one_sim <- one_sim %>%
  filter(used == "yes") %>%
  mutate(interval = ifelse(time < max(year)/2, "null", "test")) %>%
  group_by(interval) %>%
  summarise(variance = round(var(reports),1))

variance_all_sim <- emerge_sim %>%
  left_join(re_path) %>%
  mutate(used = ifelse(time <= re_one_year$year, "yes", "no")) %>%
  filter(used == "yes") %>%
  mutate(interval = ifelse(time < max(year)/2, "null", "test")) %>%
  group_by(interval, sim) %>%
  summarise(variance = var(reports))

variance_cats <- variance_all_sim %>%
  ungroup() %>%
  mutate(cat = ifelse(interval == "null", TRUE, FALSE)) 

calc_auc <- function(predictions, is_null){
    r <- rank(predictions)
    r1 <- sum(r[!is_null])
    n1 <- sum(!is_null)
    n2 <- sum(is_null)
    (r1 - n1 * (n1 + 1) / 2) / (n1 * n2)
}

var_auc <- round(calc_auc(variance_cats$variance, variance_cats$cat), 3)

# Case time series
ggplot(filter(one_sim, time < 11.5 & time > 0.6), aes(x = time, y = reports)) +
  geom_line(color = "tan", aes(alpha = used)) +
  geom_vline(aes(xintercept = 0.6), color = "dodgerblue4", linetype = 2) +
  geom_vline(aes(xintercept = re_one_year$year), color = "dodgerblue4", 
             linetype = 2) +
  geom_vline(aes(xintercept = 8/2)) +
  annotate(geom = "text", x = 2.35, y = 50, size = 3,
           label = "null interval", fontface = "bold", family = "Times") +
  annotate(geom = "text", x = 6, y = 50, size = 3,
           label = "test interval", fontface = "bold", family = "Times") +
  annotate(geom = "text", x = 2.35, y = 45, size = 3, family = "Times",
           label = paste("variance =", 
                         filter(variance_one_sim, interval == "null") %>%
                           pull(variance))) +
  annotate(geom = "text", x = 6, y = 45, size = 3, family = "Times",
           label = paste("variance =", 
                         filter(variance_one_sim, interval == "test") %>%
                           pull(variance))) +
  scale_alpha_manual(values = c(0.4, 1)) +
  guides(alpha = FALSE) +
  annotate(geom = "text", x = 7.3, y = 25, label = "end of\ncritical\nyear", 
           size = 3, color = "dodgerblue4", family = "Times") +
  labs(x = "simulation time (year)", y = "reported cases") +
  theme_classic(base_size = 11, base_family = "Times") -> cases_series

# Distribution of variance across simulations
ggplot(variance_all_sim, aes(x = log(variance + 1), fill = interval)) +
  geom_density(size = 0.5, alpha = 0.65, color = "white") +
  annotate(geom = "text", x = 3, y = 1.2, size = 3, family = "Times",
           label = paste("area under the curve:", var_auc)) +
  scale_fill_manual(values = mycols, name = "interval",
                    labels = c("null", "test")) +
  labs(x = "log(variance + 1)", y = "density") +
  coord_cartesian(xlim = c(0, 4)) +
  theme_classic(base_size = 11, base_family = "Times") +
  theme(legend.position = c(0.8, 0.8)) -> dist_plot

# AUC heatmap
emergence_aucs <- read.csv("../results/emergence-grid-aucs.csv") %>%
  filter(metric != "Decay time")

# star_tbl <- tibble(
#   city = "Niamey",
#   x = as.factor(rep(1e-04, 2)),
#   y = c(5.7, 7.7)
# )

emergence_aucs <- emergence_aucs %>%
  mutate(susc_discount = ifelse(susc_discount == 0.0, 1e-04, susc_discount)) %>%
  mutate(metric = tolower(metric))

ggplot() +
  geom_tile(data = emergence_aucs, aes(x = as.factor(susc_discount), y = metric, fill = AUC)) +
  # geom_text(data = star_tbl, aes(x = x, y = y, label = "*"), color = "white", size = 6) +
  scale_fill_viridis(limits = c(0,1), direction = -1, option = "E", name = "AUC") +
  facet_wrap(~city, nrow = 1) +
  labs(x = "susceptible depletion factor (fraction of initial susceptible pool)", y = NULL) +
  theme_minimal(base_family = "Times") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(panel.spacing = unit(1, "lines"),
        strip.text = element_text(face = "bold"),
        plot.title = element_text(size = 11, face = "bold")) -> aucs


row2 <- cowplot::plot_grid(aucs, labels = "(c)", label_size = 12, label_fontfamily = "Times", label_fontface = 3)
row1 <- cowplot::plot_grid(cases_series, dist_plot, scale = 0.9, labels = c("(a)", "(b)"), 
          label_size = 12, label_fontfamily = "Times", label_fontface = 3)
final <- cowplot::plot_grid(row1, row2, ncol = 1, align = "v")
print(final)
```


The EWS performed less well when anticipating elimination, relative to emergence (figure \ref{elim-aucs}).
Only three metrics were reliable: mean, autocovariance, and variance.
All three metrics decreased as $\mathcal{R}_e(t)$ approached the critical transition (figure S6).
As in the case of anticipating elimination, AUC values moved closer to 0.5 as the rate of vaccination increased (figure \ref{elim-aucs}*c*).
<!-- Again, this is because of shorter null and test intervals. -->

```{r elimination, fig.width=6.5, fig.height=5, fig.cap="Performance of early warning signals (EWS) over fixed windows on the approach to elimination. (*a*) A typical example of an elimination simulation for Maradi. The two vertical blue lines indicate the start (left-most line) and end (line for critical year) of the full window. The black line demarcates the division between the equal-length null and test intervals, in which we show the calculated variance. (*b*) Empirical densities of variance in the null and test intervals across 500 simulations and the associated area under the curve (AUC) statistic. (*c*) Heatmap of AUC statistics for each EWS at each speed of approach to herd immunity. AUC values closer to 0 or 1 indicate higher ability to distinguish among time series near and far from a critical transition. See figure S8 for a visualization of how vaccination speed maps to number of weeks in the null and test intervals.  \\label{elim-aucs}"}
example_data <- readRDS("../simulations/single-elimination-example.RDS")[[1]]
ews_data_example <- readRDS("../simulations/single-elimination-example.RDS")[[2]]

variance_example <- ews_data_example %>%
  group_by(half) %>%
  summarise(variance = round(var(reports)))

ggplot() +
  geom_line(data = example_data, aes(x = time, y = reports, group = group), 
            color = "tan", alpha = 0.4, size = 0.3) +
  geom_vline(data = ews_data_example, aes(xintercept = max(time)), 
             color = "dodgerblue4",  linetype = 2) +
  geom_vline(data = ews_data_example, aes(xintercept = min(time)), 
             color = "dodgerblue4",  linetype = 2) +
  geom_vline(data = ews_data_example, aes(xintercept = 50), 
             color = "grey45", linetype = 1) +
  geom_line(data = ews_data_example, aes(x = time, y = reports),
            color = "tan", size = 0.3) +
  annotate(geom = "text", x = 28, y = 1450, size = 3, family = "Times",
           label = "null interval", fontface = "bold") +
  annotate(geom = "text", x = 70, y = 1450, size = 3, family = "Times",
           label = "test interval", fontface = "bold") +
  annotate(geom = "text", x = 36, y = 900, family = "Times",
           label = "improvements \nin routine\nvaccination\nbegin", 
           size = 2.5, color = "grey25") +
  annotate(geom = "text", x = 76, y = 900, family = "Times",
           label = "vaccination\nprobability\nreaches\nherd immunity\nthreshold",
           size = 2.5, color = "dodgerblue4") +
  annotate(geom = "text", x = 28.5, y = 1300, size = 3, family = "Times",
           label = paste("variance =", 
                         filter(variance_example, half == "first") %>% 
                           pull(variance))) +
  annotate(geom = "text", x = 70, y = 1300, size = 3, family = "Times",
           label = paste("variance =", 
                         filter(variance_example, half == "second") %>% 
                           pull(variance))) +
  labs(x = "simulation time (year)", y = "reported cases") +
  theme_classic(base_size = 11, base_family = "Times") -> cases_series

# Plot variance distributions
all_variances <- read_csv("../results/ews-elimination.csv") %>%
  filter(metric == "variance", city == "Maradi", vacc_speed == 0.000015) %>%
  mutate(interval = ifelse(half == "first", "null", "test"),
         variance = value)

variance_cats <- all_variances %>%
  ungroup() %>%
  mutate(cat = ifelse(interval == "null", TRUE, FALSE)) 

calc_auc <- function(predictions, is_null){
    r <- rank(predictions)
    r1 <- sum(r[!is_null])
    n1 <- sum(!is_null)
    n2 <- sum(is_null)
    (r1 - n1 * (n1 + 1) / 2) / (n1 * n2)
}

var_auc <- round(calc_auc(variance_cats$variance, variance_cats$cat),2)

ggplot(data = all_variances, aes(x = log(variance + 1), fill = interval)) +
  geom_density(size = 0.5, alpha = 0.65, color = "white") +
  annotate(geom = "text", x = 9.5, y = 0.4, size = 3, family = "Times",
           label = paste("area under the curve:", var_auc)) +
  scale_fill_manual(values = mycols, name = "interval",
                    labels = c("null", "test")) +
  labs(x = "log(variance + 1)", y = "density") +
  coord_cartesian(xlim = c(6, 11)) +
  theme_classic(base_size = 11, base_family = "Times") +
  theme(legend.position = c(0.8, 0.8)) -> dist_plot

# AUC heatmap
elimination_aucs <- read.csv("../results/elimination-grid-aucs.csv") %>%
  filter(metric != "Decay time") %>%
  mutate(metric = tolower(metric))

ggplot() +
  geom_tile(data = elimination_aucs, aes(x = as.factor(vacc_speed*10000), 
                                         y = metric, fill = AUC)) +
  scale_fill_viridis(limits = c(0,1), direction = -1, option = "E",
                     name = "AUC") +
  facet_wrap(~city, nrow = 1) +
  labs(x = expression(paste("rate of change in vaccination probability (", 
                            phantom()%*%phantom(), 10^{-4}, phantom(0), d^{-1}, ")")), 
       y = NULL) +
  theme_minimal(base_size = 11, base_family = "Times") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(panel.spacing = unit(1, "lines"),
         strip.text = element_text(face = "bold"),
        plot.title = element_text(size = 11, face = "bold")) -> aucs

row2 <- cowplot::plot_grid(aucs, labels = "(c)", label_size = 12, 
                           label_fontfamily = "Times", label_fontface = 3)
row1 <- cowplot::plot_grid(cases_series, dist_plot, scale = 0.9, labels = c("(a)", "(b)"), 
          label_size = 12, label_fontfamily = "Times", label_fontface = 3)
final <- cowplot::plot_grid(row1, row2, ncol = 1, align = "v")
print(final)
```

In summary, our analysis of EWS suggested that indicators of critical slowing down have predictive value for emergence and elimination events.
We found similar results for the approach to elimination when calculating EWS over a moving window of 35 weeks in the null and test intervals (figure S9b).
But, all EWS performed less well when predicting the approach to emergence over the moving window (figure S9).

# Discussion

The ability to detect early warnings of outbreaks of potentially fatal diseases such as measles during non-epidemic periods of unpredictable duration may facilitate planning such as enhanced surveillance to expedite outbreak detection, implementation of serological surveys to identify immunity gaps, and initiation of targeted supplemental vaccination [@Grais2008;@Weldegebriel2011]. 
Further, it has been argued that measles eradication requires consideration of local demographic factors [@Ferrari2013] and that regional outbreak response vaccination can be effective when initiated early, even if coverage is suboptimal [@Grais2008]. 
Consequently indicators that a location or a region is on a path to outbreak or elimination can help to prioritize the timing and distribution of limited resources.
Using empirically-based transmission models, we found that generic indicators of critical slowing down were informative regarding simulated re-emergence and elimination of measles.
Our conclusions are, of course, dependent on the modeling choices we made, but using empirically-based models represents a step in the progression from theory to simulations to applied science.
This work fills the important gap between data-free simulations and application of EWS as part of a decision-support toolkit.

Overall, generic indicators performed better in scenarios of re-emergence compared with elimination. 
Moreover, indicators behaved as expected based on simple one-dimensional models of fluctuations around an equilibrium with gradually declining stability -- the prototypical model of critical slowing down.
This is because the autocorrelation and variance increased on the approach to $\mathcal{R}_e = 1$ (figure \ref{emerge-aucs}*c*).
If, alternatively, the variance had increased but the autocorrelation had not, a better supported model would be an equilibrium with fixed stability but subject to increasing intensity of perturbations.
From a model selection point of view, our simulations of re-emergence support the prototypical model of critical slowing down. 
Moreover, since our simulations were fit to measles data and had relatively high one-step-ahead predictive accuracy on average, it suggests that the prototypical model of critical slowing down may be supported by data sets similar to the ones we fit and can provide predictive value for them.
The definitive test of this approach, or course, would be to record forecasts of re-emergence based on indicators of critical slowing down and evaluate their accuracy as data are accumulated.

We found lag-1 autocorrelation not to be a strong indicator of the transition to elimination (figure \ref{elim-aucs}*c*).
Thus, the prototypical model of critical slowing down appears less useful in this scenario.
Other EWS (variance, autocovariance, and mean) did show altered behavior as the transition to elimination was approached, but these EWS were less sensitive under elimination scenarios compared to re-emergence scenarios.
These results suggest that although distributional changes in indicators occur prior to disease elimination, interpreting these changes as the loss of stability of an endemic equilibrium, or declining $\mathcal{R}_e$, requires a model which accounts for complicating system features such as seasonality, non-linearity, damped oscillations, and local extinction.


```{r susc-deplete}
# Define threshold for outbreak year --------------------------------------

# Outbreaks defined as: an annual case count exceeding x% of the maximum
# annual case count for a region, where x is the threshold set below.
outbreak_threshold <- 0.8  # 80% of max = outbreak year


# Load simulated data -----------------------------------------------------

cities <- c("Agadez", "Maradi", "Niamey", "Zinder")
sim_data <- tibble()
for(do_city in cities){
  tmp_file <- paste0("../simulations/bootstrap-sims-", do_city, ".RDS")
  tmp_data <- readRDS(tmp_file) %>%
    unnest(cols = data) %>%
    mutate(city = do_city)
  sim_data <- bind_rows(sim_data, tmp_data)
}


# Identify outbreak years and calculate S depletion -----------------------

outbreak_years <- sim_data %>%
  mutate(year = trunc(time)) %>%
  group_by(city, sim, year) %>%
  summarise(total_cases = sum(reports),
            max_S = max(S),
            min_S = min(S)) %>%
  mutate(outbreak = ifelse(total_cases > outbreak_threshold*max(total_cases), 
                           TRUE, FALSE),
         max_S_t_minus_1 = lag(max_S),
         susc_depletion = min_S / max_S_t_minus_1) %>%
  filter(outbreak == TRUE) %>%
  drop_na()


# Calculate fraction of depletions less than 0.5 --------------------------

fracs_less_than_half <- outbreak_years %>%
  ungroup() %>%
  group_by(city) %>%
  mutate(
    deplete_half = ifelse(susc_depletion < 0.5, TRUE, FALSE)
  ) %>%
  group_by(city, deplete_half) %>%
  count() %>%
  group_by(city) %>%
  mutate(
    frac_less = n/sum(n)
  ) %>%
  filter(deplete_half == TRUE) %>%
  dplyr::select(city, frac_less)

percs <- fracs_less_than_half$frac_less*100
```

A potential limitation of our findings is that the susceptible depletion factors in our simulation study (figure \ref{emerge-aucs}*c*) might be smaller than the factors that occur in reality.
A small depletion factor corresponds to a large level of susceptible depletion.
To check the relevance of this concern, we calculated the level of susceptible depletion after outbreaks (defined as years where the total number of cases reached 80% of the maximum observed) across one hundred replicate simulations (electronic supplement).
We found that susceptible depletion was less than 0.5, the smallest susceptible depletion level we tested, for `r round(percs[1], 1)`% of outbreaks in Agadez, `r round(percs[2])`% of outbreaks in Maradi, `r round(percs[3])`% of outbreaks in Niamey, and `r round(percs[4])`% of outbreaks in Zinder.
These statistics do not detract from our main finding of critical slowing down in measles dynamics, but do suggest that EWS might be less useful in some cases than in others.
For example, AUC values for emergence at the 0.5 level of susceptible depletion were already low for most cities (figure \ref{emerge-aucs}*c*).
Thus, our methods may not be practical for cities that rarely experience levels of susceptible depletion below 0.5 (e.g., Agadez).

We focused on fixed windows for calculating EWS based on the timing of the critical transition.
Thus, our work also does not represent how EWS would be operationalised in online mode.
The fixed windows were specifically designed to test whether EWS could detect a known critical transition and limit the additional complexity associated with choosing a moving window size.
Supplemental simulations showed that all EWS performed more poorly when using a moving window (electronic supplement section S11), suggesting that choosing the temporal width of the moving window is important for application of EWS in real-world settings.
\new{Determining the optimal moving window width is non-trivial [@Brett2020] and is beyond the scope of this article.}
\new{Nonetheless, our analyses show that several EWS can detect critical transitions in representatively noisy SEIR dynamics.}
\new{Providing this link from theory to application through empirically-base models represents an important step toward operationalising EWS.}

Unpredictable, recurring outbreaks with seasonality in transmission such as those observed for measles in Niger during 1995--2005 are challenging settings for the application of EWS in part because most theory regarding the behavior of EWS [@ORegan2018;@Brett2017] is based on models that exhibit simpler dynamics. 
Consequently, the development of robust, model-independent early warning systems for infectious diseases [@Han2016] likely will benefit from further study of the behavior of EWS in complex models.
Also, although we have shown that critical slowing down precedes tipping points in stochastic models that were fit to data with state-of-the-art methods, how to operationalize the phenomenon of critical slowing down remains an open research area [@Shmueli2010].
Emerging technologies like artificial intelligence might offer new ways to find optimal detection thresholds for early warning signals [@Brett2020].
But there will likely always be a role for expert judgment.
Early warning signals, although powerful and now accompanied with additional support, will likely be just one part of a decision-support toolkit.

# Acknowledgements
We thank Tobias Brett for comments on the modeling approach and Paige Miller and ric Marty for helpful comments on early versions of this work.
We thank Epicentre/MSF-OCP and the Niger Ministry of Health for making the data available.

# Funding
This research was funded by the National Institute of General Medical Sciences of the National Institutes of Health (Award Number U01GM110744).
The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.
This work was done on the Olympus High Performance Compute Cluster located at the Pittsburgh Supercomputing Center at Carnegie Mellon University, which is supported by National Institute of General Medical Sciences Modeling Infectious Disease Agent Study (MIDAS) Informatics Services Group grant 1U24GM110707.

# Authors' contributions
ATT conceived of the study, designed the study, carried out the statistical and modeling analysis, and drafted the manuscript; EBO participated in the design of the study, participated in statistical and modeling analysis, and critically revised the manuscript; MJF and AWP helped revise the manuscript; PR participated in the conception and design of the study, guided the statistical and modeling analysis, and helped draft and revise the manuscript; JMD coordinated the study, participated in the conception and design of the study, guided the statistical and modeling analysis, and helped draft and revise the manuscript.
All authors gave final approval for publication and agree to be held accountable for the work performed therein.

# References
