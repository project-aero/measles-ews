---
title: "Supporting Information for:"
subtitle: "Anticipating disease emergence and elimination: a test of early warning signals using empirically based models"
author: 
 - Andrew T. Tredennick
 - Eamon B. O'Dea
 - Matthew J. Ferrari
 - Andrew W. Park
 - Pejman Rohani
 - John M. Drake
output: 
  pdf_document:
    number_sections: true
    toc_depth: 2
    keep_tex: true
    keep_md: true
date: "`r Sys.Date()`"
csl: proceedings-of-the-royal-society-b.csl
bibliography: ./measles-ews.bib
header-includes:
  - \renewcommand{\thefootnote}{\fnsymbol{footnote}}
  - \renewcommand{\theequation}{S.\arabic{equation}}
  - \renewcommand{\thetable}{S\arabic{table}}
  - \renewcommand{\thefigure}{S\arabic{figure}}
  - \renewcommand{\thesection}{S\arabic{section}.}
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage{amsmath,amssymb}
  - \usepackage{mathptmx}
  - \newcommand{\comment}[1]{\ignorespaces}
---

```{r libraries, include=FALSE, message=FALSE, warning=TRUE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE)
library(tidyverse)
library(lubridate)
library(stringr)
library(dplyr)
library(pomp)
library(ggthemes)
library(cowplot)
library(GGally)
```

# Demographic data used in model fitting
We used two sources of demographic data to help constrain model fitting: total population size (*N*) and birth rate ($\mu$).
Both sets of data are reported on an annual basis.
To incorporate the data in our model, we fit splines through the annual observations to interpolate daily values (figure \ref{demog-plot}).
Note that the daily interpolated birth rate is still in units of "per year," which is why births are modeled as $\mu N \times \Delta t$ to include the effect of the daily time step $\Delta t$.

```{r demo-data, fig.width=8.5, fig.height=3, fig.cap="Plots of the demographic data used for model fitting. The points are the actual data and the lines are the interpolated spline fits. Population data is at the disrict level, meaning we have different data for each focal city. Birth rate data is national, meaning each city shares the same birth rates. \\label{demog-plot}"}

annual_pop <- read.csv("../data/raw-data/district_pops_colnames.csv")
colnames(annual_pop) <- c("region", as.character(1995:2005))
annual_births <- read_csv("../data/raw-data/niger_crude_birth_rates.csv",
                          col_types = cols(
  date = col_character(),
  births_per_thousand = col_double()
))
demog_clean <- readRDS("../data/clean-data/annual-demographic-data-niger-cities-clean.RDS")

# Births
birth_data <- annual_births %>%
  mutate(
    date = mdy(date),  # lubridate prefixes any 2digit year 00-68 with 20, 
                       # not a problem for us though
    year = as.character(year(date)),
    rate_per_person_per_year = births_per_thousand/1000
  ) %>%
  dplyr::select(year, rate_per_person_per_year) %>%
  mutate(year = as.numeric(year)) %>%
  filter(year > 1994 & year < 2006) %>%
  mutate(time = year+0.000)

ggplot() +
  geom_line(data = filter(demog_clean, time <= 2005), aes(x = time, y = birth_per_person_per_year), color = "grey35") +
  geom_point(data = birth_data, aes(x = time, y = rate_per_person_per_year), color = "grey35") +
  labs(x = "Time", y = expression(paste("Annual per capita birth rate (", mu, ")"))) +
  scale_color_colorblind(name = NULL) +
  theme_minimal() -> birth_plot

# Population
pop_data <- annual_pop %>%
  gather(key = year, value = population, -region) %>%
  mutate(
    region = ifelse(region == "Niamey I", "Niamey", region),
    year = as.numeric(year),
    time = year + 0.000  # make time double
  ) %>%
  filter(region %in% c("Agadez", "Maradi", "Niamey", "Zinder"))

demog_clean <- demog_clean %>%
  mutate(
    region = ifelse(region == "Agadez (City)", "Agadez", region),
    region = ifelse(region == "Maradi (City)", "Maradi", region),
    region = ifelse(region == "Niamey (City)", "Niamey", region),
    region = ifelse(region == "Zinder (City)", "Zinder", region)
  )

ggplot() +
  geom_line(data = filter(demog_clean, time <= 2005), aes(x = time, y = population_size/1000, color = region)) +
  geom_point(data = pop_data, aes(x = time, y = population/1000, color = region)) +
  labs(x = "Time", y = expression(paste("Population size, ", italic(N), " (1000s)"))) +
  scale_color_colorblind(name = NULL) +
  theme_minimal() +
  theme(legend.position = c(0.2, 0.9),
        legend.key.size = unit(1, 'lines')) -> pop_plot

plot_grid(birth_plot, pop_plot, nrow = 1, align = "h")
```

# Stochastic simulations from the fitted models

Here we show stochastic simulations from the fitted models (figure \ref{stoch-sims}).
Simulations are all initialized from the same initial conditions, which were estimated as part of model fitting.

```{r stoch-sims, fig.cap="Stochastic simulations from the fitted models. Each colored line is a single realization of the model from the same initial conditions. Ten simulations are shown. The black lines are the observed data. We do not expect model simulations to perfectly align with the data because of the multiple sources of stochasticity present. Thus, these simulations should be judged by their ability to reproduce dynamical features of the data. \\label{stoch-sims}", fig.width=8.5, fig.height=4}

code_files <- list.files("../code/")
pomp_ids <- grep("measles-pomp-object", code_files)
pomp_files <- code_files[pomp_ids]

results_files <- list.files("../results/")
mle_ids <- grep("mif-lls", results_files)
mle_files <- results_files[mle_ids]
boot_ids <- grep("boot", mle_files)
mle_files <- mle_files[-boot_ids]

source("../code/make-legacy-pomp-filtering-function.R")

all_sims <- tibble()
for(do_file in pomp_files){
  tmp_city <- str_sub(do_file, start = 21, end = nchar(do_file)-4)
  tmp_pomp <- readRDS(paste0("../code/", do_file))
  

  
  city_mle_ids <- grep(tmp_city, mle_files)
  tmp_mles <- read.csv(paste0("../results/", mle_files[city_mle_ids])) %>%
    drop_na() %>%
    filter(loglik == max(loglik)) %>%
    dplyr::select(-loglik, -loglik_se, -do_grid)

  obs_data <- data.frame(time = tmp_pomp@times, reports = as.numeric(tmp_pomp@data))
  covar_data <- cbind(time = tmp_pomp@tcovar, as.data.frame(tmp_pomp@covar))
  
  sim <- make_pomp_filter(obs_data = obs_data, 
                          covar_data = covar_data, 
                          mles = unlist(tmp_mles))
  
  tmp_sim <- pomp::simulate(
    sim,
    params = unlist(tmp_mles),
    nsim = 10,
    as.data.frame = TRUE,
    include.data = TRUE
  ) %>%
    dplyr::select(time, sim, reports, S) %>%
    mutate(city = tmp_city) %>%
    filter(time >= 1995)
  
  all_sims <- bind_rows(all_sims, tmp_sim)
}

ggplot() +
  geom_line(data = filter(all_sims, sim != "data"), aes(x = time, y = reports, color = sim), alpha = 0.25) +
  geom_line(data = filter(all_sims, sim == "data"), aes(x = time, y = reports)) +
  guides(color = "none") +
  facet_wrap(~city, scales = "free_y") +
  labs(x = "Date", y = expression(sqrt(Reports))) +
  scale_y_sqrt() +
  theme_minimal()
```

# Comparisons with benchmarking models
Here
The results in table \ref{tab:AIC} show the AIC values for each model.
The AIC values for the SEIR models are lowest for all cities, suggesting that the addition of mechanism via explicit disease transmission dynamics substantially improves model fit.



# Long-run simulations from the fitted the SEIR models
For fitting the SEIR model, we used known population size interpolated between years.
This meant we were able to ignore certain demographic processes.
For example, we ignored deaths from the susceptible pool under the assumption that the infection rate was much faster than the death rate.
We also ignored the recovered class completely because their dynamics, outside of the contribution to population size (which we assumed to be known), do not impact the $S, E, \text{or } I$ compartments.
However, we needed to include births and deaths from all compartments, including $R$, when simulating the model over arbitrarily long time periods that do not necessarily represent real times for which we would have information on population size.

We added a few terms to the SEIR model presented in the main text to account for births and deaths in all compartments.
Our strategy was to simulate a population at a dynamic equilibrium, where total population was neither increasing or decreasing over time, but it does fluctuate.
Our *simulating model* (in contrast to the *fitting model* in the main text) is as follows.

As in the main text, the SEIR model is specified as a set of difference equations,

\begin{align}
S_{t+ \Delta t} - S_{t} &= n_{0S,t} - n_{SE,t} - n_{S0,t} \\
E_{t+ \Delta t} - E_{t} &= n_{SE,t} - n_{EI,t} - n_{E0,t} \\
I_{t+\Delta t} - I_{t} &= n_{EI,t} + n_{0I,t} - n_{IR,t} - n_{I0,t} \\
R_{t+\Delta t} - R_{t} &= n_{0R,t} + n_{IR,t} - n_{R0,t},
\end{align}

\noindent{}where $\textbf{n}_t$ are random variables representing the number of individuals transitioning into or out of each class at each update $t \rightarrow t+\Delta t$.
Transition definitions are in table \ref{tab:transitions}.

| Random variable | Transition | $\left(\Delta S, \Delta E, \Delta I, \Delta R\right)$ |
| ---------- | ----------------------------| ---------- |
| $n_{0S}$ | Births into the *S* compartment, not vaccinated | (1, 0, 0, 0) |
| $n_{SE}$ | Number of people transitioning from *S* to *E* | (-1, 1, 0, 0) |
| $n_{S0}$ | Number of deaths leaving *S* | (-1, 0, 0, 0) |
| $n_{EI}$ | Number of people transitioning from *E* to *I* | (0, -1, 1, 0) |
| $n_{E0}$ | Number of deaths leaving *E* | (0, -1, 0, 0) |
| $n_{0I}$ | Number of imported infections | (0, 0, 1, 0) |
| $n_{IR}$ | Number of people transitioning from *I* to *R* | (0, 0, -1, 1) |
| $n_{I0}$ | Number of deaths leaving *I* | (0, 0, -1, 0) |
| $n_{0R}$ | Births into the *R* compartment, vaccinated | (0, 0, 0, 1) |
| $n_{R0}$ | Number of deaths leaving *R* | (0, 0, 0, -1) |

Table: Transitions in the simulating model. \label{tab:transitions}

The stochastic random variables are specified as follows:

\begin{align}
n_{0S,t} &\sim \text{Poisson}((1-p_t)\mu N \times \Delta t) \\
(n_{SE,t}, n_{S0,t}) &\sim \text{EulerMultinomial}(S_{t}, (\beta_t I_t / N, \nu), \Delta t) \\
(n_{EI,t}, n_{E0,t}) &\sim \text{EulerMultinomial}(E_{t}, (\eta, \nu), \Delta t)  \label{eq:emulti} \\
(n_{IR,t}, n_{I0,t}) &\sim \text{EulerMultinomial}(I_{t}, (\gamma, \nu), \Delta t) \\
n_{I0,t} &\sim \text{Poisson}(\psi \times \Delta t) \\
n_{0R,t} &\sim \text{Poisson}(p_t \mu N \times \Delta t) \\
n_{R0,t} &\sim \text{EulerMultinomial}(R_t, (\nu), \Delta t),
\end{align}
\noindent{}where $p_t$ is the vaccination probability (set at $p = 0.7$), $\mu$ is the constant birth rate (set at $\mu = 0.05$), $N$ is the equilibrium population size, $\sim \text{EulerMultinomial}(T, r_i, \Delta t)$ specifies that the variables on the left of $\sim$ follow an Euler Multinomial distribution for $T$ individuals with hazard rates $r_i$ and step size $\Delta t$, $\beta_t$ is a time-varying rate of transmission, $\eta$ is a time-invariant rate of transfer from the exposed class to the infectious class, $\gamma$ is a time-invariant recovery rate, $\nu$ is the constant death rate, and $\psi$ is the rate of imported infections (estimated by the model). 
The Euler Multinomial distribution corresponds to a multinomial distribution where the event probabilities $P_i$ are determined by the Euler time step $\Delta t$ and the hazard rates $r_i$, according to 
\begin{align}
P_0 &= \exp( -\sum_i r_i \Delta t), \\
P_i &= (1 - P_0) r_i / (\sum_i r_i)\qquad \text{for} \qquad i > 0.
\end{align}
Event zero is the event that an individual stays in its initial compartment and does not contribute to the vector $\textbf{n}_t$.
To provide a specific example, equation \eqref{eq:emulti} corresponds to 
\begin{equation}
(E_{t} - n_{EI,t} - n_{E0,t}, \,n_{EI,t},\, n_{E0,t}) \sim \text{Multinomial}(E_{t}; P_0, (1 - P_0) \eta /(\eta + \nu), (1 - P_0) \nu / (\eta + \nu)),
\end{equation}
where $P_0 =  \exp(-(\eta + \nu) \Delta t)$.
We set $1/\eta = 8$ days, $1/\gamma = 5$ days, and $\nu = 0.05$ per year. 
We used a daily time step of $\Delta t = \text{year} / 365$.
Setting the birth rate equal to $\mu N$ and the *per capita* death rate equal to $\nu = \mu$ makes $N$ a stable equilibrium population size.
We modeled the rate of transmission as:
\begin{equation}
\beta_t = \beta \left(1 + \exp \left(\sum^6_{i=1} q_i \xi_{i_{t}}\right) \right) \Gamma_t.
\end{equation}
$\beta$ is the minimum transmission rate over the season and the term $\sum^6_{i=1} q_i \xi_{i_{t}}$ is a B-spline to model seasonality in transmission.
The B-spline bases ($\xi_{i_{t}}$) are periodic with a 1 year period.
The transmission rate ($\beta_t$) is also subject to stochastic process noise at each time step, $\Gamma_t$, which we model as gamma-distributed white (temporally uncorrelated) noise with mean 1 and intensity $\sigma^2$ [@Breto2011].

Finally, observations were simulated from the model on a weekly time step by drawing counts of cases ($y_t$) from a negative binomial distribution centered on the number of people that transitioned from the infectious to recovered class over seven days ($x_t$), subject to estimated reporting rate ($\rho$), and with a dispersion parameter equal to the MLE: $y_t \sim \text{Negative Binomial}(\rho x_t, \tau)$, where we use the same parameterization of the negative binomial as described in our model definition in the main text.

In this model, the effective reproduction number can be approximated as:

$$
\mathcal{R}_e(t) \approx \frac{S_t}{N_t} \frac{\eta \beta_t}{(\eta + \nu)(\gamma + \nu)}.
$$

The model described above was implemented in the `R` package `pomp` [@King2016; @King2018] to simulate the re-emergence and elimination scenarios.

# Computing the time of critical transitions
To define the null and test intervals for our simulations of re-emergence and elimination, we need to know when the critical transition between alternative modes of fluctuation occurs.
For re-emergence, we defined the critical year as the year in which the effective reproduction number ($\mathcal{R}_e$) reaches or exceeds the critical value of 1.  
When determining the critical year, we eliminate the variation in $\mathcal{R}_e$ that arises from the gamma white noise factor and thus calculate the expected value of $\mathcal{R}_e(t)$ over the set of all simulation replicates at time $t$.
From a window ranging from the beginning of the simulation to the end of the critical year, we defined the null interval as the first half of the window (far from $\mathcal{R}_e = 1$) and the test interval as the second half of the window (near $\mathcal{R}_e = 1$).
Figure \ref{emerge-sim} shows a typical example.

```{r emerge-windows, fig.width=6, fig.cap="A typical emergence simulation for Maradi where the susceptible depletion factor was 1e-04. (*a*) The simulated trajectory of $\\mathcal{R}_e$ and the end of the year in which $\\mathcal{R}_e$ first reaches the critical value of 1 (denoted by dashed blue line). (*b*) The simulated trajectory of the number of cases. Note that the x-axis has been reduced relative to the top panel. The two vertical blue lines indicate the start (left-most line) and end (line for end of critical year) of the full window. The black line demarcates the division between the equal-length null and test intervals. \\label{emerge-sim}"}
ex_file <- "../simulations/emergence-simulations-grid-Maradi-1e-04.RDS"
emerge_sim <- readRDS(ex_file)

re_one_year <- emerge_sim %>%
  group_by(time) %>%
  summarise(mean_re = mean(RE_seas)) %>%  
  mutate(year = round(time)) %>%  # create 'year' variable
  ungroup() %>%
  filter(mean_re >= 1) %>%  # drop times where Re less than 1
  filter(year == min(year) + 1) %>%  # filter to critical transition year
  distinct(year, .keep_all = TRUE) %>%  # drop duplicates
  dplyr::select(year) %>%
  ungroup()

re_path <- emerge_sim %>%
  group_by(time) %>%
  summarise(mean_re = mean(RE_seas)) %>%  
  mutate(year = round(time)) %>%  # create 'year' variable
  ungroup()

one_sim <- emerge_sim %>% 
  filter(sim == 1) %>%
  left_join(re_path, by = "time") %>%
  mutate(used = ifelse(time <= re_one_year$year, "yes", "no"))

re_series <- ggplot(filter(one_sim, time < 11.5), aes(x = time, y = mean_re)) +
  geom_line(color = "tan", aes(alpha = used)) +
  geom_hline(aes(yintercept = 1), color = "grey35", linetype = 3) +
  geom_vline(aes(xintercept = re_one_year$year), color = "dodgerblue4", linetype = 2) +
  annotate(geom = "text", x = 10, y = 0.3, label = "End\nof\ncritical\nyear", size = 3, color = "dodgerblue4") +
  scale_alpha_manual(values = c(0.5, 1)) +
  guides(alpha = "none") +
  labs(x = "Simulation time (year)", y = expression(R[e])) +
  theme_classic(base_size = 12)

cases_series <- ggplot(filter(one_sim, time < 11.5), aes(x = time, y = reports)) +
  geom_line(color = "tan", aes(alpha = used)) +
  geom_vline(aes(xintercept = 0), color = "dodgerblue4", linetype = 2) +
  geom_vline(aes(xintercept = re_one_year$year), color = "dodgerblue4", linetype = 2) +
  geom_vline(aes(xintercept = re_one_year$year /2)) +
  annotate(geom = "text", x = 1.75, y = 250, label = "Null window") +
  annotate(geom = "text", x = 5.25, y = 250, label = "Test window") +
  scale_alpha_manual(values = c(0.4, 1)) +
  guides(alpha = "none") +
  annotate(geom = "text", x = 7.35, y = 150, label = "End\nof\ncritical\nyear", size = 3, color = "dodgerblue4") +
  labs(x = "Simulation time (year)", y = "Reported cases") +
  theme_classic(base_size = 12)

plot_grid(re_series, cases_series, nrow = 2, align = "v", 
          scale = 0.9, labels = c("(a)", "(b)"), label_size = 12,
          label_fontfamily = "Times", label_fontface = 3)
```

For simulations of disease elimination by increasing the vaccination probability of the population, we define the critical time as the year in which the vaccination probability reaches the threshold needed for herd immunity.
This vaccination threshold is defined as $p^* = 1 - 1/\mathcal{R}_0$.
Because our transmission function is seasonal, we first approximated time-specific $\mathcal{R}_0$ as: $\mathcal{R}_0(t) = \frac{\eta \beta_t}{(\eta+\nu)(\gamma+\nu)}$, where $1/\eta$ is the incubation period, $1/\gamma$ is the infectious period, $\beta_t$ is the time-specific rate of transmission, and $\nu$ is the death rate. 
Only $\beta_t$ is estimated by our model. 
We set $1/\eta$ = 8 days, $1/\gamma$ = 5 days, and $\nu$ = 0.05 per year.
Figure 2 in the main text shows our estimates of $\mathcal{R}_0$ over the course of a year using this approximation.
We took a conservative approach for calculating the vaccination threshold by using the maximum value of $\mathcal{R}_0(t)$ out of the range of values in its seasonal variation. 
That is, we used $p^* = 1 - 1/\text{max}(\mathcal{R}_0(t))$ as the threshold value.
We set the time at which the vaccination probability is equal to this threshold value as the endpoint for the EWS analysis.
All elimination simulations had vaccination improvements that started at year 50.
So, we define the test interval as the times between the beginning of year 50 and the time at which the vaccination probability is equal to $p^*$.
We then defined the null interval as a window with length equal to the test interval and ending at the end of year 49.
Figure \ref{elimin-sim} shows a typical example.

```{r elim-ex, fig.width=6, fig.cap="A typical elimination simulation for Maradi where the rate of change in vaccination probability is 1.5e-05 per day. The null and test intervals are defined based on the time at which the vaccination improvements begin (year 50, black line) and the year at which the vaccination probability reaches the threshold for herd immunity (right-most dashed blue line). The beginning of the null interval is determined by the length of the series from time 50 to the time of reaching the immunity threshold: the null interval ends at time 50 (when the vaccination improvements begin) and starts at whatever time results in a series that is equal in length to the test interval. \\label{elimin-sim}"}

example_data <- readRDS("../simulations/single-elimination-example.RDS")[[1]]
ews_data_example <- readRDS("../simulations/single-elimination-example.RDS")[[2]]

rho_curve_ramp <- function(t, start = 50, speed = 1.5e-05){
  ifelse(
    t <= start,
    rho <- 0.7,
    # rho <- 0.3 * (1 - exp((t - start) * -0.015 speed)) + 0.7  # exponential
    rho <- min(0.7 + (t - start)*speed, 1)  # linear
  )
  return(rho)
}

years <- 100
weeks <- years*52
days <- years*365
vacc_coverage_ts <- sapply(0:days, FUN = rho_curve_ramp, 
                           start = 50*365, speed = 1.5e-05)

vacc_ex_tbl <- tibble(
  time = 1:length(vacc_coverage_ts),
  coverage = vacc_coverage_ts
)


vacc_plot <- ggplot(vacc_ex_tbl, aes(time/365, coverage)) +
  geom_line(color = "dodgerblue4") +
  geom_hline(aes(yintercept = 0.7), linetype = 2, 
             size = 0.25, color = "grey45") +
  geom_hline(aes(yintercept = unique(example_data$threshold)), linetype = 2, 
             size = 0.25, color = "grey45") +
  annotate(geom = "text", x = 81, y = 0.72, color = "grey45",
           label = "Current vaccination probability in Niger", size = 3) +
  annotate(geom = "text", x = 25, y = 0.91, color = "grey45",
           label = "Vaccination probability for herd immunity", size = 3) +
  scale_y_continuous(limits = c(0.7, 1)) +
  labs(x = NULL, y = "Vaccination\nprobability") +
  theme_classic(base_size = 14)

ts_plot <- ggplot() +
  geom_line(data = example_data, aes(x = time, y = reports, group = group), color = "tan", alpha = 0.4, size = 0.3) +
  geom_vline(data = ews_data_example, aes(xintercept = max(time)), color = "dodgerblue4",  linetype = 2) +
  geom_vline(data = ews_data_example, aes(xintercept = min(time)), color = "dodgerblue4",  linetype = 2) +
  geom_vline(data = ews_data_example, aes(xintercept = 50), color = "grey45", linetype = 1) +
  geom_line(data = ews_data_example, aes(x = time, y = reports), color = "tan", size = 0.3) +
  annotate(geom = "text", x = 28, y = 1450, label = "Null window") +
  annotate(geom = "text", x = 70, y = 1450, label = "Test window") +
  annotate(geom = "text", x = 41, y = 900, label = "Improvement\nin routine\nvaccination\nbegins", size = 3, color = "grey25") +
  annotate(geom = "text", x = 81, y = 900, label = "Vaccination\nprobability\nreaches\nherd immunity\nthreshold", size = 3, color = "dodgerblue4") +
  labs(x = "Simulation time (year)", y = "Reported cases") +
  theme_classic(base_size = 14)

plot_grid(vacc_plot, ts_plot, rel_heights = c(1, 1), ncol = 1, align = "v")

```

# Early warning signals

We calculated nine early warning signals using the ```spaero::get_stats()``` function.
Formulas for the early warning signals are in table \ref{tab:ews}.

| EWS | Estimator | Theoretical Correlation with $\mathcal{R}_e(t)$ in an emergence scenario |
| -------------------- | ----------------------------------- | ------------------------ |
| Mean | \( \bar{y} = \sum_{i=1}^n \frac{y_i}{n} \) | Positive |
| Variance | \( s^2 = \sum_{i=1}^n \frac{(y_i - \bar{y})^2}{n} \) | Positive |
| Coefficient of variation | \( \frac{ s }{ \bar{y} } \) | Null |
| Index of dispersion | \( \frac{ s^2 }{ \bar{y} } \) | Positive |
| Skewness | \( \frac{1}{s^3} \sum_{i=1}^n \frac{\left( y_i - \bar{y} \right)^3}{n} \) | Positive |
| Kurtosis | \( \frac{1}{s^4} \sum_{i=1}^n \frac{\left( y_i - \bar{y} \right)^4}{n} \) | Positive |
| Autocovariance | \( s^2_1 =  \sum^{n}_{i=2} \frac{\left( y_i - \bar{y} \right)\left( y_{i - 1}  - \bar{y} \right)}{n} \) | Positive |
| Autocorrelation | \( r_1 = \frac{s^2_1 }{ s^2} \) | Positive |
| Decay time | \( -1 / \text{ln}(r_1) \) | Positive |

Table: List of candidate early warning signals and their estimating equations. See @Brett2018 for details, as well as moving window versions which we use in the section "Moving window analysis" in the following. \label{tab:ews}

# Trends of early warning signals

Theory suggests that most EWS should increase as disease dynamics
approach a critical transition from below (emergence).  When
approaching the critical transition from above (elimination), we are not aware of any well-developed  theoretical predictions applicable to our model.

To confirm that the EWS are behaving as expected, and to provide empirical results for cases in which we lack expectations, we plotted histograms of the EWS for the test and null intervals for both simulation types, emergence and elimination.

```{r ews-hists, message=FALSE, warning=TRUE, echo = FALSE, fig.cap="Histograms of EWS from emergence simulations where the susceptible depletion factor was 1e-04.", fig.height=5}
emerge_ews <- read.csv("../results/ews-emergence.csv") %>%
  filter(metric != "variance_first_diff" & susc_discount == 0.0)  %>%
  mutate(metric = as.character(metric)) %>%
  mutate(
    metric = ifelse(metric == "variance", "Variance", metric),
    metric = ifelse(metric == "variance_first_diff", "Var. 1st Diff.", metric),
    metric = ifelse(metric == "autocovariance", "Autocovar.", metric),
    metric = ifelse(metric == "autocorrelation", "Autocorr.", metric),
    metric = ifelse(metric == "decay_time", "Decay\ntime", metric),
    metric = ifelse(metric == "mean", "Mean", metric),
    metric = ifelse(metric == "index_of_dispersion", "Index of\ndispersion", metric),
    metric = ifelse(metric == "coefficient_of_variation", "Coeff. var.", metric),
    metric = ifelse(metric == "skewness", "Skewness", metric),
    metric = ifelse(metric == "kurtosis", "Kurtosis", metric)
  )

gout <- list()
for(do_city in sort(unique(emerge_ews$city))){
  if(do_city != "Zinder"){
    gout[[do_city]] <- ggplot(filter(emerge_ews, city == do_city), aes(fill = half, x = value)) +
      geom_histogram(bins = 20) +
      facet_wrap(~metric, scales = "free", nrow = 1) +
      scale_fill_manual(values = c("tan", "dodgerblue4")) +
      theme_minimal(base_size = 8) +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      guides(fill = "none") +
      labs(y = "Count", x = "") +
      ggtitle(do_city)
  }

  if(do_city == "Zinder"){
    gout[[do_city]] <- ggplot(filter(emerge_ews, city == do_city), aes(fill = half, x = value)) +
      geom_histogram(bins = 20) +
      facet_wrap(~metric, scales = "free", nrow = 1) +
      scale_fill_manual(values = c("tan", "dodgerblue4"), labels = c("Null", "Test"), name = NULL) +
      theme_minimal(base_size = 8) +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      labs(y = "Count", x = "EWS value") +
      ggtitle(do_city)
  }

}

ews_hists <- cowplot::plot_grid(
  plotlist = gout,
  nrow = 4,
  labels = c("(a)", "(b)", "(c)", "(d)"),
  label_size = 12,
  label_fontfamily = "Times", 
  label_fontface = 3
)
print(ews_hists)
```

```{r ews-hists2, message=FALSE, warning=TRUE, echo = FALSE, fig.cap="Histograms of EWS from elimination simulations where the rate of change in vaccination probability is equal to 1.5e-05 per day.", fig.height=5}
elimination_ews <- read.csv("../results/ews-elimination.csv") %>%
  filter(metric != "variance_first_diff" & vacc_speed == 1.5e-05) %>%
  mutate(metric = as.character(metric)) %>%
  mutate(
    metric = ifelse(metric == "variance", "Variance", metric),
    metric = ifelse(metric == "variance_first_diff", "Var. 1st Diff.", metric),
    metric = ifelse(metric == "autocovariance", "Autocovar.", metric),
    metric = ifelse(metric == "autocorrelation", "Autocorr.", metric),
    metric = ifelse(metric == "decay_time", "Decay\ntime", metric),
    metric = ifelse(metric == "mean", "Mean", metric),
    metric = ifelse(metric == "index_of_dispersion", "Index of\ndispersion", metric),
    metric = ifelse(metric == "coefficient_of_variation", "Coeff. var.", metric),
    metric = ifelse(metric == "skewness", "Skewness", metric),
    metric = ifelse(metric == "kurtosis", "Kurtosis", metric)
  )

gout <- list()
for(do_city in sort(unique(emerge_ews$city))){
  if(do_city != "Zinder"){
    gout[[do_city]] <- ggplot(filter(elimination_ews, city == do_city), aes(fill = half, x = value)) +
      geom_histogram(bins = 20) +
      facet_wrap(~metric, scales = "free", nrow = 1) +
      scale_fill_manual(values = c("tan", "dodgerblue4")) +
      theme_minimal(base_size = 8) +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      guides(fill = "none") +
      labs(y = "Count", x = "") +
      ggtitle(do_city)
  }

  if(do_city == "Zinder"){
    gout[[do_city]] <- ggplot(filter(elimination_ews, city == do_city), aes(fill = half, x = value)) +
      geom_histogram(bins = 20) +
      facet_wrap(~metric, scales = "free", nrow = 1) +
      scale_fill_manual(values = c("tan", "dodgerblue4"), labels = c("Null", "Test"), name = NULL) +
      theme_minimal(base_size = 8) +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      labs(y = "Count", x = "EWS value") +
      ggtitle(do_city)
  }

}

ews_hists <- cowplot::plot_grid(
  plotlist = gout,
  nrow = 4,
  labels = c("(a)", "(b)", "(c)", "(d)"),
  label_size = 12,
  label_fontfamily = "Times", 
  label_fontface = 3
)
print(ews_hists)
```

# Bootstrapped parameter confidence intervals

We used a bootstrap approach to estimate approximate 95\% confidence intervals for all parameters.
Below we show summary statistics for all parameters except the B-splines.
For B-splines, and transmission rate more generally, we plot the seasonal transmission rate function for all bootstrap replicates (figure \ref{season-trans}).

```{r param-summaries, message=FALSE, warning=TRUE, echo = FALSE, results = "asis"}

# Define computation grid -------------------------------------------------

nboots <- 100
nmifs <- 50
comp_grid <- expand.grid(1:nboots, 1:50)
colnames(comp_grid) <- c("boot_series", "param_set")
comp_grid$do_grid <- 1:nrow(comp_grid)


# Load loglikelihood results and combine ----------------------------------

result_files <- list.files("../results/")
mle_files <- result_files[grep("initial-mif-lls", result_files)]

mles <- tibble()
for(do_file in mle_files){
  tmp <- read.csv(paste0("../results/", do_file)) %>%
    drop_na() %>%
    filter(loglik == max(loglik)) %>%
    dplyr::select(loglik, loglik_se, beta_mu, beta_sd, iota, rho, tau, S_0, E_0, I_0) %>%
    gather(key = parameter, value = mle) %>%
    mutate(city = str_sub(do_file, 17, (nchar(do_file)-4)))
  
  mles <- bind_rows(mles, tmp)
}

loglik_files <- list.files("../results/", pattern = "bootstrap-mif-lls")
param_summaries <- tibble()

for(do_file in loglik_files){
  do_city <- str_sub(do_file, 19, -5)
  tmp_file <- read.csv(paste0("../results/", do_file)) %>%
    slice(2:n()) %>%  # ignore first row of NAs
    left_join(comp_grid, by = "do_grid") %>%  # merge in comp grid info
    group_by(boot_series) %>%
    filter(loglik == max(loglik)) %>%
    ungroup() %>%
    dplyr::select(-do_grid, -loglik, -loglik_se, -boot_series, -param_set,
                  -b1, -b2, -b3, -b4, -b5, -b6) %>%
    gather(key = parameter, value = mle_value) %>%
    group_by(parameter) %>%
    summarise(
      mean_value = mean(mle_value),
      median_value = median(mle_value),
      std_dev = sd(mle_value),
      upper_95_ci = quantile(mle_value, 0.975),
      lower_95_ci = quantile(mle_value, 0.025)
    ) %>%
    mutate(city = do_city)
  
  param_summaries <- bind_rows(param_summaries, tmp_file)
  }

mle_and_boots <- left_join(mles, param_summaries, by = c("parameter", "city"))

# Load example pomp file for basis function
pomp_file <- "../code/measles-pomp-object-Agadez.RDS"
measles_pomp <- readRDS(pomp_file)  # exemplar bases


# Calculate seasonal transmission functions -------------------------------

bases <- as_tibble(measles_pomp@covar) %>%
  dplyr::select(starts_with("x")) %>%
  dplyr::slice(1:365) %>%
  mutate(
    day = 1:365
  ) %>%
  gather(key = base, value = value, -day)

season <- bases %>%
  spread(key = base, value = value) %>%
  dplyr::select(-day) %>%
  as.matrix()

seasonal_functions <- tibble()
for(do_file in loglik_files){
  do_city <- str_sub(do_file, 19, -5)
  
  b_splines <- read.csv(paste0("../results/", do_file)) %>%
    slice(2:n()) %>%  # ignore first row of NAs
    left_join(comp_grid, by = "do_grid") %>%  # merge in comp grid info
    group_by(boot_series) %>%
    filter(loglik == max(loglik)) %>%
    ungroup() %>%
    dplyr::select(b1, b2, b3, b4, b5, b6)
  
  betas <- read.csv(paste0("../results/", do_file)) %>%
    slice(2:n()) %>%  # ignore first row of NAs
    left_join(comp_grid, by = "do_grid") %>%  # merge in comp grid info
    group_by(boot_series) %>%
    filter(loglik == max(loglik)) %>%
    ungroup() %>%
    dplyr::select(beta_mu)
  
  seasonal_betas <- tibble()
  for(i in 1:nrow(b_splines)){
    qis <- as.numeric(b_splines[i, ])
    beta_tmp <- as.numeric(betas[i, "beta_mu"])
    
    seasonal_tmp <- tibble(
      beta = as.numeric((1+exp(season %*% qis)) * beta_tmp),
      day = 1:365,
      boot = i
    )
    seasonal_betas <- bind_rows(seasonal_betas, seasonal_tmp)
  }  # end bootstrap loop
  
  seasonal_betas <- seasonal_betas %>%
    mutate(city = do_city)
  
  seasonal_functions <- bind_rows(seasonal_functions, seasonal_betas)
  
}  # end city loop

param_summaries <- mle_and_boots %>%
  mutate(
    parameter = ifelse(parameter == "loglik", "Log likelihood", parameter),
    parameter = ifelse(parameter == "loglik_se", "Log likelihood S.E.", parameter),
    parameter = ifelse(parameter == "beta_mu", "$\\beta$", parameter),
    parameter = ifelse(parameter == "beta_sd", "$\\sigma$", parameter),
    parameter = ifelse(parameter == "rho", "$\\rho$", parameter),
    parameter = ifelse(parameter == "iota", "$\\psi$", parameter),
    parameter = ifelse(parameter == "S_0", "$S_{t=0} / N_{t=0}$", parameter),
    parameter = ifelse(parameter == "E_0", "$E_{t=0} / N_{t=0}$", parameter),
    parameter = ifelse(parameter == "I_0", "$I_{t=0} / N_{t=0}$", parameter),
    parameter = ifelse(parameter == "tau", "$\\tau$", parameter)
  ) %>%
  select(parameter, mle, mean_value, median_value, std_dev, lower_95_ci, upper_95_ci, city) %>%
  rename(
    `Parameter` = parameter,
    `MLE` = mle,
    `Mean` = mean_value,
    `Median` = median_value,
    `SD` = std_dev,
    `Upper 95% CI` = upper_95_ci,
    `Lower 95% CI` = lower_95_ci
  )
```

```{r param-tables, message=FALSE, warning=TRUE, echo = FALSE, results = "asis"}

for(do_city in unique(param_summaries$city)){
  tmp_table <- param_summaries %>%
  filter(city == do_city) %>%
  select(-city) %>%
  mutate_if(is.numeric, ~as.character(signif(., 3)))

  docap <- paste0("Maximum likelihood estimates and summary statistics of parameters from bootstrapped estimates for ", do_city, ".")
  print(knitr::kable(tmp_table, format = "pandoc", caption = docap))
}
```

```{r plot-seasonal-transmission, fig.cap="Bootstrap replicates of estimated seasonal transmission functions. \\label{season-trans}", fig.width=8.5, fig.height=3}

seasonal_functions <- seasonal_functions %>%
  mutate(
    date = as.Date(day, origin = "2016-12-31", tz = "UTC")
  )

ggplot(seasonal_functions, aes(x = date, y = beta, group = boot)) +
  geom_line(alpha = 0.3, color = "dodgerblue4") +
  labs(x = "Date", y = expression(paste("Tranmission rate, ",beta[t], " (", yr^-1, ")"))) +
  scale_x_date(date_labels = "%b", date_breaks = "2 months") +
  facet_wrap(~city, nrow = 1) +
  theme_minimal()

```

# Correlations among parameters

We computed parameter correlations using the 100 parametric bootstrapped samples.
Correlations were generally weak (see plots below), suggesting parameter identifiability.
The strongest correlation was between the minimum tranmission rate ($\beta$) and the initial susceptible population size ($S_{t=0}/N_{t_0}$).
This correlation was negative for all cities, meaning that as the estimate of initial susceptible population size increased the estimate of minimum transmission rate decreased.

```{r param-cors, fig.width=8.5, fig.height=3}
column_names <- c("S", "E", "I", "beta", "sigma", "psi", "rho", "tau")
all_params <- tibble()
for(do_file in loglik_files){
  do_city <- str_sub(do_file, 19, -5)
  tmp_file <- read.csv(paste0("../results/", do_file)) %>%
    slice(2:n()) %>%  # ignore first row of NAs
    left_join(comp_grid, by = "do_grid") %>%  # merge in comp grid info
    group_by(boot_series) %>%
    filter(loglik == max(loglik)) %>%
    ungroup() %>%
    dplyr::select(-do_grid, -loglik, -loglik_se, -boot_series, -param_set,
                  -b1, -b2, -b3, -b4, -b5, -b6) %>%
    dplyr::select(S_0, E_0, I_0, everything())
  colnames(tmp_file) <- column_names
  print(ggcorr(tmp_file, parse = TRUE, label = TRUE) +
          ggtitle(do_city))
}
```

# Length of null and test intervals

In the main text we show EWS performance across the range of susceptible depletion factors and vaccination improvement speeds we modeled.
To put these values into context, here we show the corresponding window sizes for each simulation.
These window sizes are the number of weeks that occur in the null and test intervals (Figure \ref{bws}).

```{r bw-weeks, fig.width=8.5, fig.height=4, fig.cap="Length of null and test intervals (in weeks) for emergence and elimination simulations at different parameter values.  \\label{bws}"}
read_csv("../results/emergence-bandwidths-colnames.csv",
         col_types = cols(
           row_number = col_integer(),
  city = col_character(),
  susc_discount = col_double(),
  bandwidth = col_integer()
)) %>%
  ggplot(aes(x = susc_discount, y = bandwidth, color = city)) +
  geom_line() +
  geom_point(size = 3) +
  labs(x = "Susceptible depletion factor", 
       y = "Number of weeks in interval",
       title = "Length of emergence intervals") +
  scale_color_colorblind(name = NULL) +
  guides(color = "none") +
  theme_minimal() -> emerge_ints

read_csv("../results/elimination-bandwidths-colnames.csv",
         col_types = cols(
  row_number = col_integer(),
  city = col_character(),
  vacc_speed = col_double(),
  bandwidth = col_integer()
)) %>%
  ggplot(aes(x = vacc_speed, y = bandwidth, color = city)) +
  geom_line() +
  geom_point(size = 3) +
  labs(x = "Rate of change in vaccination probability (per day)", 
       y = "Number of weeks in interval",
       title = "Length of elimination intervals") +
  scale_color_colorblind(name = NULL) +
  theme_minimal() +
  theme(legend.position = c(0.8,0.8)) -> elimin_ints

cowplot::plot_grid(emerge_ints, elimin_ints, nrow = 1, align = "h")

```

# Moving window analysis

To complement our fixed window analysis presented in the main text, we conducted a moving window analysis as might be conducted on real surveillance data.
We used the same null and test intervals as described above for the emergence and elimination scenarios.
However, instead of calculating a single value for each EWS over the entire window of the interval, we calculated EWS in the intervals over moving windows of 35 weeks.
We then calculated the Kendall's rank correlation ($\tau$) between each EWS and time in each of the null and test intervals.
We used the distributions of Kendall's $\tau$ over the 500 replicate simulations to then calculate the Area Under the Curve (AUC) metric for each EWS.
For the approach to elimination, the results are similar to those for the fixed window analysis (Figure \ref{mvw-ews}B).
For the approach to emergence, however, the moving window results show much worse performance for Agadez and Zinder, and, on average, the AUC values are lower for all EWS in each city (Figure \ref{mvw-ews}A).


```{r plot-aucs, fig.width=8.5, fig.height=5.5, fig.cap="Performance of early warning signals (EWS) over a moving window. Correlations between EWS (calculated over 35 week moving windows) and time were calculated over two intervals, one far from a critical transition and one near, for simulations of re-emergence (*a*) and elimination (*b*). EWS performance is quantified using the AUC metric, which we show here as a heatmap of AUC values. AUC values farther from 0.5 indicate higher ability to distinguish among time series near and far from a critical transition.  \\label{mvw-ews}"}
library(viridis)
emergence_aucs <- read.csv("../results/emergence-mvw-grid-aucs.csv")
elimination_aucs <- read.csv("../results/elimination-mvw-grid-aucs.csv")

emerge_plot <- ggplot() +
  geom_tile(data = emergence_aucs, aes(x = as.factor(susc_discount), y = metric, fill = AUC)) +
  scale_fill_viridis(limits = c(0,1), direction = -1, option = "E", name = "AUC") +
  facet_wrap(~city, nrow = 1) +
  labs(x = "Susceptible depletion factor", y = NULL) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(panel.spacing = unit(1, "lines"),
        plot.title = element_text(size = 11, face = "bold")) +
  ggtitle("Anticipating emergence over a moving window")

eliminate_plot <- ggplot() +
  geom_tile(data = elimination_aucs, aes(x = as.factor(vacc_speed*10000), y = metric, fill = AUC)) +
  scale_fill_viridis(limits = c(0,1), direction = -1, option = "E", name = "AUC") +
  facet_wrap(~city, nrow = 1) +
  labs(x = expression(paste("Rate of change in vaccination probability (", phantom()%*%phantom(), 10^{-4}, phantom(0), d^{-1}, ")")), y = NULL) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(panel.spacing = unit(1, "lines"),
        plot.title = element_text(size = 11, face = "bold")) +
  ggtitle("Anticipating elimination over a moving window")

cowplot::plot_grid(emerge_plot, eliminate_plot, nrow = 2, align = "v", labels = c("(a)", "(b)"), label_size = 12,
                   label_fontfamily = "Times", label_fontface = 3)
```


# Susceptible depletion after outbreaks

We *a priori* defined the magnitude of susceptible depletion in our models of measles re-emergence.
Thus, a potential limit to our study is that the actual magnitudes of susceptible depletion are less than the values we modeled.
That is, maybe we modeled very unrealistic levels of susceptible depletion, making our results interesting but not useful.
To test the importance of this limitation, we calculated the relative decline of the susceptible class after outbreak years.
We used the 100 replicate simulations that were used for parametric bootstrapping.
These simulations adequately reproduce the general dynamics of measles in each city, including outbreak size.
We used the simulations because the replicates gave us more outbreaks to work with than the observed data alone.

For each of the 100 replicates for each city, we defined an "outbreak year" as any year in which the cumulative number of reported cases exceeded 80% of the maximum number of cumulative cases observed across all years.
We then calculated susceptible depletion (i.e., the susceptible depletion fraction used in our modeling study) as the minimum number of susceptible individuals in the outbreak year divided by the maximum number of susceptible individuals in the previous year.
For example, let year *t* be an outbreak year where the cumulative number of cases exceeded 80% of the maximum cumulative cases observed.
The level of susceptible depletion between year $t-1$ and year $t$ is then: $\min(\{S_i \text{ in year } t\})/\max(\{S_i \text{ in year } t-1\})$.
Essentially, this metric tells us the depletion factor that would need to be applied to *S* at its peak in year *t - 1* to match the reduction in $S$ caused by the outbreak of the size in year *t*.
Histograms for each city are in Figure \ref{susc-disc}.

```{r, fig.width=4, fig.height=3, fig.cap="Histograms of susceptible depletion factors for each city. Values were calculated by comparing the number of susceptible individuals before and after large outbreaks from 100 replicate simulations from the fitted models for each city.  \\label{susc-disc}"}
# Define threshold for outbreak year --------------------------------------

# Outbreaks defined as: an annual case count exceeding x% of the maximum
# annual case count for a region, where x is the threshold set below.
outbreak_threshold <- 0.8  # 80% of max = outbreak year


# Load simulated data -----------------------------------------------------

cities <- c("Agadez", "Maradi", "Niamey", "Zinder")
sim_data <- tibble()
for(do_city in cities){
  tmp_file <- paste0("../simulations/bootstrap-sims-", do_city, ".RDS")
  tmp_data <- readRDS(tmp_file) %>%
    unnest(cols = data) %>%
    mutate(city = do_city)
  sim_data <- bind_rows(sim_data, tmp_data)
}


# Identify outbreak years and calculate S depletion -----------------------

outbreak_years <- sim_data %>%
  mutate(year = trunc(time)) %>%
  group_by(city, sim, year) %>%
  summarise(total_cases = sum(reports),
            max_S = max(S),
            min_S = min(S)) %>%
  mutate(outbreak = ifelse(total_cases > outbreak_threshold*max(total_cases), 
                           TRUE, FALSE),
         max_S_t_minus_1 = lag(max_S),
         susc_depletion = min_S / max_S_t_minus_1) %>%
  filter(outbreak == TRUE) %>%
  drop_na()


# Calculate fraction of depletions less than 0.5 --------------------------

fracs_less_than_half <- outbreak_years %>%
  ungroup() %>%
  group_by(city) %>%
  mutate(
    deplete_half = ifelse(susc_depletion < 0.5, TRUE, FALSE)
  ) %>%
  group_by(city, deplete_half) %>%
  count() %>%
  group_by(city) %>%
  mutate(
    frac_less = n/sum(n)
  ) %>%
  filter(deplete_half == TRUE) %>%
  dplyr::select(city, frac_less)


# Plot boxplots of susceptible depletion ----------------------------------

ggplot() +
  geom_histogram(data = filter(outbreak_years, city == "Agadez"), 
                 aes(x = susc_depletion, fill = city), 
                 color = "white", binwidth = 0.05) +
  geom_histogram(data = filter(outbreak_years, city == "Maradi"), 
                 aes(x = susc_depletion, fill = city), 
                 color = "white", binwidth = 0.05) +
  geom_histogram(data = filter(outbreak_years, city == "Niamey"), 
                 aes(x = susc_depletion, fill = city), 
                 color = "white", binwidth = 0.05) +
  geom_histogram(data = filter(outbreak_years, city == "Zinder"), 
                 aes(x = susc_depletion, fill = city), 
                 color = "white", binwidth = 0.05) +
  geom_vline(aes(xintercept = 0.5), color = "grey25", linetype = 2) +
  labs(y = "Number of outbreaks", x = "Level of susceptible depletion") +
  scale_fill_colorblind(name = NULL) +
  theme_minimal(base_size = 12)
```



# References
