---
title: "Compare EWS and model-based outbreak detection"
author: "Andrew Tredennick"
date: 2019-02-07
output: html_notebook
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(pomp)
library(foreach)
library(doParallel)

knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

# Motivation
Parametric models of disease dynamics are data hungry and take a lot of time and effort to fit.
However, their mechanistic basis may lead to better predictions of outbreaks in highly seasonal systems.
Model-independent early warning signals (EWS), on the other hand, lack mechanism but are easy to calculate and require less data.
An open question is whether parametric models are worth the effort.
That is, are EWS just as good for half the hassle?

In this notebook, I answer the above question by predicting large vs. small outbreaks from a fitted parametric *SEIR* model and from EWS.

# Methods

## Defining large and small outbreaks
The first step is to classify the seasonal epidemics as outbreaks and non-outbreaks.
To do this, I will fit a general mixture model of two exponentials.
The break point between the two defines the incidence at which we classify an outbreak as large or small.
I use incidence, rather than raw case numbers, so I can combine the data from all the cities, increasing the sample size to a decent level.

```{r classify-outbreaks}
# Load measles data
fname <- "../../data/clean-data/weekly-measles-incidence-niger-cities-clean.RDS"
measles_data <- readRDS(fname) %>%
  filter(year > 1994)  # remove 1994 year, only used for modeling

# Make population df
pop_data <- tibble(
  region = c("Agadez (City)", "Maradi (City)", 
             "Niamey (City)", "Zinder (City)"),
  pop = c(118224, 267249, 1027000, 322935)  # from Wikipedia
)

# Summarize to cumulative yearly cases
cusum_data <- measles_data %>%
  group_by(region, year) %>%
  summarise(cases = sum(cases)) %>%
  left_join(pop_data, by = "region") %>%  # add in population data
  mutate(incidence = cases/pop)  # calculate incidence

x <- sort(cusum_data$incidence)  # extract incidence data

# Fit null distribution for starting values
fit1 <- MASS::fitdistr(x, "exponential")

# Define likelihood of mixed exponential
mixexplik <- function(p, lambda1, lambda2) {
  z <- p*dexp(x,lambda1) + (1-p)*dexp(x,lambda2)
  return(-sum(log(z)))
}

# Fit the model
mle_fit <- suppressWarnings(  # ignore warnings about bad guesses
  stats4::mle(minuslogl = mixexplik, 
              start= list(p = 0.2,
                          lambda1 = as.numeric(fit1$estimate), 
                          lambda2 = as.numeric(fit1$estimate)), 
              method="Nelder-Mead")
)

# Calculate the boundary incidence between small and large outbreaks
boundary <- qexp(p = 0.5, rate = mle_fit@coef["p"]*mle_fit@coef["lambda1"])
```

The GMM suggests that the boundary between small and large outbreaks is an incidence level of ```r round(boundary, 4)```.

## Simulate a new series
The next step is to simulate a new time series from the fitted models.
I do this because we want to predict outbreaks as if we are dealing with new data, not the same exact data used to fit the model.
For now, I am just going to focus on Niamey as a test case.

```{r sim-new-data}
# Load pomp object
pomp_object <- readRDS("../../code/measles-pomp-object-Niamey.RDS")

# Load MLEs
mle_file <- paste0("../../results/initial-mif-lls-Niamey.csv")
mles <- read.csv(mle_file) %>%
  as_tibble() %>%
  filter(loglik == max(loglik, na.rm = TRUE)) %>%
  dplyr::select(-do_grid, -loglik, -loglik_se)

sim <- as_tibble(
    simulate(pomp_object, params = mles, nsim = 1, as.data.frame = TRUE,
             include.data = FALSE, seed = 12345278)
  ) %>%
  filter(time >= 1995) %>%
  dplyr::select(sim, time, reports, S, E, I, RE_seas) %>%
  mutate(year = trunc(time)) %>%
  group_by(year) %>%
  mutate(cumulative_cases = sum(reports)) %>%
  mutate(incidence = cumulative_cases/1027000) %>%  # divide cases by population
  mutate(outbreak_year = ifelse(incidence < boundary, FALSE, TRUE)) %>%
  ungroup() %>%
  mutate(date = unique(measles_data$date))

ggplot(sim, aes(x = date, y = reports)) +
  geom_line(aes(group = year, color = outbreak_year)) +
  ggtitle("Simulated time series from the MLE model")
```

## Predict trajectories of the new series
Now we can use the fitted model to predict trajectories, informed by data, via particle filtering.
The idea is to use particle filtering up to a certain time point *t* and then make forecasts for $t + 1, t + 2, t + 3, \dots, t + T$, where *T* is the final week we wish to forecast.
To start, *t* will be the end of the year and *T* will be the end of the next year.
Eventually we will look across forecasts that start from $t-0, t-1, t-2, t-3, \dots, t-k$, where *k* is a week very close to the end of the previous year's measles season (around calendar week 40).

As an initial attempt, I will focus on the large outbreak in 2000 of the simulated series.
The "data" will be reports from week 40 to week 52 in 1999.
Forecasts will be made for all of 2000 (52 weeks).

```{r plot-data-used}
test_data <- sim %>%
  filter(year(date) < 2000) %>%
  filter(year(date) == 1999 | (year(date) == 1998 & week(date) > 30)) %>%
  mutate(split = ifelse(year(date) == 1998, 
                        "initial conditions", 
                        "to be forecast"))

ggplot(test_data, aes(x = date, y = reports)) +
  geom_line(aes(color = split)) +
  ggtitle("Data for initial conditions and to be forecast")
```

For this initial test, I'm going to use the data in red above as known initial conditions for the forecasts from the parametric model.
In practice, I think I should use a particle filter to get the initial states up to a certain point and then forecast from those filtering distributions.
Essentially, I am removing initial conditions error for now.

First, make a `pomp` model that can take a set of initial conditions and then simulate forward.

```{r make-pomp, eval = TRUE}
make_pomp_simulator <- function(do_city, mles, years_to_sim = 1, init)
{
  library(tidyverse)
  library(pomp)
  
  # Define stochastic process (SDEs) 
  
  measles_process <- Csnippet(
    "
    // Define the variables
    int nrate = 7;            // number of rates
    double rate[nrate];	  	  // transition rates
    double trans[nrate];   	  // transition numbers
    double lambda;            // force of infection
    double beta;              // transmission rate
    double eta = 365/8;       // infectious rate (8 days latent)
    double gamma = 365/5;     // recovery rate (5 days infectious)
    double dW;                // white noise
    double seas;              // seasonality term
    double dNS0, dN0S, dNSE;  // S transitions
    double dNE0, dNEI;        // E transitions
    double dN0I, dNI0, dNIR;  // I transitions
    double dN0R, dNR0;        // R transitions

    // Calculate force of infection
    seas = (1 + exp(dot_product(K, &xi1, &b1)));
    beta = beta_mu*seas;
    lambda = beta*I/N;
    
    // Gamma noise, mean=dt, variance=(beta_sd^2 dt)
    dW = rgammawn(beta_sd, dt);
    
    // Compute the transition rates
    rate[0] = nu;           // susceptible deaths
    rate[1] = lambda*dW/dt; // force of infection
    rate[2] = nu;           // exposed deaths
    rate[3] = eta;          // infectious rate from latent
    rate[4] = nu;           // infected deaths
    rate[5] = gamma;	      // recovery from infectious
    rate[6] = nu;           // recovered deaths
    
    // Compute the state transitions
    reulermultinom(2, S, &rate[0], dt, &trans[0]);
    reulermultinom(2, E, &rate[2], dt, &trans[2]);
    reulermultinom(2, I, &rate[4], dt, &trans[4]);
    reulermultinom(1, R, &rate[6], dt, &trans[6]);
    
    // Transitions
    dNS0 = trans[0];                                // susceptible deaths
    dN0S = rpois(vacc_discount * mu * N * dt);      // births, unvaccinated
    dNSE = trans[1];                                // S -> E
    dNE0 = trans[2];                                // exposed deaths
    dNEI = trans[3];                                // E -> I
    dN0I = rpois(eta * dt);                         // imported infections
    dNI0 = trans[4];                                // infected deaths
    dNIR = trans[5];                                // I -> R
    dN0R = rpois((1-vacc_discount) * mu * N * dt);  // births, vaccinated
    dNR0 = trans[6];                                // recovered deaths
    
    // Balance the equations
    S += dN0S - dNSE               - dNS0;
    E +=        dNSE - dNEI        - dNE0;
    I += dN0I        + dNEI - dNIR - dNI0;
    R += dN0R               + dNIR - dNR0;
    
    cases += dNIR;  // cumulative reports at end of infectious period (I->R)
    RE_seas = ((eta*beta*(vacc_discount * mu)) / (nu*(eta+nu)*(gamma+nu))) * (S / N);
    "
  )
  
  
  # Define likelihood function 
  
  measles_dmeasure <- Csnippet(
    "
    double mean;
    double f;
    mean = cases*rho;
    if (ISNA(reports)) {  // for catching missing observations
      lik = (give_log) ? 0 : 1;
    } else {
      f = dnbinom_mu(reports, 1/tau, mean, give_log);  // neg binomial likelihood
    }
    
    lik = (give_log) ? log(f) : f;
    "
  )
  
  
  # Define process simulator for observations 
  
  measles_rmeasure <- Csnippet(
    "
    reports = rnbinom_mu(1/tau, rho*cases);  // neg binomial measurement process
    
    if (reports > 0.0) {
      reports = nearbyint(reports);
    } else {
      reports = 0.0;
    }
    "
  )
  
  # Define parameter transformation scales 
  
  from_estimation <- Csnippet(
    "
    Tiota = exp(iota);
    Trho = expit(rho);
    Tbeta_sd = exp(beta_sd);
    Ttau = exp(tau);
    "
  )
  
  to_estimation <- Csnippet(
    "
    Tiota = log(iota);
    Trho = logit(rho);
    Tbeta_sd = log(beta_sd);
    Ttau = log(tau);
    "
  )
  
  initial_values <- Csnippet(
    "
    S = S_0;
    E = E_0;
    I = I_0;
    R = R_0;
    cases = rho*I_0;
    RE_seas = 0;
    "
  )
  
  all_times <- seq(0, years_to_sim, by = 1/365)
  report_times <- all_times[seq(1, length(all_times), 7)]
  
  # Make data tables
  the_data <- tibble(
    time = report_times,
    reports = NA
  )
  
  # Generate basis functions for seasonality
  covar_table <- periodic.bspline.basis(
    all_times,
    nbasis = 6,
    degree = 3,
    period = 1,
    names = "xi%d"
  ) %>%
    as_tibble() %>%
    mutate(
      time = all_times
    )
  
  vacc_discount <-  0.3
  global_str <- paste0(
    "int K = 6; double mu = 0.05; double nu = 0.05;", 
    " double S_0 = ", init$S, ";",
    " double E_0 = ", init$E, ";",
    " double I_0 = ", init$I, ";",
    " double R_0 = ", init$R, ";",
    " double N = ", round(init$N), ";",
    " double vacc_discount = ", vacc_discount, ";"
  )
  
  simulator_pomp <- pomp(
    data = the_data,
    times = "time",
    covar = covar_table,
    tcovar = "time",
    t0 = min(the_data$time),
    rprocess = euler.sim(step.fun = measles_process, delta.t = 1/365),
    rmeasure = measles_rmeasure,
    dmeasure = measles_dmeasure,
    initializer = initial_values,
    statenames = c("S", "E", "I", "R", "cases", "RE_seas"),
    toEstimationScale = to_estimation,
    fromEstimationScale = from_estimation,
    paramnames = names(mles),
    params = unlist(mles),
    globals = global_str,
    zeronames = c("cases")
  )
  
  return(simulator_pomp)
}
```

Now feed the initial conditions to the model and simulate trajectories.

```{r sim-trajectories}
pop_size <- readRDS("../../data/clean-data/annual-demographic-data-niger-cities-clean.RDS") %>%
  filter(trunc(time) == 1998, region == "Niamey (City)") %>%
  filter(time == max(time)) %>%
  pull(population_size)

initial_conditions <- test_data %>%
  filter(year(date) == 1998) %>%
  filter(date == max(date)) %>%
  dplyr::select(S, E, I) %>%
  mutate(N = pop_size,
         R = round(N - (S + E + I)))

pomp_simulator <- make_pomp_simulator(do_city = "Niamey", mles = mles %>% dplyr::select(-S_0, -E_0, -I_0), 
                                      years_to_sim = 1, 
                                      init = initial_conditions)
rep_trajectories <- pomp_simulator %>%
  simulate(nsim = 1000, as.data.frame = TRUE, 
           include.data = FALSE, seed = 18431236) %>%
  as_tibble() %>%
  filter(time > 0)  # remove initial conditions time step

rep_for_plot <- rep_trajectories %>%
  group_by(sim) %>%
  mutate(cumulative_cases = cumsum(reports)) %>%
  dplyr::select(time, sim, reports, cumulative_cases) %>%
  mutate(outbreak_year = ifelse(max(cumulative_cases) > boundary * 1027000, TRUE, FALSE)) %>%
  gather(key, value, -time, -sim, -outbreak_year)
  
ggplot(rep_for_plot, aes(x = time, y = value, group = sim, color = outbreak_year)) +
  geom_line(alpha = 0.5, size = 0.3) +
  facet_wrap(~key, scales = "free_y", ncol = 2)
```

See this, https://kingaa.github.io/sbied/ebola/ebola.html, for ideas on setting up a particle filter that transitions to forecasting.

## Forecasting code
```{r forecast-functions, eval = FALSE}
filter_states <- function(pomp_obj, param_df, num_particles = 2000){
  pf <- pomp::pfilter(pomp_obj, params = unlist(param_df), 
                      Np = num_particles, save.states = TRUE)
  pf@saved.states[-1]
}

simulate_over_obs <- function(pomp_obj, param_df, nreps){
  pp <- pomp::parmat(unlist(param_df), nrep = nreps)
  pomp::simulate(pomp_obj, params = pp, include.data = TRUE, 
                 as.data.frame = TRUE)
}

simulate_forecasts <- function(pomp_obj, train_sims, time_start, time_end,
                               param_df, nreps, states_list){ 
  start_time_id <- which(round(time(pomp_obj),3) == time_start)
  end_time_id <- which(round(time(pomp_obj),3) == time_end)
  forecast_times <- time(pomp_obj)[start_time_id:end_time_id]
  
  pomp_forecast <- pomp_obj
  time(pomp_forecast) <- forecast_times
  timezero(pomp_forecast) <- forecast_times[1]
  
  population_size_t0 <- train_sims %>% 
    filter(round(time,3) == time_start, sim == "data") %>% 
    pull(N)
  initial_proportions <- t(all_states[[start_time_id]]) %>%
    as_tibble() %>%
    dplyr::select(S, E, I) %>%
    dplyr::mutate(S_0 = S/population_size_t0,
                  E_0 = E/population_size_t0,
                  I_0 = I/population_size_t0) %>%
    dplyr::select(-S, -E, -I) %>%
    t()
    
  pp <- pomp::parmat(unlist(param_df), nrep = nreps)
  pp[rownames(initial_proportions), ] <- initial_proportions
  pomp::simulate(pomp_forecast, params = pp, include.data = FALSE, 
                 as.data.frame = TRUE)
}

do_city <- "Zinder"
pomp_mod_file <- paste0("../../code/measles-pomp-object-", do_city, ".RDS")
mle_file <- paste0("../../results/initial-mif-lls-", do_city, ".csv")
data_file <- "../../data/clean-data/weekly-measles-incidence-niger-cities-clean.RDS"

pop_data <- tibble(
  region = c("Agadez", "Maradi", 
             "Niamey", "Zinder"),
  pop = c(118224, 267249, 1027000, 322935)  # from Wikipedia
)

city_pop <- pop_data %>% filter(region == do_city) %>% pull(pop)


M1 <- readRDS(pomp_mod_file) 
mles <- read_csv(mle_file) %>%
  filter(loglik == max(loglik, na.rm = TRUE)) %>%
  dplyr::select(-do_grid, -loglik, -loglik_se)
the_data <- readRDS(data_file) %>%
  filter(region == paste0(do_city, " (City)"))

time_date_map <- tibble(
  pomp_time = round(time(M1), 3),
  calendar_date = the_data$date,
  year = year(calendar_date),
  week = week(calendar_date)
)

forecast_start_times <- time_date_map %>%
  filter(year > 1994, week > 29, year < 2005) %>%
  dplyr::select(-calendar_date, -week) 

forecast_end_times <- time_date_map %>%
  filter(year > 1995, week == 52) %>%
  dplyr::select(-calendar_date, -week) %>%
  mutate(year = year - 1)

new_data <- pomp::simulate(M1, nsim = 1, seed = 123857, 
                           as.data.frame = TRUE, include.data = FALSE) 

M1@data["reports", ] <- t(new_data$reports)
all_states <- filter_states(M1, mles, num_particles = 50)

all_probs <- tibble()
for(do_year in unique(forecast_start_times$year)){
  year_time_grid <- expand.grid(
    filter(forecast_start_times, year == do_year) %>% pull(pomp_time),
    filter(forecast_end_times, year == do_year) %>% pull(pomp_time)
  )

  tmp_probs <- foreach::foreach(i = 1:nrow(year_time_grid), 
                                .combine = rbind) %do%
    {
    tstart <- year_time_grid[i, 1]
    tend <- year_time_grid[i, 2]
    
    train_sims <- simulate_over_obs(M1, mles, nreps = ncol(all_states[[1]]))
    forecasts <- simulate_forecasts(pomp_obj = M1, train_sims = train_sims, 
                                    time_start = tstart, time_end = tend, 
                                    param_df = mles, 
                                    nreps = ncol(all_states[[1]]), 
                                    states_list = all_states)
    
    forecasts %>%
      mutate(year = trunc(time)) %>%
      group_by(sim, year) %>%
      summarise(total_reports = sum(reports)) %>%
      filter(year == max(year)) %>%
      ungroup() %>%
      mutate(incidence = total_reports/city_pop,
             outbreak_year = ifelse(incidence >= boundary, TRUE, FALSE)) %>%
      group_by(year, outbreak_year) %>%
      count() %>%
      ungroup() %>%
      mutate(week = i+29)
    }
  all_probs <- bind_rows(all_probs, tmp_probs)
}


# Add in TRUE/FALSE for each year as needed
template <- expand.grid(c(TRUE, FALSE), 
                        unique(all_probs$year), 
                        unique(all_probs$week))
colnames(template) <- c("outbreak_year", "year", "week") 

new_data_classified <- new_data %>%
  dplyr::select(time, reports) %>%
  mutate(year = trunc(time)) %>%
  group_by(year) %>%
  summarise(total_cases = sum(reports)) %>%
  mutate(incidence = total_cases / city_pop,
         true_outbreak_year = ifelse(incidence >= boundary, TRUE, FALSE))

save_probs <- all_probs %>%
  right_join(
    template
  ) %>%
  arrange(year, week) %>%
  mutate(n = ifelse(is.na(n) == TRUE, 0, n),
         lead_time = 52 - (week-1)) %>%
  left_join(new_data_classified)

ggplot(filter(save_probs, outbreak_year == TRUE), 
       aes(x = lead_time, y = n, color = true_outbreak_year)) +
  geom_line() +
  geom_point() +
  facet_wrap(~year) +
  scale_x_reverse()


# 
# train_sims <- simulate_over_obs(M1, mles, nreps = ncol(all_states[[1]]))
# forecasts <- simulate_forecasts(pomp_obj = M1, train_sims = train_sims, 
#                                 time_start = 2004.975, time_end = 2005.978, 
#                                 param_df = mles, nreps = ncol(all_states[[1]]), 
#                                 states_list = all_states)
# 
# forecasts %>% 
#   filter(sim != "data") %>%
#   ggplot(aes(x = time, y = reports, group = sim)) +
#   geom_line(alpha = 0.2, size = 0.2) +
#   geom_point(data = filter(forecasts, sim == "data"), color = "blue")
```


## Use EWS to predict outbreaks

Now I will calculate EWS over a moving window in an increasinly large time series from week 30 to week 52 leading up to the next season.
For each length of time series (i.e., lead time) I will calculate the trend in the EWS over time.
Increasing EWS signal an upcoming transition.
When the mean, autocorrelation, autocovariance, variance, and decay time all show increasing trends, I will call that a warning of an outbreak.

```{r calc-ews}
# Get the case data
ews_data <- test_data %>%
  filter(year(date) < 2000) %>%
  dplyr::select(date, reports)

# Set the EWS bandwidth to 15 weeks
bandwidth <- 15

# Set up lead time sequence
stop_times <- seq_len(nrow(ews_data))[-c(1:3)]  # drop 1st element b/c it's 1 yr only

# Loop over stop times and calculate EWS trends
out_trends <- tibble()  # empty tibble for storage
for(tstop in stop_times){
  x <- ews_data$reports[1:tstop]
  trends <- spaero::get_stats(x = x, center_trend = "local_constant",
                              center_kernel = "uniform",
                              center_bandwidth = bandwidth, 
                              stat_trend = "local_constant",
                              stat_kernel = "uniform", 
                              stat_bandwidth = bandwidth, lag = 1,
                              backward_only = TRUE)$taus %>%
    as_tibble() %>%
    gather() %>%
    mutate(trend_sign = sign(value)) %>%
    filter(!(key %in% c("skewness", "kurtosis", 
                        "coefficient_of_variance"))) %>%
    group_by(trend_sign) %>%
    count() %>%
    mutate(stop_week = tstop)
  
  out_trends <- bind_rows(out_trends, trends)
}

warning_week <- out_trends %>%
  filter(trend_sign == 1) %>%
  mutate(lead_time = 52 - (30 + stop_week)) %>%
  filter(n == max(n)) %>%
  pull(lead_time) %>%
  max()

out_trends %>%
  filter(trend_sign == 1) %>%
  mutate(lead_time = 52 - (30 + stop_week)) %>%
  ggplot(aes(x = lead_time, y = n)) +
   geom_vline(aes(xintercept = warning_week), color = "red") +
  geom_line(size = 0.4, color = "grey45") +
  geom_point(size = 4, color = "grey45") +
  scale_x_reverse() +
  labs(x = "lead time (weeks)", y = "number of EWS increasing")
```

OK, that was for on outbreak year.
Now I'll do the same analysis for every year, whether a large or small outbreak.

```{r ews-all-years}
my_get_stats <- function(x, bandwidth){
   spaero::get_stats(x = x, center_trend = "local_constant",
                     center_kernel = "uniform", center_bandwidth = bandwidth, 
                     stat_trend = "local_constant", stat_kernel = "uniform", 
                     stat_bandwidth = bandwidth, lag = 1, backward_only = TRUE)
}

get_trends <- function(x, bandwidth, ews_to_ignore = NULL){
  stop_times <- seq_len(length(x))[-c(1:3)]
  out_trends <- tibble()
  
  for(tstop in stop_times){
    xnow <- x[1:tstop]
    trends <- my_get_stats(x = xnow, bandwidth = bandwidth)$taus %>%
      as_tibble() %>%
      gather() %>%
      mutate(trend_sign = sign(value)) %>%
      filter(!(key %in% ews_to_ignore)) %>%
      group_by(trend_sign) %>%
      count() %>%
      mutate(stop_week = tstop,
             lead_time = 52 - (30 + stop_week))
    
    out_trends <- bind_rows(out_trends, trends)
  }
  return(out_trends)
}

get_testing_data <- function(df, test_year){
  df %>%
    filter(year == (test_year - 1) & week(date) > 30) %>%
    pull(reports)
}

run_ews_analysis <- function(df, test_year, bw = 15, ews_to_ignore){
  cases <- get_testing_data(df, test_year)
  ews_trends <- get_trends(x = cases, bandwidth = bw,
                           ews_to_ignore = ews_to_ignore)
  return(ews_trends)
} 

years_to_predict <- unique(sim$year)[-1]
all_trends <- tibble()
ignore_these <-  c("skewness", "kurtosis", "cofficient_of_variation")

for(do_year in years_to_predict){
  all_trends %>%
    bind_rows(
      run_ews_analysis(sim, test_year = do_year, 
                       bw = 15, ews_to_ignore = ignore_these) %>%
        mutate(test_year = do_year)
    ) -> all_trends
}

all_trends %>%
  filter(trend_sign == 1) %>%
  left_join(
    sim %>% dplyr::select(year, outbreak_year),
    by = c("test_year" = "year")
  ) %>%
  ggplot(aes(x = lead_time, y = n/5, color = outbreak_year)) +
  geom_hline(aes(yintercept = 1), color = "grey45") +
  geom_line() +
  geom_point() +
  scale_x_reverse() +
  scale_y_continuous(limits = c(0, 1)) +
  facet_wrap(~test_year, nrow = 2) +
  labs(x = "lead time (weeks)", y = "proprtion of EWS increasing")
```

